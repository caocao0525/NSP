{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76c36b48",
   "metadata": {},
   "source": [
    "# Utilities\n",
    "Various functions to process the initial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "706ee542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### To convert the file into .py\n",
    "# !jupyter nbconvert --to script css_utility.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "caaf2acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lee/anaconda3/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from motif_utils import seq2kmer\n",
    "from motif_utils import kmer2seq\n",
    "from scipy.stats import norm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import random\n",
    "import collections\n",
    "from collections import defaultdict, OrderedDict\n",
    "import operator\n",
    "import itertools\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "import glob\n",
    "from wordcloud import WordCloud\n",
    "import stylecloud\n",
    "from collections import Counter\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2290a7",
   "metadata": {},
   "source": [
    "## Index\n",
    "\n",
    "* **[1. Gene and Genome file preprocessing](#1.-Gene-and-Genome-file-preprocessing)**\n",
    "    * [1-1. Gene file separation by chromosome](#1-1.-Gene-file-separation-by-chromosome)\n",
    "    * [1-2. Genome statistics](#1-2.-Genome-statistics)\n",
    "* **[2. Chromatin state preprocessing](#2.-Chromatin-state-preprocessing)**\n",
    "    * [2-1. Chromatin state file info](#2-1.-Chromatin-state-file-info)\n",
    "    * [2-2. Prerequisite dictionaries](#2-2.-Prerequisite-dictionaries)\n",
    "        * [2-2-1. Function to convert RGB into decimal RGB](#2-2-1.-Function-to-convert-RGB-into-decimal-RGB)\n",
    "    * [2-3. Generate CSS .bed to dataframe](#2-3.-Generate-CSS-.bed-to-dataframe)\n",
    "        * [2-3-1. Individual dataframe analysis](#2-3-1.-Individual-dataframe-analysis)\n",
    "    * [2-4. CSS string generation from dataframe](#2-4.-CSS-string-generation-from-dataframe)\n",
    "        * [2-4-1. Real length CSS](#2-4-1.-Real-length-CSS)\n",
    "        * [2-4-2. Unit-length CSS](#2-4-2.-Unit-length-CSS)\n",
    "    * [2-5. Chromatin State Statistics](#2-5.-Chromatin-State-Statistics)\n",
    "* **[3. Cutting the chromatin state (Dataset Preparation)](#3.-Cutting-the-chromatin-state-(Dataset-Preparation))**\n",
    "    * [3-1. Quiescent state distribution](#3-1.-Quiescent-state-distribution)\n",
    "    * [3-2. Cut the telomere region on CSS and save the file](#3-2.-Cut-the-telomere-region-on-CSS-and-save-the-file) <font color=\"royalblue\">-> **pretrain data are saved**</font>\n",
    "    * [3-3. Cut the chromatin states : genic/non-genic area](#3-3.-Cut-the-chromatin-states-:-genic-or-non-genic-area)\n",
    "        * [3-3-1. Genic area](#3-3-1.-Genic-area)\n",
    "        * [3-3-2. Non-genic area (intergenic region)](#3-3-2.-Non-genic-area-(intergenic-region))\n",
    "        * [3-3-3. Genic or Non-genic raw-length CSS to unit-length CSS](#3-3-3.-Genic-or-Non-genic-raw-length-CSS-to-unit-length-CSS)\n",
    "            * [3-3-3-0. Small code modifications](#3-3-3-0.-Small-code-modifications)\n",
    "            * [3-3-3-1. CSS for 57 Epigenomes Genic regions are saved.](#3-3-3-1.-CSS-for-57-Epigenomes-Genic-regions-are-saved.)\n",
    "        * [3-3-4. Cut the unit-length css into trainable size and kmerize it](#3-3-4.-Cut-the-unit-length-css-into-trainable-size-and-kmerize-it) <font color=\"royalblue\">-> **pretrain data are saved**</font>\n",
    "        * [3-3-5. Fine-tuning data: Dataframe version](#3-3-5.-Fine-tuning-data:-Dataframe-version)\n",
    "        * [3-3-6. Fine-tuning data: save files as .tsv](#3-3-6.-Fine-tuning-data:-save-files-as-.tsv) <font color=\"orange\"> -> **fine-tuning data are saved** </font>\n",
    "    * [3-4. Count the number of 15th states in genic and non-genic region](#3-4.-Count-the-number-of-15th-states-in-genic-and-non-genic-region)         \n",
    "    * [3-5. Complexity of CSS in genic area](#3-5.-Complexity-of-CSS-in-genic-area)\n",
    "        * [3-5-1. Create a matrix to show the statistics](#3-5-1.-Create-a-matrix-to-show-the-statistics)\n",
    "        * [3-5-2. Extract the complex and less complex css on gene](#3-5-2.-Extract-the-complex-and-less-complex-css-on-gene)\n",
    "            * [3-5-2-1. CSS for 57 Epigenomes Complex and Less Complex Genic regions are saved.](#3-5-2-1.-CSS-for-57-Epigenomes-Complex-and-Less-Complex-Genic-regions-are-saved.)\n",
    "        * [3-5-3. Cut into Kmer and save](#3-5-3.-Cut-into-Kmer-and-save) <font color=\"royalblue\">-> **pretrain data are saved**</font>\n",
    "        * [3-5-4. Show the composition for each case](#3-5-4.-Show-the-composition-for-each-case)\n",
    "        * [3-5-5. Prepare and save Fine-tuning for Complex gene CSS and others](#3-5-5.-Prepare-and-save-Fine-tuning-for-Complex-gene-CSS-and-others) <font color=\"orange\"> -> **fine-tuning data are saved**</font>\n",
    "    * [3-6. Gene expression classification](#3-6.-Gene-expression-classification)\n",
    "        * [3-6-1. Gene expression file into the list of dataframe](#3-6-1.-Gene-expression-file-into-the-list-of-dataframe)\n",
    "            * [3-6-1-1. Not expressed refFlat ](#3-6-1-1.-Not-expressed-refFlat)\n",
    "        * [3-6-2. Matching to CSS](#3-6-2.-Matching-to-CSS)\n",
    "            * [3-6-2-1. CSS for various gene expression cases are saved.](#3-6-2-1.-CSS-for-various-gene-expression-cases-are-saved.)\n",
    "        * [3-6-3. Cut into Kmer and save](#3-6-3.-Cut-into-Kmer-and-save)<font color=\"royalblue\">-> **pretrain data are saved**</font>\n",
    "        * [3-6-4. Fine-tuning data](#3-6-4.-Fine-tuning-data) <font color=\"orange\"> -> **fine-tuning data are saved** </font>\n",
    "    * [3-7. Promoter classification](#3-7.-Promoter-classification)\n",
    "        * [3-7-1. Prmototer region extraction by location](#3-7-1.-Prmototer-region-extraction-by-location)\n",
    "        * [3-7-2. Chromatin state per data strip visualization](#3-7-2.-Chromatin-state-per-data-strip-visualization)\n",
    "        * [3-7-3. Extract Promoter regions from gene with various expression level](#3-7-3.-Extract-Promoter-regions-from-gene-with-various-expression-level)\n",
    "        * [3-7-4. Extract Promoter regions from not expressed genes](#3-7-4.-Extract-Promoter-regions-from-not-expressed-genes)\n",
    "        * [3-7-5. Strong and Weak promoter](#3-7-5.-Strong-and-Weak-promoter)\n",
    "        * [3-7-6. Kmerize and save and merge](#3-7-6.-Kmerize-and-save-and-merge)\n",
    "        * [3-7-7. Exclusive case](#3-7-7.-Exclusive-case)\n",
    "        * [3-7-8. Fine tuning result visualization](#3-7-8.-Fine-tuning-result-visualization)\n",
    "    * [3-8. Enhancer classification](#3-8.-Enhancer-classification)\n",
    "        * [3-8-1. Enhancer region extraction by location](#3-8-1.-Enhancer-region-extraction-by-location)\n",
    "        * [3-8-2. Extract Enhancer regions from gene with various expression level](#3-8-2.-Extract-Enhancer-regions-from-gene-with-various-expression-level)\n",
    "        * [3-8-3. Extract Enhancer regions from not expressed genes](#3-8-3.-Extract-Enhancer-regions-from-not-expressed-genes)\n",
    "        * [3-8-4. Kmerize and save and merge](#3-8-4.-Kmerize-and-save-and-merge) <font color=\"orange\"> -> **fine-tuning data are saved** </font>\n",
    "        * [3-8-5. Fine-tuning save byCellType](#3-8-5.-Fine-tuning-save-byCellType) <font color=\"orange\"> -> **fine-tuning data are saved** </font>\n",
    "* **[4. CSS Pattern analysis](#4.-CSS-Pattern-analysis)**\n",
    "* **[5. Training result analysis](#5.-Training-result-analysis)**\n",
    "    * [5-1. Evaluation](#5-1.-Evaluation)\n",
    "        * [5-1-2. Pretrain evaluation](#5-1-2.-Pretrain-evaluation)\n",
    "        * [5-1-3. Fine tuning evaluation](#5-1-3.-Fine-tuning-evaluation)\n",
    "    * [5-2. Motif](#5-2.-Motif)\n",
    "        * [5-2-1. Motif visualization](#5-2-1.-Motif-visualization)\n",
    "            * [5-2-1-1. Motif to Logo](#5-2-1-1.-Motif-to-Logo)\n",
    "        * [5-2-2. Motif extraction](#5-2-2.-Motif-extraction)\n",
    "        * [5-2-3. Motif embedding: one-hot](#5-2-3.-Motif-embedding:-one-hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4421a5",
   "metadata": {},
   "source": [
    "**Frequently used functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2143a0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatLst(lst):\n",
    "    flatten_lst=[elm for sublst in lst for elm in sublst]\n",
    "    return flatten_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b765864",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_list_maker(path, files):\n",
    "    all_files=[]\n",
    "    for file in files:\n",
    "        file_path=os.path.join(path,file)\n",
    "        all_files.append(file_path)\n",
    "    return all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7297205d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def colored_css_str_as_is(sub_str):   # convert space into space\n",
    "    col_str=\"\"\n",
    "    for letter in sub_str:\n",
    "        if letter==\" \":\n",
    "            col_str+=\" \"\n",
    "        else:                \n",
    "            for state in list(state_col_255_dict.keys()):\n",
    "                if letter==state:\n",
    "                    r=state_col_255_dict[letter][0]\n",
    "                    g=state_col_255_dict[letter][1]\n",
    "                    b=state_col_255_dict[letter][2]\n",
    "                    col_letter=\"\\033[38;2;{};{};{}m{}\\033[38;2;255;255;255m\".format(r,g,b,letter)\n",
    "                    col_str+=col_letter\n",
    "    return print(\"\\033[1m\"+col_str+\"\\033[0;0m\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb94779a",
   "metadata": {},
   "source": [
    "## 1. Gene and Genome file preprocessing\n",
    "Handling the human gene location file and the reference human genome file *hg19*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd3b1bc",
   "metadata": {},
   "source": [
    "**Gene file info**\n",
    "* This file includes the information of the location of genes on the human genome.\n",
    "* Name: `RefSeq.WholeGene.bed`\n",
    "* Location: (local linux DLBOX2 ->) `../database/RefSeq/` (server ->) `euphonium:/work/Database/UCSC/hg19/` \n",
    "* Structure: \n",
    "    * tab-delimited\n",
    "    * columns: `{0:\"chromosome\",1:\"TxStart\",2:\"TxEnd\",3:\"name\",4:\"unk0\",5:'strand', 6:'cdsStart', 7:'cdsEnd',8:\"unk1\",9:\"exonCount\",10:\"unk2\",11:\"unk3\"}`\n",
    "<br>\n",
    "\n",
    "**Genome file info**\n",
    "\n",
    "* This file is the human reference genome file.\n",
    "* Name: `genome.fa`\n",
    "* Location: (local linux DLBOX2, macpro ->) `../database/hg19/` (server ->) `/work/Database/UCSC/hg19/`\n",
    "* Chromosome-wise file location: (local linux DLBOX2, macpro ->) `../database/hg19/genome_per_chr/`\n",
    "* Structure:\n",
    "    * `>` delimiter per chromosome (e.g. `>chr1`)\n",
    "    * The file is separated chromosome-wise, using following command lines\n",
    "        > (1) `sed 's/>//g' genome.fa > genome_mod.fa` : find `>` and remove it then save as `genome.fa`<br>\n",
    "        > (2) `awk '$1 ~/^chr/{close(name);name=$1;next}{print $1>name}' genome_mod.fa` : find string starting `chr` form `genome_mod.fa` and save the 1st field (=the base string) as reading the file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "456028d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the file from local\n",
    "whole_gene_file='../database/RefSeq/RefSeq.WholeGene.bed'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72ebb3c",
   "metadata": {},
   "source": [
    "### 1-1. Gene file separation by chromosome\n",
    "#### Function: `WhGene2GLChr`\n",
    "* **Description**: Generate the chromosome-wise list of dataframe of gene location\n",
    "<br>\n",
    "* **Input**: `whole_gene_file`\n",
    "* **Output**: `g_df_chr_lst` A list of chromosome-wise Dataframes, each of which contains `chromosome` (chromosome number), `TxStart`, `TxEnd`, and `name` (gene name). Note that `chrM` is removed in the process. \n",
    "\n",
    "* This fuction is used in the function `compGene2css` [jump](#compGene2css) which generates **`css_gene_lst_all`**, the list of list that contains the chromatin states for genic region per chromosome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f555c512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for preprocess the whole gene data and produce chromosome-wise gene lists\n",
    "# each element is dataframe\n",
    "\n",
    "def whGene2GLChr(whole_gene_file='../database/RefSeq/RefSeq.WholeGene.bed'):\n",
    "    print(\"Extracting the gene file ...\")\n",
    "    g_fn=whole_gene_file\n",
    "    g_df_raw=pd.read_csv(g_fn, sep='\\t', lineterminator='\\n', header=None, low_memory=False)\n",
    "    g_df_int=g_df_raw.rename(columns={0:\"chromosome\",1:\"TxStart\",2:\"TxEnd\",3:\"name\",4:\"unk0\",\n",
    "                                  5:'strand', 6:'cdsStart', 7:'cdsEnd',8:\"unk1\",9:\"exonCount\",\n",
    "                                  10:\"unk2\",11:\"unk3\"})\n",
    "    g_df=g_df_int[[\"chromosome\",\"TxStart\",\"TxEnd\",\"name\"]]\n",
    "    \n",
    "    # Remove other than regular chromosomes\n",
    "    chr_lst=['chr1','chr2','chr3','chr4','chr5','chr6','chr7','chr8','chr9','chr10',\n",
    "             'chr11','chr12','chr13','chr14','chr15','chr16','chr17','chr18','chr19',\n",
    "             'chr20','chr21','chr22','chrX','chrY']\n",
    "    g_df=g_df.loc[g_df[\"chromosome\"].isin(chr_lst)]\n",
    "    \n",
    "    # Create a list of chromosome-wise dataframe \n",
    "    g_df_chr_lst=[]\n",
    "    for num in range(len(chr_lst)):\n",
    "        chr_num=chr_lst[num]\n",
    "        g_chr_df='g_'+chr_num\n",
    "        locals()[g_chr_df]=g_df[g_df[\"chromosome\"]==chr_num]\n",
    "        g_chr_df=locals()[g_chr_df]\n",
    "        g_chr_df=g_chr_df.sort_values(\"TxStart\")\n",
    "        g_df_chr_lst.append(g_chr_df)\n",
    "    print(\"Done!\")\n",
    "    \n",
    "    return g_df_chr_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdd499f",
   "metadata": {},
   "source": [
    "### 1-2. Genome statistics\n",
    "\n",
    "* Prerequisite file: chromosome-wise separated reference genome file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a90c573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prerequisite file load\n",
    "# chr_path='../database/hg19/genome_per_chr/'\n",
    "# chr_list=[os.path.join(chr_path, file) for file in sorted(os.listdir(chr_path))]\n",
    "# chr1=chr_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eab8960",
   "metadata": {},
   "source": [
    "#### Function `chrNdist`\n",
    "\n",
    "* **Description**: Generate the index list and dataframe ('start' and 'end' location) of 'N' base in genome file. <br> 'N' indicates that it can be *any* base (See [reference](https://iubmb.qmul.ac.uk/misc/naseq.html))\n",
    "* **Input**: Chromosome-wise separated genome\n",
    "* **Output**: Two elements (`all_n_index` (list) and  `n_dist_df`(dataframe)). <br> `all_n_index` is just a list of all the indices where 'N's are located, while `n_dist_df` accomodates 'start', 'end', and 'count' as columns.\n",
    "* **Note** that the 'N' here stands for 50 bases. (resolution=50 bases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a983d85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chrNdist(chr_file): #=chr1):\n",
    "    \"\"\"\n",
    "    input: divided genome by chromosome (without any index, only genome)\n",
    "    output: dataframe of [start, end] position of \"N\" in the genome sequence\n",
    "    \"\"\"\n",
    "    with open(chr_file) as infile:\n",
    "        all_n_line=\"N\"*50    # python reads text line by 50 characters\n",
    "        all_n_index=[]\n",
    "        all_n_start=[1]\n",
    "        all_n_end=[]\n",
    "\n",
    "        for i, line in enumerate(infile):\n",
    "            if all_n_line in line:\n",
    "                all_n_index.append(i)    # all_n_index is a list of N\n",
    "\n",
    "        for i, num in enumerate(all_n_index):   \n",
    "            if i==0:        \n",
    "                pre_num=num\n",
    "            elif num !=pre_num+1:\n",
    "                all_n_start.append(num)\n",
    "            pre_num=num   \n",
    "        for i, num in enumerate(all_n_index):   \n",
    "            if i==0:        \n",
    "                pre_num=num\n",
    "            elif num !=pre_num+1:\n",
    "                all_n_end.append(pre_num+1)\n",
    "            pre_num=num\n",
    "        all_n_end.append(all_n_index[-1]+1)\n",
    "\n",
    "        assert len(all_n_start)==len(all_n_end)\n",
    "        \n",
    "        n_dist_df=pd.DataFrame({\"start\":all_n_start,\"end\":all_n_end, \n",
    "                                \"count\":[e-s+1 for s,e in zip(all_n_start,all_n_end)]},\n",
    "                               columns=[\"start\",\"end\",\"count\"])\n",
    "        ######## uncomment this block if you want to draw the histogram!\n",
    "#         fig=plt.figure(figsize=(8,4))\n",
    "#         plt.hist(all_n_index, 50, facecolor='teal', alpha=0.75)\n",
    "#         plt.xlabel(\"Position\")\n",
    "#         plt.ylabel(\"number of 'N' lines\")\n",
    "#         plt.show()    \n",
    "        return all_n_index, n_dist_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec03aaf8",
   "metadata": {},
   "source": [
    "#### Function: `all_chr_Ndist `\n",
    "\n",
    "* **Description**\n",
    "    * Draw a histogram of 'N' distiribution chromosome-wise.\n",
    "    * Generate a list of chromosome-wise list of the index for 'N' location (still, resolution = 50 bases)\n",
    "* **Input**: The reference genome file path `'../database/hg19/genome_per_chr/'`\n",
    "* **Option**: Normalization (default=`True`)\n",
    "\n",
    "* **Output**\n",
    "    * A list of chromosome-wise list of 'N' location on genome.\n",
    "    * `all_chr_n_index_norm` (if normalization ON) \n",
    "    * `all_chr_n_index` (if normalization OFF)\n",
    "<!-- ![](./desc_img/all_chr_Ndist.png) -->\n",
    "\n",
    "<img src=\"./desc_img/all_chr_Ndist.png\" width=\"500\" height=\"250\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0b1b453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_chr_Ndist(ref_genome_path='../database/hg19/genome_per_chr/', normalization=True):\n",
    "    \n",
    "    \"\"\"\n",
    "    input: ref_genome_path='../database/hg19/genome_per_chr/'\n",
    "    output: all_chr_n_index_norm (normalization ON) / all_chr_n_index (normalization OFF)\n",
    "    option: normalization (all chromosome length= 0 to 1 for drawing a dist. graph)\n",
    "    \"\"\"\n",
    "    \n",
    "    path=ref_genome_path\n",
    "    chr_list=[(file, os.path.join(path, file)) for file in sorted(os.listdir(path)) if \"chrM\" not in file] # remove chrM\n",
    "    \n",
    "    fig=plt.figure(figsize=(12,6))\n",
    "    ax = plt.subplot(111)\n",
    "    \n",
    "    all_chr_n_index=[] # list of list (raw data)\n",
    "    all_chr_n_index_norm=[] # list of list (normalized data)\n",
    "    \n",
    "    for i, (chr_no, chr_path) in enumerate(chr_list):\n",
    "        all_n_index, n_dist_df=chrNdist(chr_path)\n",
    "        # save the raw data\n",
    "        all_chr_n_index.append(all_n_index)\n",
    "        \n",
    "        ########### normalization here ###########\n",
    "        all_n_index_norm=[elm/all_n_index[-1] for elm in all_n_index]\n",
    "        ##########################################\n",
    "        \n",
    "        grad_color=plt.cm.terrain(i*10)\n",
    "        ax.hist(all_n_index_norm, 50, color=grad_color, histtype=\"step\", label=chr_no)\n",
    "        all_chr_n_index_norm.append(all_n_index_norm)\n",
    "        \n",
    "    ### show only the normalized disribution\n",
    "    box = ax.get_position()\n",
    "    ax.set_position([box.x0, box.y0, box.width * 0.8, box.height]) # Shrink current axis's height by 20% on the bottom\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.xlabel(\"Normalized Position\")\n",
    "    plt.ylabel(\"number of 'N' lines\")\n",
    "    plt.grid(b=None)\n",
    "\n",
    "    plt.show()  \n",
    "    \n",
    "    if normalization:\n",
    "        return all_chr_n_index_norm \n",
    "    else:\n",
    "        return all_chr_n_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13309e5",
   "metadata": {},
   "source": [
    "# 2. Chromatin state preprocessing\n",
    "**[back to index](#Index)**\n",
    "\n",
    "Chromatin state file (`.bed` file) preprocessing to further analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df78600",
   "metadata": {},
   "source": [
    "## 2-1. Chromatin state file info\n",
    "\n",
    "* This files are the chromatin state-annotated (15 different states, per 200 bps) genomes of 127 different cells.\n",
    "* Location: (local linux DLBOX2, macpro ->) `/database/bed/unzipped`  (server ->) `euph:/work/ChIP-seq/ROADMAP/byFileType/chromhmmSegmentations/ChmmModels/coreMarks/jointModel/final/*_15_coreMarks_dense.bed`\n",
    "* Structure: tab-delimited, 4 columns (chromosome numner, start, end, and state number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce6b1d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pickle for a cell-wise dataframe (should be modified to correct the cell ID)\n",
    "def total_df2pickle(total_df_list):\n",
    "    for num, df_cell in enumerate(tqdm.notebook.tqdm(total_df_list)):\n",
    "        path=\"../database/cell_pickle/\"\n",
    "        if num+1 < 10:\n",
    "            file_name=path+\"df_cell\"+\"00\"+str(num+1)+\".pkl\"\n",
    "            df_cell_pickled=df_cell.to_pickle(file_name)\n",
    "        elif num+1 < 100:\n",
    "            file_name=path+\"df_cell\"+\"0\"+str(num+1)+\".pkl\"\n",
    "            df_cell_pickled=df_cell.to_pickle(file_name)\n",
    "        else:\n",
    "            file_name=path+\"df_cell\"+str(num+1)+\".pkl\"\n",
    "            df_cell_pickled=df_cell.to_pickle(file_name)\n",
    "\n",
    "path='../database/bed/unzipped/'\n",
    "bed_files=os.listdir(path)\n",
    "\n",
    "pickle_path='../database/cell_pickle/'\n",
    "pickle_files=os.listdir(pickle_path)\n",
    "            \n",
    "all_files=file_list_maker(path, bed_files)\n",
    "all_cell_pickles=file_list_maker(pickle_path, pickle_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95d9bfbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../database/bed/unzipped/E119_15_coreMarks_stateno.bed'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e85da4e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../database/cell_pickle/df_cell022.pkl'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cell_pickles[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7d645b",
   "metadata": {},
   "source": [
    "#### Updated the pickled df to match the cell ID\n",
    "* The following function has been conducted and no need to run\n",
    "* Output path is `../database/roadmap/df_pickled/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a712ce49",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_unzipped=\"../database/bed/unzipped/\" ## unzipped bed file (chromatin state annotation file for ROADMAP)\n",
    "unzipped_epi=sorted(os.listdir(path_unzipped))\n",
    "unzipped_epi_files=[os.path.join(path_unzipped,file) for file in unzipped_epi]\n",
    "\n",
    "def unzipped_to_df(unzipped_epi_files, output_path=\"../database/roadmap/df_pickled/\"):\n",
    "    for file in unzipped_epi_files:\n",
    "        cell_id=file.split(\"/\")[-1][:4]\n",
    "        output_name=output_path+cell_id+\"_df_pickled.pkl\"\n",
    "        df=bed2df_expanded(file)\n",
    "        df.to_pickle(output_name)\n",
    "    return print(\"done!\")\n",
    "# unzipped_to_df(unzipped_epi_files, output_path=\"../database/roadmap/df_pickled/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61af4ff",
   "metadata": {},
   "source": [
    "* The following function has been conducted and no need to run\n",
    "* Input path: (df_pickled_path=) `../database/roadmap/df_pickled/`\n",
    "* Output path: `../database/roadmap/css_pickled/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc02de26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickled_df2unit_css(df_pickled_path, output_path=\"../database/roadmap/css_unit_pickled/\",verbose=True):\n",
    "    \n",
    "    def load_pickled_df(df_pickled_file):\n",
    "        with open(df_pickled_file, \"rb\") as f:\n",
    "            df = pickle.load(f)\n",
    "        unit_css = df2unitcss(df)\n",
    "        return unit_css   \n",
    "        df_pickled_files = [os.path.join(df_pickled_path, df) for df in sorted(os.listdir(df_pickled_path))]      \n",
    "    \n",
    "    for file in df_pickled_files:\n",
    "        cell_id = file.split(\"/\")[-1][:4]\n",
    "        output_name = output_path + cell_id + \"_css_pickled.pkl\"           \n",
    "        unit_css=load_pickled_df(file)\n",
    "        with open(output_name, 'wb') as g:\n",
    "            pickle.dump(unit_css, g)          \n",
    "        if verbose:\n",
    "            print(cell_id+\" is done\")\n",
    "\n",
    "    return print(\"All done!\")\n",
    "# pickled_df2unit_css(df_pickled_path,output_path=\"../database/roadmap/css_pickled/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983eb6e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6330ba71",
   "metadata": {},
   "source": [
    "## 2-2. Prerequisite dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ed5aad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict={1:\"A\", 2:\"B\", 3:\"C\", 4:\"D\", 5:\"E\",6:\"F\",7:\"G\",8:\"H\" ,\n",
    "                9:\"I\" ,10:\"J\",11:\"K\", 12:\"L\", 13:\"M\", 14:\"N\", 15:\"O\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbe7fa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "css_name=['TssA','TssAFlnk','TxFlnk','Tx','TxWk','EnhG','Enh','ZNF/Rpts',\n",
    "          'Het','TssBiv','BivFlnk','EnhBiv','ReprPC','ReprPcWk','Quies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6196a9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "css_dict=dict(zip(list(state_dict.values()), css_name))  # css_dict={\"A\":\"TssA\", \"B\":\"TssAFlnk\", ... }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a03cc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# color dict update using the info from https://egg2.wustl.edu/roadmap/web_portal/chr_state_learning.html\n",
    "# 18th May 2022\n",
    "css_color_dict={'TssA':(255,0,0), # Red\n",
    "                'TssAFlnk': (255,69,0), # OrangeRed\n",
    "                'TxFlnk': (50,205,50), # LimeGreen\n",
    "                'Tx': (0,128,0), # Green\n",
    "                'TxWk': (0,100,0), # DarkGreen\n",
    "                'EnhG': (194,225,5), # GreenYellow \n",
    "                'Enh': (255,255,0),# Yellow\n",
    "                'ZNF/Rpts': (102,205,170), # Medium Aquamarine\n",
    "                'Het': (138,145,208), # PaleTurquoise\n",
    "                'TssBiv': (205,92,92), # IndianRed\n",
    "                'BivFlnk': (233,150,122), # DarkSalmon\n",
    "                'EnhBiv': (189,183,107), # DarkKhaki\n",
    "                'ReprPC': (128,128,128), # Silver\n",
    "                'ReprPCWk': (192,192,192), # Gainsboro\n",
    "                'Quies': (240, 240, 240)}  # White -> bright gray "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af152ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_col_dict_num={'A': (1.0, 0.0, 0.0),\n",
    " 'B': (1.0, 0.271, 0.0),\n",
    " 'C': (0.196, 0.804, 0.196),\n",
    " 'D': (0.0, 0.502, 0.0),\n",
    " 'E': (0.0, 0.392, 0.0),\n",
    " 'F': (0.761, 0.882, 0.02),\n",
    " 'G': (1.0, 1.0, 0.0),\n",
    " 'H': (0.4, 0.804, 0.667),\n",
    " 'I': (0.541, 0.569, 0.816),\n",
    " 'J': (0.804, 0.361, 0.361),\n",
    " 'K': (0.914, 0.588, 0.478),\n",
    " 'L': (0.741, 0.718, 0.42),\n",
    " 'M': (0.502, 0.502, 0.502),\n",
    " 'N': (0.753, 0.753, 0.753),\n",
    " 'O': (0.941, 0.941, 0.941)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c13341b",
   "metadata": {},
   "source": [
    "### 2-2-1. Function to convert RGB into decimal RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfa51178",
   "metadata": {},
   "outputs": [],
   "source": [
    "def colors2color_dec(css_color_dict):\n",
    "    colors=list(css_color_dict.values())\n",
    "    color_dec_list=[]\n",
    "    for color in colors:\n",
    "        color_dec=tuple(rgb_elm/255 for rgb_elm in color)\n",
    "        color_dec_list.append(color_dec)        \n",
    "    return color_dec_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0bceba",
   "metadata": {},
   "source": [
    "**scale 0 to 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e4be49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_col_dict=dict(zip(list(state_dict.values()),colors2color_dec(css_color_dict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6fd5c5",
   "metadata": {},
   "source": [
    "**scale 0 to 255**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0819c597",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_col_255_dict=dict(zip(list(state_dict.values()),list(css_color_dict.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b438c64e",
   "metadata": {},
   "source": [
    "**hexacode**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea6d9b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hexa_state_col_dict={letter: \"#{:02x}{:02x}{:02x}\".format(*rgb) for letter,rgb in state_col_255_dict.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a8ee90",
   "metadata": {},
   "source": [
    "**name instead of alphabets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13cfe7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "css_name_col_dict=dict(zip(css_name,state_col_dict.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ef3909",
   "metadata": {},
   "source": [
    "## 2-3. Generate CSS .bed to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f92a5e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe from bed file\n",
    "# bed file here means: EXXX_15_coreMarks_stateno.bed\n",
    "\n",
    "def bed2df_as_is(filename):    \n",
    "    \n",
    "    \"\"\"Create dataframe from the .bed file, as is.\n",
    "    Dataframe contains following columns:\n",
    "    chromosome |  start |  end  | state \"\"\"\n",
    "    \n",
    "    df_raw=pd.read_csv(filename, sep='\\t', lineterminator='\\n', header=None, low_memory=False)\n",
    "    df=df_raw.rename(columns={0:\"chromosome\",1:\"start\",2:\"end\",3:\"state\"})\n",
    "    df=df[:-1]\n",
    "    df[\"start\"]=pd.to_numeric(df[\"start\"])\n",
    "    df[\"end\"]=pd.to_numeric(df[\"end\"])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa9c3da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bed2df_expanded(filename):\n",
    "    \n",
    "    \"\"\"Create an expanded dataframe from the .bed file.\n",
    "    Dataframe contains following columns:\n",
    "    chromosome |  start |  end  | state | length | unit | state_seq | state_seq_full\"\"\"\n",
    "   \n",
    "    df_raw=pd.read_csv(filename, sep='\\t', lineterminator='\\n', header=None, low_memory=False)\n",
    "    df=df_raw.rename(columns={0:\"chromosome\",1:\"start\",2:\"end\",3:\"state\"})\n",
    "    df=df[:-1]\n",
    "    df[\"start\"]=pd.to_numeric(df[\"start\"])\n",
    "    df[\"end\"]=pd.to_numeric(df[\"end\"])\n",
    "    df[\"state\"]=pd.to_numeric(df[\"state\"])\n",
    "    df[\"length\"]=df[\"end\"]-df[\"start\"]\n",
    "    df[\"unit\"]=(df[\"length\"]/200).astype(int)  # chromatin state is annotated every 200 bp (18th May 2022)\n",
    "               \n",
    "    df[\"state_seq\"]=df[\"state\"].map(state_dict)\n",
    "    df[\"state_seq_full\"]=df[\"unit\"]*df[\"state_seq\"]\n",
    "    \n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf755bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_df_maker(all_files):\n",
    "    \n",
    "    \"\"\"Create a list of dataframe from a list of bed files.\n",
    "    This function utilizes the function named 'bed2df_expanded.'\"\"\"\n",
    "    \n",
    "    total_df=[]\n",
    "    for filename in all_files:\n",
    "        df=bed2df_expanded(filename)\n",
    "        total_df.append(df)\n",
    "    return total_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c5da4e",
   "metadata": {},
   "source": [
    "### 2-3-1. Individual dataframe analysis\n",
    "\n",
    "* Functions for analyzing an individual dataframe\n",
    "* CSS here refers Chromatin state sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b1b4d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numchr(df):\n",
    "    assert \"chromosome\" in df.columns, \"Check your df has the column named 'chromosome'\"\n",
    "    return df[\"chromosome\"].nunique()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9266675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a large piece of string of the whole state_seq_full \n",
    "# CSS: chromatin-state sequence\n",
    "\n",
    "def df2css_allchr(df):\n",
    "    \n",
    "    \"\"\"Create a large piece of string of the whole state_seq_full \n",
    "    This function generates a string from the entire chromosomes\"\"\"\n",
    "    \n",
    "    state_seq_full_list=df[\"state_seq_full\"].tolist()\n",
    "    state_seq_full_to_str=''.join([elm for elm in state_seq_full_list ])\n",
    "    return state_seq_full_to_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1ee94a",
   "metadata": {},
   "source": [
    "#### Create CSS chromosome-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d05d43a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, learn where one chromosome ends in the df\n",
    "# this is just a prerequisite function for df2css_chr\n",
    "\n",
    "def df2chr_index(df):\n",
    "    \n",
    "    \"\"\"Create a list of smaller piece of string of the state_seq_full per chromosome\n",
    "    This function generates a list of chromatin state sequence strings chromosome-wise\"\"\"\n",
    "    \n",
    "    total_row=len(df)\n",
    "    chr_len=[]\n",
    "    chr_check=[]\n",
    "    chr_index=[]\n",
    "\n",
    "    for i in range(total_row):\n",
    "        if (df[\"start\"].iloc[i]==0) & (i >0):\n",
    "            chr_len.append(df[\"end\"].iloc[i-1]) # chr_len stores the end position of each chromosome\n",
    "            chr_check.append(df[\"start\"].iloc[i]) # for assertion : later check chr_check are all zero\n",
    "            chr_index.append(i-1) # the index (row number)\n",
    "\n",
    "    end_len=df[\"end\"].iloc[-1] # add the final end position\n",
    "    end_index=total_row-1 # add the final end index (row number)\n",
    " \n",
    "    chr_len.append(end_len)\n",
    "    chr_index.append(end_index)\n",
    "\n",
    "    assert len(chr_len)==df[\"chromosome\"].nunique() #assert the length of the list corresponds to no. of chromosome\n",
    "    assert len(chr_index)==df[\"chromosome\"].nunique()\n",
    "    \n",
    "    return chr_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c84dab",
   "metadata": {},
   "source": [
    "#### Create df cut by each chromosome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "86e3b8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df2chr_df(df):\n",
    "   \n",
    "    \"\"\"Create a list of dataframes, each of which containing \n",
    "    the the whole expanded type of dataframe per chromosome\"\"\"\n",
    "    \n",
    "    start=0\n",
    "    df_chr_list=[]\n",
    "    chr_index=df2chr_index(df)\n",
    "    \n",
    "    for index in chr_index:\n",
    "        df_chr=df[start:index+1] # note that python [i:j] means from i to j-1\n",
    "        chr_name=df[\"chromosome\"].iloc[start] # string, such as chr1, chr2, ...\n",
    "        df_name='df_'+chr_name  # the chromosome-wise data stored like df_chr1, df_chr2, ...\n",
    "        locals()[df_name]=df_chr # make a string into a variable name\n",
    "        df_chr_list.append(df_chr)\n",
    "        start=index+1\n",
    "    \n",
    "    return df_chr_list   # elm is the df of each chromosome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebc9494",
   "metadata": {},
   "source": [
    "#### Create CSS chromosome-wise, string only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a4e82dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of dataframes, each of which contains the name of chromosome and chromosome-wise string of state_seq_full\n",
    "# This is prerequisite function for df2css_chr_string\n",
    "\n",
    "def df2css_chr(df):\n",
    "   \n",
    "    \"\"\"Create a list of dataframes, each of which containing \n",
    "    the chromosome name and the state_seq_full per chromosome (2 columns)\"\"\"\n",
    "    \n",
    "    start=0\n",
    "    df2col_chr_list=[]\n",
    "    chr_index=df2chr_index(df)\n",
    "    \n",
    "    for index in chr_index:\n",
    "        df_chr=df[[\"chromosome\",\"state_seq_full\"]][start:index+1] # note that python [i:j] means from i to j-1\n",
    "        chr_name=df[\"chromosome\"].iloc[start] # string, such as chr1, chr2, ...\n",
    "        df2col_name='df2col_'+chr_name  # the chromosome-wise data stored like df2col_chr1, df2col_chr2, ...\n",
    "        locals()[df2col_name]=df_chr # make a string into a variable name\n",
    "        df2col_chr_list.append(df_chr)\n",
    "        start=index+1\n",
    "    \n",
    "    return df2col_chr_list    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b631c09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df2css_chr_str(df):\n",
    "    \n",
    "    \"\"\"Create a list of strings which is the state_seq_full, all-connected per chromosome\"\"\"\n",
    "    \n",
    "    chr_index=df2chr_index(df)  \n",
    "    chr_index_num=len(chr_index) \n",
    "\n",
    "    df2col_chr_list=df2css_chr(df)  # contains a list of df: chromosome name, state_seq_full (2-column datafame)\n",
    "    chr_css_list=[]\n",
    "\n",
    "    for num in range(chr_index_num): \n",
    "        css_full_list=df2col_chr_list[num][\"state_seq_full\"].tolist()  # extract the state_seq_full only and make it a list\n",
    "        css_full_to_str=''.join([elm for elm in css_full_list]) # make it a long string of all-connected state_seq_full (chromosome-wise)\n",
    "        chr_css_list.append(css_full_to_str)\n",
    "    return chr_css_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926d5326",
   "metadata": {},
   "source": [
    "## 2-4. CSS string generation from dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9baebf5",
   "metadata": {},
   "source": [
    "### 2-4-1. Real length CSS\n",
    "\n",
    "#### Function: `df2longcss`\n",
    "* make a long string of the css (not using unit, but the **real** length)\n",
    "* ChrM is removed\n",
    "* chromosome-wise list\n",
    "* real length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "34358ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a long string of the css (not using unit, but the real length)\n",
    "\n",
    "# def df2longcss(df):\n",
    "#     df_lst_chr=df2chr_df(df)\n",
    "#     # remove the microchondria DNA from df_lst_chr\n",
    "#     if df_lst_chr[-3][\"chromosome\"].iloc[0]==\"chrM\":\n",
    "#         del df_lst_chr[-3]\n",
    "#         assert df_lst_chr[-3][\"chromosome\"].iloc[0]==\"chr22\"\n",
    "#     else:   \n",
    "#         assert df_lst_chr[-3][\"chromosome\"].iloc[0]==\"chr22\"\n",
    "    \n",
    "#     all_css=[]\n",
    "#     for i in range(len(df_lst_chr)):\n",
    "#         df_chr=df_lst_chr[i]\n",
    "#         css_chr=''\n",
    "#         for j in range(len(df_chr)):\n",
    "#             css_chr+=df_chr[\"length\"].iloc[j]*df_chr[\"state_seq\"].iloc[j]\n",
    "#         all_css.append(css_chr)  \n",
    "#     return all_css"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ecba6a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a long string of the css (not using unit, but the real length)\n",
    "# modified 4.July 2023, to support the case where ChromosomeM is not at -3, but -2\n",
    "\n",
    "def df2longcss(df):\n",
    "    df_lst_chr=df2chr_df(df)\n",
    "    # remove the microchondria DNA from df_lst_chr\n",
    "    if df_lst_chr[-3][\"chromosome\"].iloc[0]==\"chrM\":\n",
    "        del df_lst_chr[-3]\n",
    "#         assert df_lst_chr[-3][\"chromosome\"].iloc[0]==\"chr22\"\n",
    "    elif df_lst_chr[-2][\"chromosome\"].iloc[0]==\"chrM\":\n",
    "        del df_lst_chr[-2]\n",
    "#         assert df_lst_chr[-3][\"chromosome\"].iloc[0]==\"chr22\"\n",
    "    \n",
    "    all_css=[]\n",
    "    for i in range(len(df_lst_chr)):\n",
    "        df_chr=df_lst_chr[i]\n",
    "        css_chr=''\n",
    "        for j in range(len(df_chr)):\n",
    "            css_chr+=df_chr[\"length\"].iloc[j]*df_chr[\"state_seq\"].iloc[j]\n",
    "        all_css.append(css_chr)  \n",
    "    return all_css"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37700d4d",
   "metadata": {},
   "source": [
    "### 2-4-2. Unit-length CSS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6864ea",
   "metadata": {},
   "source": [
    "#### Function: `df2unitcss`\n",
    "\n",
    "* make a unit-length string of the css (not the real length, but **200-bp resolution unit**)\n",
    "* ChrM is removed\n",
    "* chromosome-wise list\n",
    "* unit length (chromatin is annotated per 200 bp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d57de8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a long string of the css (unit length, not the real length)\n",
    "\n",
    "def df2unitcss(df):\n",
    "    df_lst_chr=df2chr_df(df)\n",
    "    # remove the microchondria DNA from df_lst_chr\n",
    "    if df_lst_chr[-3][\"chromosome\"].iloc[0]==\"chrM\":\n",
    "        del df_lst_chr[-3]\n",
    "#         assert df_lst_chr[-3][\"chromosome\"].iloc[0]==\"chr22\"\n",
    "#     else:   \n",
    "#         assert df_lst_chr[-3][\"chromosome\"].iloc[0]==\"chr22\"\n",
    "    \n",
    "    all_unit_css=[]\n",
    "    for i in range(len(df_lst_chr)):\n",
    "        df_chr=df_lst_chr[i]\n",
    "        css_chr=''\n",
    "        for j in range(len(df_chr)):\n",
    "            css_chr+=df_chr[\"unit\"].iloc[j]*df_chr[\"state_seq\"].iloc[j]\n",
    "        all_unit_css.append(css_chr)  \n",
    "    return all_unit_css"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb479357",
   "metadata": {},
   "source": [
    "#### These are new functions (corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "382c65f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shorten_string(s, factor):\n",
    "    # This regular expression matches groups of the same character.\n",
    "    pattern = re.compile(r'(.)\\1*')\n",
    "\n",
    "    # This function will be used to replace each match.\n",
    "    def replacer(match):\n",
    "        # The group that was matched.\n",
    "        group = match.group()\n",
    "\n",
    "        # Calculate the new length, rounding as necessary.\n",
    "        new_length = round(len(group) / factor)\n",
    "\n",
    "        # Return the character repeated the new number of times.\n",
    "        return group[0] * new_length\n",
    "\n",
    "    # Use re.sub to replace each match in the string.\n",
    "    return pattern.sub(replacer, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6331c2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Convert2unitCSS_main_new(css_lst_all, unit=200):# should be either css_gene_lst_all or css_Ngene_lst_all\n",
    "    \"\"\"\n",
    "    Input: css_gene_lst_all or css_Ngene_lst_all, the list of chromosome-wise list of the css in genic, intergenic regions.\n",
    "    Output: css_gene_unit_lst_all or css_Ngene_unit_lst_all\n",
    "    \"\"\"\n",
    "    reduced_all=[]\n",
    "    for i in range(len(css_lst_all)):\n",
    "        reduced_chr=[]\n",
    "        for j in range(len(css_lst_all[i])):\n",
    "            reduced=shorten_string(css_lst_all[i][j], unit)\n",
    "            reduced_chr.append(reduced)\n",
    "        reduced_all.append(reduced_chr)\n",
    "    return reduced_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99d109d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816f2d88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e929ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33ca72a1",
   "metadata": {},
   "source": [
    "## 2-5. Chromatin State Statistics\n",
    "\n",
    "\n",
    "#### Function: `prop_data2df`\n",
    "\n",
    "* With 15th state (including 15ths state)\n",
    "* `'../database/conserv_overlap/'` contains the emission of the state (occupation of the state on the genome) \n",
    "* State distribution on genome across all the cell types\n",
    "* Mostly for visualization\n",
    "    <img src=\"./desc_img/prop_data2df.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0a3e3a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prop_data2df(path='../database/conserv_overlap/'):\n",
    "    file_list=[os.path.join(path, file) for file in os.listdir(path)]\n",
    "    \n",
    "    temp_df=pd.read_csv(file_list[0],sep='\\t', lineterminator='\\n')\n",
    "    init_col=pd.DataFrame(temp_df[\"state (Emission order)\"])\n",
    "    init_col=init_col.rename(columns={\"state (Emission order)\":\"state\"})\n",
    "    for file in file_list:\n",
    "        file_name=file.split('/')[3]\n",
    "        sample_name=file_name.split('_')[0]\n",
    "\n",
    "        prop_data=pd.read_csv(file, sep='\\t', lineterminator='\\n')\n",
    "        prop=prop_data[\"Genome %\"]\n",
    "        temp_df=pd.concat([init_col,prop], axis=1)\n",
    "        temp_df=temp_df.rename(columns={\"Genome %\":str(sample_name)})\n",
    "        init_col=temp_dfx\n",
    "    \n",
    "    # show the result df (first col=state, other col=samples)\n",
    "    temp_df.drop(temp_df.tail(1).index, inplace=True) # remove the last row (100%)\n",
    "    \n",
    "    # transposed and trimmed df (col+1=state no. row=samples)\n",
    "    trans_df=temp_df.T\n",
    "    trans_df.drop(trans_df.head(1).index, inplace=True)\n",
    "    trans_df.columns=temp_df[\"state\"].to_list()\n",
    "    \n",
    "    state_list=temp_df[\"state\"].to_list()\n",
    "    \n",
    "    ################### create a plot for genome proportion across cell types\n",
    "    fig=plt.figure(figsize=(9,5))\n",
    "    ax=fig.add_subplot(111)\n",
    "    for i in range(len(state_list)):\n",
    "        state=list(css_color_dict.keys())[i]\n",
    "        state_as_colname=list(trans_df.columns)[i]\n",
    "\n",
    "        color=tuple([elm/255 for elm in css_color_dict[state]])\n",
    "\n",
    "        bp=ax.boxplot(trans_df.iloc[:,i],widths=0.65,positions = [i+1], notch=True,patch_artist=True, \n",
    "                     boxprops=dict(facecolor=color, color=\"gray\"),whiskerprops=dict(color=\"gray\", linewidth=2),\n",
    "                     medianprops=dict(color=color, linewidth=2),\n",
    "                     capprops=dict(color=\"gray\", linewidth=2),\n",
    "                     flierprops=dict(markeredgecolor=color, markeredgewidth=1.5))\n",
    "    plt.xticks(list(range(1,16)),list(trans_df.columns))\n",
    "    plt.xlabel(\"Chromatin state\")\n",
    "    plt.ylabel(\"Genome [%]\\n across Different Cell Types\")\n",
    "    fig.autofmt_xdate(rotation=45)\n",
    "    plt.show()\n",
    "    ###################\n",
    "    \n",
    "    return temp_df, trans_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "de44156b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_df, trans_df=prop_data2df(path='../database/conserv_overlap/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20ab882",
   "metadata": {},
   "source": [
    "# 3. Cutting the chromatin state (Dataset Preparation)\n",
    "**[back to index](#Index)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe0bf89",
   "metadata": {},
   "source": [
    "## 3-1. Quiescent state distribution\n",
    "How Quiescent states are distributed on the whole genome?\n",
    "\n",
    "#### Function: `UnitCSS_Q_Dist`\n",
    "\n",
    "* Input: df, chromosome number\n",
    "* Output: `q_index` index of genome (not normalized) where Quiescent states are found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1c60ce67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index list for O state in unit-length css sequence:\n",
    "def UnitCSS_Q_Dist(df, chr_no=1):\n",
    "    all_unit_css=df2unitcss(df)\n",
    "    chr_unit_css=all_unit_css[chr_no]\n",
    "    q_index=[]\n",
    "    for i,state in enumerate(chr_unit_css):\n",
    "        if state==\"O\":\n",
    "            q_index.append(i)\n",
    "    ######## uncomment this block if you want to draw the histogram!\n",
    "#     fig=plt.figure(figsize=(8,4))\n",
    "#     plt.hist(q_index, 30, histtype=\"step\", color='orange')\n",
    "# #     sns.histplot(q_index, kde=False, color='orange', bins=30, element=\"step\", fill=False)\n",
    "\n",
    "#     plt.xlabel(\"Position\")\n",
    "#     plt.ylabel(\"number of 'O' state\")\n",
    "#     plt.show()\n",
    "    return q_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2175e482",
   "metadata": {},
   "source": [
    "#### Function: `all_chr_UnitCSS_Q_Dist(df, normalization=True)`\n",
    "\n",
    "* Input: df, normalization (T/F, default=T)\n",
    "* Output: list of list, the element of which is a list contains the position index of the Q state in a chromosome\n",
    "    * Normalization True: `all_chr_q_index_norm`\n",
    "    * Normalization False: `all_chr_q_index`\n",
    "* Graph (distribution histogram)\n",
    "<img src=\"./desc_img/all_chr_UnitCSS_Q_Dist.png\" width=\"400\" height=\"150\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "327e6cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_chr_UnitCSS_Q_Dist(df,normalization=True):\n",
    "    \n",
    "    \"\"\"\n",
    "    input: df (the dataframe acquired by bed2df_expanded function for a chromatin state bed file)\n",
    "    output: all_chr_q_index_norm (normalization ON) / all_chr_q_index (normalization OFF)\n",
    "    option: normalization (all chromosome length= 0 to 1 for drawing a dist. graph)\n",
    "    \"\"\"\n",
    "    \n",
    "    all_unit_css=df2unitcss(df)  # a list of unit-css of df sample, chromosome wise\n",
    "       \n",
    "    fig=plt.figure(figsize=(12,6))\n",
    "    ax = plt.subplot(111)\n",
    "    all_chr_q_index=[] # list of list (raw data)\n",
    "    all_chr_q_index_norm=[] # list of list (normalized data)\n",
    "    \n",
    "    for i in range(len(all_unit_css)):\n",
    "        q_index=UnitCSS_Q_Dist(df, chr_no=i)\n",
    "        all_chr_q_index.append(q_index)\n",
    "        \n",
    "        ########### normalization here ###########\n",
    "        q_index_norm=[elm/q_index[-1] for elm in q_index]\n",
    "        ##########################################\n",
    "        all_chr_q_index_norm.append(q_index_norm)\n",
    "        if i <=21:\n",
    "            chr_name=\"chr\"+str(i+1)\n",
    "        elif i==23:\n",
    "            chr_name=\"chrX\"\n",
    "        else:\n",
    "            chr_name=\"chrY\"\n",
    "\n",
    "        grad_color=plt.cm.coolwarm(i*10)\n",
    "#         ax.hist(q_index_norm, 100, color=grad_color, ec='white', alpha=0.5, label=chr_no)\n",
    "        ax.hist(q_index_norm, 50, color=grad_color, histtype=\"step\", label=chr_name)\n",
    "\n",
    "    ### show only the normalized disribution\n",
    "    box = ax.get_position()\n",
    "    ax.set_position([box.x0, box.y0, box.width * 0.8, box.height]) # Shrink current axis's height by 20% on the bottom\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.xlabel(\"Normalized Position\")\n",
    "    plt.ylabel(\"number of 'O' state\")\n",
    "    plt.grid(b=None)\n",
    "    \n",
    "    if normalization:\n",
    "        return all_chr_q_index_norm\n",
    "    else:\n",
    "        return all_chr_q_index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57854437",
   "metadata": {},
   "source": [
    "## 3-2. Cut the telomere region on CSS and save the file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bcb39c",
   "metadata": {},
   "source": [
    "### 3-2-1. Random cut\n",
    "**Pretrain data was generated by this function, and chromosome-wise data are saved at `database/wo_telo`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13a2023",
   "metadata": {},
   "source": [
    "#### Function: `chr_cssWOtelo_ranCUT_Kmer`\n",
    "\n",
    "* Cut the list of CSS into trainable size and save after trimming the telometer region \n",
    "    >1. Cut the telomere (50 units=10000 bp)\n",
    "    >2. Select the sample `df` and chromosome number `chr_no` to take\n",
    "    >3. Determine the range of random cut of the string (e.g. `100` to `2000`)\n",
    "    >4. Determine the `k` for making kmer\n",
    "    \n",
    "* Input: df,chr_no,num1=5,num2=510, k=3, weight_rn=False, v_name=\"v1.01\"\n",
    "> weight_rn `True`: 50% cut into 510, 50% cut randomly between 5 and 510 <br>\n",
    "> weight_rn `False` : 100% cut randomly between 5 and 510\n",
    "* Output file name: `k_wo_telo_v1.01.txt`, v1 stands for version 1 (considering telomere length) \n",
    "* Usage: `chr_cssWOtelo_ranCUT_Kmer(df,1,100,200,6)`\n",
    "\n",
    "* Version control (e.g. v1.01)\n",
    "     * v1: version 1, telomere length set at 50 units.\n",
    "     * .01: not weighted random, from 5 to 510 \n",
    "\n",
    ">*Output message* <br>\n",
    ">unit-length css of chr1 cut randomly(weighted range:5-510) for 3mer was saved at '../database/wo_telo/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c41e45c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "#    Chromosome-wise save     #\n",
    "###############################\n",
    "\n",
    "# randomly cut the string \n",
    "\n",
    "def chr_cssWOtelo_ranCUT_Kmer(df,chr_no,num1=5,num2=510, k=3, weight_rn=False, v_name=\"v1.01\"):\n",
    "    \"\"\"\n",
    "    Usage: chr_cssWOtelo_ranCUT_Kmer(df,chr_no,num1,num2, weight_rn, k, v_name)\n",
    "    \n",
    "    - df: expanded version of 1 sample bed file\n",
    "    - chr_no: no. of chromosome\n",
    "    - num1: cut range start\n",
    "    - num2: cut range end\n",
    "    - weight_rn: \n",
    "      if True: random with weighted, 50% of chance to be num2, 50% random between num1 and num2\n",
    "      if False: random between num1 and num2\n",
    "    - k: kmer\n",
    "    - v_name: version name to be used as a file name \n",
    "      (Conventionally, 01 was used for weighted_rn False, 02 for True\n",
    "       v1 just stands for telomere is set to be 50 unit)\n",
    "    \n",
    "    output: randomly cut w15 css for one chromosome unit-length css\n",
    "    \"\"\"\n",
    "    all_unit_css=df2unitcss(df)\n",
    "    ch1_unit_css=all_unit_css[chr_no]\n",
    "    ch1_unit_css_wotelo=ch1_unit_css[50:-50] #cut the telomere\n",
    "\n",
    "    splitted=[]\n",
    "    prev=0\n",
    "\n",
    "    ori_lst=[elm for elm in range(num1,num2+1)]   # list of num between num1 and num2\n",
    "    sin_lst=[num2]*len(ori_lst)   # list of all num2 (length is the same of ori_lst)\n",
    "    tot_lst=ori_lst+sin_lst\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        if weight_rn:\n",
    "            n=random.choice(tot_lst)\n",
    "\n",
    "        else:\n",
    "            n=random.randint(num1,num2)\n",
    "        \n",
    "        splitted.append(ch1_unit_css_wotelo[prev:prev+n])\n",
    "        prev=prev+n\n",
    "        if prev >= len(ch1_unit_css_wotelo)-1:\n",
    "            break\n",
    "   \n",
    "    ch1_unit_css_wotelo_kmer=[seq2kmer(item, k) for item in splitted]\n",
    "    \n",
    "      \n",
    "    path='../database/wo_telo/'\n",
    "    fn_base=\"chr\"+str(chr_no)+\"_\"+str(k)+\"_wo_telo_\"+v_name   # version 1.01_pre (Oct. 2022) : telo 50 unit, rn 200-1000\n",
    "                                                              # version 1.01 (Oct. 2022) : telo 50, rn 5 - 510\n",
    "    ext=\".txt\"\n",
    "          \n",
    "    fn=path+fn_base+ext  # file name\n",
    "\n",
    "    with open(fn,\"w\") as save_file:\n",
    "        save_file.write(\"\\n\".join(ch1_unit_css_wotelo_kmer))\n",
    "          \n",
    "    return print(\"unit-length css of chr{} cut randomly(weighted range:{}-{}) for {}mer was saved at {}\".format(chr_no, num1, num2, k,fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f96033a",
   "metadata": {},
   "source": [
    "#### Function: `cell_cssWOtelo_ranCUT_Kmer`\n",
    "\n",
    "* Conduct the same work but now cell-wise, not chromosome-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfe4b0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "#    Cell-wise save     #\n",
    "###############################\n",
    "\n",
    "# randomly cut the string \n",
    "\n",
    "def cell_cssWOtelo_ranCUT_Kmer(all_file_path=all_files, cell_num=0, num1=5,num2=510, k=4, weight_rn=False, v_name=\"v1.01\"):\n",
    "    \"\"\"\n",
    "    Usage: chr_cssWOtelo_ranCUT_Kmer(df,chr_no,num1,num2, weight_rn, k, v_name)\n",
    "    \n",
    "    - all_file_path: the list of all_files (see css_utility)\n",
    "    - cell_num: the number of cell in the list of all_files\n",
    "    - num1: cut range start\n",
    "    - num2: cut range end\n",
    "    - weight_rn: \n",
    "      if True: random with weighted, 50% of chance to be num2, 50% random between num1 and num2\n",
    "      if False: random between num1 and num2\n",
    "    - k: kmer\n",
    "    \n",
    "    output: randomly cut w15 css for one chromosome unit-length css\n",
    "    \"\"\"\n",
    "    target_cell=all_file_path[cell_num]\n",
    "    cell_id=target_cell.split(\"/\")[-1].split(\"_\")[1]\n",
    "    assert type(cell_id)==str,\"Check the all_file path\"\n",
    "    \n",
    "    df=bed2df_expanded(target_cell)    \n",
    "    all_unit_css=df2unitcss(df)\n",
    "    all_chr=len(all_unit_css)\n",
    "    \n",
    "    all_chr_unit_css_wotelo_kmer=[]\n",
    "    \n",
    "    for chr_no in range(all_chr):        \n",
    "    \n",
    "        chr_unit_css=all_unit_css[chr_no]\n",
    "        chr_unit_css_wotelo=chr_unit_css[50:-50] #cut the telomere\n",
    "\n",
    "        splitted=[]\n",
    "        prev=0\n",
    "\n",
    "        ori_lst=[elm for elm in range(num1,num2+1)]   # list of num between num1 and num2\n",
    "        sin_lst=[num2]*len(ori_lst)   # list of all num2 (length is the same of ori_lst)\n",
    "        tot_lst=ori_lst+sin_lst\n",
    "\n",
    "        while True:\n",
    "\n",
    "            if weight_rn:\n",
    "                n=random.choice(tot_lst)\n",
    "\n",
    "            else:\n",
    "                n=random.randint(num1,num2)\n",
    "\n",
    "            splitted.append(chr_unit_css_wotelo[prev:prev+n])\n",
    "            prev=prev+n\n",
    "            if prev >= len(chr_unit_css_wotelo)-1:\n",
    "                break\n",
    "\n",
    "        chr_unit_css_wotelo_kmer=[seq2kmer(item, k) for item in splitted]\n",
    "        all_chr_unit_css_wotelo_kmer.append(chr_unit_css_wotelo_kmer)\n",
    "        \n",
    "    all_unit_css_wotelo_kmer=flatLst(all_chr_unit_css_wotelo_kmer)\n",
    "    \n",
    "    path='../database/wo_telo/'\n",
    "    fn_base=\"cell\"+cell_id+\"_\"+str(k)+\"_wo_telo_\"+v_name   # version 1.01_pre (Oct. 2022) : telo 50 unit, rn 200-1000\n",
    "                                                              # version 1.01 (Oct. 2022) : telo 50, rn 5 - 510\n",
    "    ext=\".txt\"\n",
    "          \n",
    "    fn=path+fn_base+ext  # file name\n",
    "\n",
    "    with open(fn,\"w\") as save_file:\n",
    "        save_file.write(\"\\n\".join(all_unit_css_wotelo_kmer))\n",
    "    \n",
    "    \n",
    "    return print(\"unit-length css of cell ID {} cut randomly(weighted range:{}-{}) for {}mer was saved at {}\".format(cell_id, num1, num2, k,fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69d81ad",
   "metadata": {},
   "source": [
    "### 3-2-1. Kmerized data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f965c7",
   "metadata": {},
   "source": [
    "#### Function: `dataLengCompo`\n",
    "* Input: data path, k (of kmer), color, bins, dna or not (default=false)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bd4010a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataLengCompo(path, k, color=\"teal\", bins=15, dna=False):\n",
    "    \"\"\"\n",
    "    Create a histogram of data length (elements before k-merization in the training dataset list)\n",
    "    \"\"\"\n",
    "    file_name=path\n",
    "    with open(file_name) as f:\n",
    "        len_lst=[]\n",
    "        for line_no, line in enumerate(f):\n",
    "            if dna:\n",
    "                line_len=int((len(line)-1)/k)+(k-1)  # -1 comes from the space only between DNA sequence kmer\n",
    "                if line_len!=0:\n",
    "                    len_lst.append(line_len)               \n",
    "            else:\n",
    "                line_len=int(len(line)/(k+1))+(k-1)  # reduced \n",
    "#                 line_len=int(len(line)/(k+1))*k # +1 comes from the space after the kmers\n",
    "                len_lst.append(line_len)\n",
    "                \n",
    "    fig=plt.figure(figsize=(6,4))\n",
    "    \n",
    "    s=sns.histplot(len_lst, kde=False, color=color, log_scale=True, bins=bins, element=\"step\", fill=False)\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.xlabel(\"Length of each element in training dataset\", fontsize=12)\n",
    "    plt.xlim([1,10000])\n",
    "    plt.show()\n",
    "    return  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd68457",
   "metadata": {},
   "source": [
    "## 3-3. Cut the chromatin states : genic or non-genic area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb0de6d",
   "metadata": {},
   "source": [
    "### 3-3-1. Genic area\n",
    "#### Function: `compGene2css`\n",
    "\n",
    "* Input: whole_gene_file, df\n",
    "* Output: `css_gene_lst_all` list of list that css for genic region per chromosome (which can be utilized very frequently after this)\n",
    "* The output is pickled as `\"../database/temp_files/css_gene_lst_all\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cd6b065c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def shorten_string(s, factor):\n",
    "#     # This regular expression matches groups of the same character.\n",
    "#     pattern = re.compile(r'(.)\\1*')\n",
    "\n",
    "#     # This function will be used to replace each match.\n",
    "#     def replacer(match):\n",
    "#         # The group that was matched.\n",
    "#         group = match.group()\n",
    "\n",
    "#         # Calculate the new length, rounding as necessary.\n",
    "#         new_length = round(len(group) / factor)\n",
    "\n",
    "#         # Return the character repeated the new number of times.\n",
    "#         return group[0] * new_length\n",
    "\n",
    "#     # Use re.sub to replace each match in the string.\n",
    "#     return pattern.sub(replacer, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e46b6f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Convert2unitCSS_main_new(css_lst_all, unit=200):# should be either css_gene_lst_all or css_Ngene_lst_all\n",
    "#     \"\"\"\n",
    "#     Input: css_gene_lst_all or css_Ngene_lst_all, the list of chromosome-wise list of the css in genic, intergenic regions.\n",
    "#     Output: css_gene_unit_lst_all or css_Ngene_unit_lst_all\n",
    "#     \"\"\"\n",
    "#     reduced_all=[]\n",
    "#     for i in range(len(css_lst_all)):\n",
    "#         reduced_chr=[]\n",
    "#         for j in range(len(css_lst_all[i])):\n",
    "#             reduced=shorten_string(css_lst_all[i][j], unit)\n",
    "#             reduced_chr.append(reduced)\n",
    "#         reduced_all.append(reduced_chr)\n",
    "#     return reduced_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "499a7618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compGene2css(whole_gene_file,df):   # note that the result is also overlapped css... >>rewrite it with gene_removeDupl!\n",
    "#     \"\"\"\n",
    "#     Input: Reference gene file, df (CSS)\n",
    "#     Output: list of chromosome-wise list that contains the css at genic area only.\n",
    "#     \"\"\"\n",
    "#     g_lst_chr=whGene2GLChr(whole_gene_file) # list of gene table df per chromosome\n",
    "#     css_lst_chr=df2longcss(df) # list of long css per chromosome\n",
    "#     total_chr=len(g_lst_chr)\n",
    "    \n",
    "#     css_gene_lst_all=[]\n",
    "#     for i in tqdm_notebook(range(total_chr)):\n",
    "#         css=css_lst_chr[i]   # long css of i-th chromosome\n",
    "#         gene_df=g_lst_chr[i] # gene df of i-th chromosome\n",
    "        \n",
    "#         css_gene_lst_chr=[]\n",
    "#         for j in range(len(gene_df)):\n",
    "#             g_start=gene_df[\"TxStart\"].iloc[j]-1  # python counts form 0\n",
    "#             g_end=gene_df[\"TxEnd\"].iloc[j]+1      # python excludes the end\n",
    "            \n",
    "#             css_gene=css[g_start:g_end]           # cut the gene area only\n",
    "#             css_gene_lst_chr.append(css_gene)     # store in the list\n",
    "          \n",
    "#         css_gene_lst_all.append(css_gene_lst_chr)  # list of list\n",
    "    \n",
    "#     assert len(css_gene_lst_all)==total_chr\n",
    "#     return css_gene_lst_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e30547ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compGene2css(whole_gene_file,df):   # fixed June. 29. 2023\n",
    "    \"\"\"\n",
    "    Input: Reference gene file, df (CSS)\n",
    "    Output: list of chromosome-wise list that contains the css at genic area only.\n",
    "    \"\"\"\n",
    "#     g_lst_chr=whGene2GLChr(whole_gene_file) # list of gene table df per chromosome\n",
    "    \n",
    "    ########### new fancy gene table without overlap ###########\n",
    "#     g_lst_chr=gene_removeDupl(whole_gene_file) #### fixed June. 29. 2023\n",
    "    g_df_chr_lst=whGene2GLChr(whole_gene_file) #### fixed June. 29. 2023\n",
    "    g_lst_chr=merge_intervals(g_df_chr_lst) #### fixed June. 29. 2023\n",
    "    ############################################################\n",
    "    \n",
    "    css_lst_chr=df2longcss(df) # list of long css per chromosome\n",
    "    total_chr=len(g_lst_chr)\n",
    "    \n",
    "    css_gene_lst_all=[]\n",
    "    for i in tqdm_notebook(range(total_chr)):\n",
    "        css=css_lst_chr[i]   # long css of i-th chromosome\n",
    "        gene_df=g_lst_chr[i] # gene df of i-th chromosome\n",
    "        \n",
    "        css_gene_lst_chr=[]\n",
    "        for j in range(len(gene_df)):\n",
    "            g_start=gene_df[\"TxStart\"].iloc[j]-1  # python counts form 0\n",
    "            g_end=gene_df[\"TxEnd\"].iloc[j]+1      # python excludes the end\n",
    "            \n",
    "            css_gene=css[g_start:g_end]           # cut the gene area only\n",
    "            css_gene_lst_chr.append(css_gene)     # store in the list\n",
    "          \n",
    "        css_gene_lst_all.append(css_gene_lst_chr)  # list of list\n",
    "    \n",
    "    assert len(css_gene_lst_all)==total_chr\n",
    "    return css_gene_lst_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d6ba42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d62a9ef0",
   "metadata": {},
   "source": [
    "#### Function: `pickled_df2gene_unit_css`\n",
    "\n",
    "* This function is already executed and no need to rerun.\n",
    "* This function saves the all genic region in ROADMAP data in unit css \n",
    "* Input: `df_pickled_path=\"../database/roadmap/df_pickled/\"`, `output_path=\"../database/roadmap/\"`\n",
    "* The output is pickled under the output path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2bc77a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickled_df2gene_unit_css(df_pickled_path=\"../database/roadmap/df_pickled/\", output_path=\"../database/roadmap/\", verbose=True):\n",
    "    \"\"\"\n",
    "    Save unit CSS into Genic, for the entire 127 epigenomes\n",
    "    \"\"\"\n",
    "    df_pickled_files = [os.path.join(df_pickled_path, df) for df in sorted(os.listdir(df_pickled_path))]\n",
    "    \n",
    "    def load_pickled_df(df_pickled_file):\n",
    "        with open(df_pickled_file, \"rb\") as f:\n",
    "            df = pickle.load(f)\n",
    "        return df\n",
    "    \n",
    "    for file in df_pickled_files:\n",
    "        cell_id = file.split(\"/\")[-1][:4]          \n",
    "\n",
    "        gene_output_name = output_path +\"gene_css_unit_pickled/\"+ cell_id + \"_gene_css_pickled.pkl\"\n",
    "        df=load_pickled_df(file)\n",
    "\n",
    "        css_gene_lst_all=compGene2css(whole_gene_file,df)\n",
    "        css_gene_unit_lst_all=Convert2unitCSS_main(css_gene_lst_all, unit=200)\n",
    "\n",
    "        with open(gene_output_name, 'wb') as g:\n",
    "            pickle.dump(css_gene_unit_lst_all, g)\n",
    "\n",
    "        if verbose:\n",
    "            print(cell_id+\" is done\")\n",
    "\n",
    "    return print(\"All done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41196d56",
   "metadata": {},
   "source": [
    "#### Function: `countGeneCss`\n",
    "* How many css data strips are in the Non-genic (intergenic) region?\n",
    "* How long each css data strips are in the Non-genic (intergenic) region?\n",
    "* Input: `css_gene_lst_all`, the result list from `compGene2css(whole_gene_file,df)`. (Also pickled at `\"../database/temp_files/css_gene_lst_all\"`\n",
    "* Output: Two lists (`g_css_cnt_all` and `g_css_len_all`) and their distribution histogram\n",
    "\n",
    "<img src=\"./desc_img/countGeneCss.png\" width=\"600\" height=\"300\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b607cc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def countGeneCss(css_gene_lst_all):\n",
    "    g_css_cnt_all=[]\n",
    "    g_css_len_all=[]\n",
    "    tot_chr=len(css_gene_lst_all)\n",
    "    for chr_no in range(tot_chr):\n",
    "        g_chr_lst=css_gene_lst_all[chr_no]\n",
    "        g_css_cnt_all.append(len(g_chr_lst))\n",
    "        g_css_len_chr=[]\n",
    "        for i in range(len(g_chr_lst)):\n",
    "            g_css_len=len(g_chr_lst[i])\n",
    "            g_css_len_chr.append(g_css_len)  # to let it iterate for chr!\n",
    "        g_css_len_all.append(g_css_len_chr)\n",
    "    g_css_len_all=flatLst(g_css_len_all) \n",
    "    \n",
    "    g_css_len_all=list(filter(lambda elm: elm!=0, g_css_len_all))  # remove 0s\n",
    "        \n",
    "    # visualization for ng_css_cnt_all (no. of data strips per chromosome)\n",
    "    fig,(ax1, ax2)=plt.subplots(1,2,figsize=(12,4), sharey=False)\n",
    "    ax1=sns.histplot(g_css_cnt_all, bins=12, color=\"cadetblue\", element=\"step\", fill=False, ax=ax1)\n",
    "    ax1.set_xlabel(\"Count of data strip on Genic region\", fontsize=13)\n",
    "    ax1.set_ylabel(\"Count\", fontsize=13)\n",
    "    ax1.grid(b=None)\n",
    "    ax1.xaxis.grid(None)\n",
    "    ax1.yaxis.grid()\n",
    "    \n",
    "    # visualization for ng_css_cnt_all (no. of data strips per chromosome)\n",
    "    ax2=sns.histplot(g_css_len_all, bins=15, log_scale=True, color=\"crimson\", element=\"step\", fill=False, ax=ax2)\n",
    "    ax2.set_xlabel(\"Length of CSS on Genic region\", fontsize=13)\n",
    "    ax2.set_ylabel(\"Count\", fontsize=13)\n",
    "    ax2.grid(b=None)\n",
    "    plt.grid(False)\n",
    "            \n",
    "    return g_css_cnt_all,g_css_len_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6661bb7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a69027e1",
   "metadata": {},
   "source": [
    "### 3-3-2. Non-genic area (intergenic region)\n",
    "\n",
    "* The problem in evaluating the intergenic region is that the positions of genes are frequently duplicated. Therefore, the gene table shares lots of same start and end position.\n",
    "    1. First, we need to take a look how many genes are duplicated at the start and end position.\n",
    "    2. Second, gene table has been collapsed to remove the overlaps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81495f86",
   "metadata": {},
   "source": [
    "#### Function: `count_samePos` (To take a look how many genes are overlapped)\n",
    "* Input: `whole_gene_file='../database/RefSeq/RefSeq.WholeGene.bed'`\n",
    "* Output: 2 dataframes (`df_cnt` and `df_pro`) and visualization for them in violin plot\n",
    "    * `df_cnt` : Chromosome-wise list of the count of the duplicated gene Start and End position on genome\n",
    "    * `df_pro` : Chromosome-wise list of the proportion of the duplicated gene Start and End position on genome (per gene)    \n",
    "    \n",
    "<img src=\"./desc_img/gene_dup_start_end_vis.png\" width=\"500\" height=\"200\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "82db0a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to visualize how many genes are sharing the start and end position on genome\n",
    "\n",
    "def count_samePos(whole_gene_file='../database/RefSeq/RefSeq.WholeGene.bed'):\n",
    "    g_df_chr_lst=whGene2GLChr(whole_gene_file)\n",
    "    cnt_same_start_all=[]\n",
    "    pro_same_start_all=[]\n",
    "    cnt_same_end_all=[]\n",
    "    pro_same_end_all=[]\n",
    "    tot_chr_no=len(g_df_chr_lst)\n",
    "    \n",
    "    ########### count the same start position ###########\n",
    "    def count_sameStart(g_df_chr_lst,chr_no):\n",
    "        cnt_same_start=0\n",
    "        tot_start=len(g_df_chr_lst[chr_no])\n",
    "        for i in range(len(g_df_chr_lst[chr_no])):\n",
    "            chr1=g_df_chr_lst[chr_no][\"TxStart\"]\n",
    "            if i==0:\n",
    "                continue\n",
    "            elif chr1.iloc[i]==chr1.iloc[i-1]:\n",
    "                cnt_same_start+=1  # how many same start in rows\n",
    "            else:\n",
    "                continue\n",
    "        prop_same_start=cnt_same_start/tot_start\n",
    "        return cnt_same_start, prop_same_start\n",
    "    \n",
    "    ########### count the same end position ############\n",
    "    def count_sameEnd(g_df_chr_lst,chr_no):\n",
    "        cnt_same_end=0\n",
    "        tot_end=len(g_df_chr_lst[chr_no])\n",
    "        for i in range(len(g_df_chr_lst[chr_no])):\n",
    "            chr1=g_df_chr_lst[chr_no][\"TxEnd\"]       \n",
    "            if i==0:\n",
    "                continue\n",
    "            elif chr1.iloc[i]==chr1.iloc[i-1]:\n",
    "                cnt_same_end+=1  # how many same start in rows\n",
    "            else:\n",
    "                continue\n",
    "        prop_same_end=cnt_same_end/tot_end\n",
    "        return cnt_same_end, prop_same_end\n",
    "    ####################################################\n",
    "    \n",
    "    for chr_no in tqdm_notebook(range(tot_chr_no)):\n",
    "        cnt_same_start, prop_same_start = count_sameStart(g_df_chr_lst,chr_no)\n",
    "        cnt_same_end, prop_same_end = count_sameEnd(g_df_chr_lst,chr_no)\n",
    "        \n",
    "        cnt_same_start_all.append(cnt_same_start)\n",
    "        pro_same_start_all.append(prop_same_start)\n",
    "        cnt_same_end_all.append(cnt_same_end)\n",
    "        pro_same_end_all.append(prop_same_end)\n",
    "        \n",
    "    dict_cnt={\"cnt_same_start\":cnt_same_start_all, \"cnt_same_end\":cnt_same_end_all}\n",
    "    dict_pro={\"pro_same_start\":pro_same_start_all, \"pro_same_end\":pro_same_end_all}\n",
    "    df_cnt=pd.DataFrame(dict_cnt)\n",
    "    df_pro=pd.DataFrame(dict_pro)\n",
    "    \n",
    "    ###### Visualization ######\n",
    "    fig, (ax1,ax2) = plt.subplots(1,2,figsize=(10,5), sharey=False)\n",
    "    ax1=sns.violinplot(data=df_cnt, palette=\"pastel\", linewidth=0.7, saturation=0.5, ax=ax1)\n",
    "    ax1.set_ylabel(\"Count\", fontsize=15)\n",
    "    ax2=sns.violinplot(data=df_pro, palette=\"husl\", linewidth=0.7, saturation=0.5, ax=ax2)\n",
    "    ax2.set_ylim([0.2,0.8])\n",
    "    ax2.set_ylabel(\"Proportion\", fontsize=15)\n",
    "    plt.show()\n",
    "\n",
    "    return df_cnt, df_pro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09167c5",
   "metadata": {},
   "source": [
    "#### Function: `removeOverlapDF` and `gene_removeDupl`\n",
    "\n",
    "* Main function: `gene_removeDupl`\n",
    "* `removeOverlapDF`: function used inside the main function.\n",
    "* To acquire final collapsed gene table, run `gene_removeDupl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "148fd1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeOverlapDF(test_df):    \n",
    "    new_lst=[]\n",
    "    for i in range(len(test_df)):\n",
    "        start=test_df[\"TxStart\"].iloc[i]\n",
    "        end=test_df[\"TxEnd\"].iloc[i]\n",
    "\n",
    "        exist_pair=(start,end)\n",
    "\n",
    "        if i==0:\n",
    "            new_pair=exist_pair\n",
    "            new_lst.append(new_pair)        \n",
    "        else:\n",
    "            start_pre=test_df[\"TxStart\"].iloc[i-1]\n",
    "            end_pre=test_df[\"TxEnd\"].iloc[i-1]\n",
    "\n",
    "            # first, concatenate all the shared start\n",
    "            if start==start_pre:\n",
    "                new_end=max(end, end_pre)\n",
    "                new_pair=(start, new_end)\n",
    "            # second, concatenate all the shared end\n",
    "            elif end==end_pre:\n",
    "                new_start=min(start, start_pre)\n",
    "                new_pair=(new_start, end)\n",
    "            else:    \n",
    "                new_pair=exist_pair\n",
    "\n",
    "        new_lst.append(new_pair) \n",
    "    new_lst=list(dict.fromkeys(new_lst))\n",
    "    \n",
    "    mod_lst=[[start, end] for (start, end) in new_lst] # as a list element\n",
    "\n",
    "    for j, elm in enumerate(mod_lst):\n",
    "        start, end = elm[0], elm[1]\n",
    "\n",
    "        if j==0:\n",
    "            continue\n",
    "        else:\n",
    "            start_pre=mod_lst[j-1][0]\n",
    "            end_pre=mod_lst[j-1][1]\n",
    "\n",
    "            if end_pre>=end:\n",
    "                mod_lst[j][0]=mod_lst[j-1][0]  # if end_pre is larger than end, replace start as start_pre\n",
    "                mod_lst[j][1]=mod_lst[j-1][1]  # if end_pre is larger than end, replace end as end_pre\n",
    "\n",
    "            elif start <=end_pre:\n",
    "                mod_lst[j][0]=mod_lst[j-1][0]  # current start=start_pre\n",
    "                mod_lst[j-1][1]=max(mod_lst[j][1],mod_lst[j-1][1])  # end_pre = end\n",
    "\n",
    "            else:\n",
    "                continue\n",
    "           \n",
    "    mod_lst=[tuple(elm) for elm in mod_lst]\n",
    "    fin_lst=list(dict.fromkeys(mod_lst))\n",
    "    gene_collapsed_df=pd.DataFrame(fin_lst, columns=[\"TxStart\", \"TxEnd\"])\n",
    " \n",
    "    return gene_collapsed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3ce0120f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gene_removeDupl(whole_gene_file='../database/RefSeq/RefSeq.WholeGene.bed'):\n",
    "    g_df_chr_lst=whGene2GLChr(whole_gene_file)\n",
    "    new_gene_lst_all=[]\n",
    "    for chr_no in range(len(g_df_chr_lst)):\n",
    "        gene_df=g_df_chr_lst[chr_no]\n",
    "        gene_collapsed_df=removeOverlapDF(gene_df)\n",
    "        new_gene_lst_all.append(gene_collapsed_df)\n",
    "    return new_gene_lst_all # list of chromosome-wise dataframe for collapsed gene table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7426ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ff094f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Merging the gene table #### modified June. 29. 2023\n",
    "\n",
    "def merge_intervals(df_list):\n",
    "    merged_list = []  # List to hold merged DataFrames\n",
    "\n",
    "    for df in df_list:\n",
    "        # Sort by 'TxStart'\n",
    "        df = df.sort_values(by='TxStart')\n",
    "\n",
    "        # Initialize an empty list to store the merged intervals\n",
    "        merged = []\n",
    "\n",
    "        # Iterate through the rows in the DataFrame\n",
    "        for _, row in df.iterrows():\n",
    "            # If the list of merged intervals is empty, or the current interval does not overlap with the previous one,\n",
    "            # append it to the list\n",
    "            if not merged or merged[-1]['TxEnd'] < row['TxStart']:\n",
    "                merged.append({'TxStart': row['TxStart'], 'TxEnd': row['TxEnd']})  # Only keep 'TxStart' and 'TxEnd'\n",
    "            else:\n",
    "                # Otherwise, there is an overlap, so we merge the current and previous intervals\n",
    "                merged[-1]['TxEnd'] = max(merged[-1]['TxEnd'], row['TxEnd'])\n",
    "\n",
    "        # Convert the merged intervals back into a DataFrame and append it to the list\n",
    "        merged_list.append(pd.DataFrame(merged))\n",
    "\n",
    "    return merged_list  # a list of DF, containing only TxStart and TxEnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1ed3a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6eeed7e",
   "metadata": {},
   "source": [
    "#### Function: `compNonGene2css`\n",
    "* This function extracts the css on the non-genic (intergenic) area of the genome.\n",
    "* The function `gene_removeDupl` was used here, for extracting the non-genic region index.\n",
    "* Input: `whole_gene_file` and `df` (from the css bed file)\n",
    "* Output: `css_Ngene_lst_all` The CSS on the non-genic region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30387822",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### fixed June 29. 2023\n",
    "def compNonGene2css(whole_gene_file,df): \n",
    "    \"\"\"\n",
    "    Input: Reference gene file, df (CSS)\n",
    "    Output: list of chromosome-wise list that contains the css at \"non-genic\" area only.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Extracting the CSS on the intergenic region ...\")\n",
    "\n",
    "    ########### new fancy gene table without overlap ###########\n",
    "#     new_gene_lst_all=gene_removeDupl(whole_gene_file) ##### fixed June 29. 2023\n",
    "    g_df_chr_lst=whGene2GLChr(whole_gene_file)  ##### fixed June 29. 2023\n",
    "    new_gene_lst_all=merge_intervals(g_df_chr_lst) ##### fixed June 29. 2023\n",
    "    ############################################################\n",
    "    \n",
    "    css_lst_chr=df2longcss(df) # list of long css per chromosome\n",
    "    total_chr=len(new_gene_lst_all)\n",
    "    \n",
    "    css_Ngene_lst_all=[]\n",
    "        \n",
    "    for i in tqdm_notebook(range(total_chr)):\n",
    "        css=css_lst_chr[i]   # long css of i-th chromosome\n",
    "        gene_df=new_gene_lst_all[i] # gene df of i-th chromosome\n",
    "        \n",
    "#         assert gene_df[\"TxStart\"].iloc[0]>=1, \"Gene starts from the very first location at {}-th chromosome.\".format(i)\n",
    "#         assert gene_df[\"TxEnd\"].iloc[-1]<=len(css), \"Gene ends at the very last location at {}-th chromosome.\".format(i)  \n",
    "        ### asertion was removed because it produces an error when trying to apply to cells without Y chr.        \n",
    "    \n",
    "        css_Ngene_lst_chr=[]        \n",
    "        for j in range(len(gene_df)):\n",
    "            if j==0:\n",
    "                ng_start=1 # to avoid any \"zero\" causing problem \n",
    "                ng_end=gene_df[\"TxStart\"].iloc[j]\n",
    "#                 print(\"j: {} | ng_start: {} - ng_end: {} \".format(j, ng_start, ng_end)) # for checking\n",
    "            elif j==len(gene_df)-1: \n",
    "                ng_start=gene_df[\"TxEnd\"].iloc[j]\n",
    "                ng_end=len(css)\n",
    "#                 print(\"j: {} | ng_start: {} - ng_end: {} \".format(j, ng_start, ng_end)) # for checking\n",
    "            else:\n",
    "                ng_start=gene_df[\"TxEnd\"].iloc[j-1]\n",
    "                ng_end=gene_df[\"TxStart\"].iloc[j]\n",
    "#                 print(\"j: {} | ng_start: {} - ng_end: {} \".format(j, ng_start, ng_end)) # for checking \n",
    "        \n",
    "            css_Ngene=css[ng_start:ng_end]\n",
    "            css_Ngene_lst_chr.append(css_Ngene)\n",
    "        \n",
    "        css_Ngene_lst_all.append(css_Ngene_lst_chr) \n",
    "        \n",
    "    assert len(css_Ngene_lst_all)==total_chr\n",
    "    print(\"Done!\")\n",
    "    \n",
    "    return css_Ngene_lst_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12918d70",
   "metadata": {},
   "source": [
    "#### Function: `countNgeneCss`\n",
    "* How many css data strips are in the Non-genic (intergenic) region?\n",
    "* How long each css data strips are in the Non-genic (intergenic) region?\n",
    "* Input: `css_Ngene_lst_all`, the result list from `compNonGene2css(whole_gene_file,df)`. (Also pickled at `\"../database/temp_files/css_Ngene_lst_all\"`\n",
    "* Output: Two lists (`ng_css_cnt_all` and `ng_css_len_all`) and their distribution histogram\n",
    "\n",
    "<img src=\"./desc_img/countNgeneCss.png\" width=\"600\" height=\"300\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "99f2a2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def countNgeneCss(css_Ngene_lst_all):\n",
    "    ng_css_cnt_all=[]\n",
    "    ng_css_len_all=[]\n",
    "    tot_chr=len(css_Ngene_lst_all)\n",
    "    for chr_no in range(tot_chr):\n",
    "        ng_chr_lst=css_Ngene_lst_all[chr_no]\n",
    "        ng_css_cnt_all.append(len(ng_chr_lst))\n",
    "        ng_css_len_chr=[]\n",
    "        for i in range(len(ng_chr_lst)):\n",
    "            ng_css_len=len(ng_chr_lst[i])\n",
    "            ng_css_len_chr.append(ng_css_len)  # to let it iterate for chr!\n",
    "        ng_css_len_all.append(ng_css_len_chr)\n",
    "    ng_css_len_all=flatLst(ng_css_len_all) \n",
    "    \n",
    "    ng_css_len_all=list(filter(lambda elm: elm!=0, ng_css_len_all))  # remove 0s\n",
    "        \n",
    "    # visualization for ng_css_cnt_all (no. of data strips per chromosome)\n",
    "    fig,(ax1, ax2)=plt.subplots(1,2,figsize=(12,4), sharey=False)\n",
    "    ax1=sns.histplot(ng_css_cnt_all, bins=12, color=\"navy\", element=\"step\", fill=False, ax=ax1)\n",
    "    ax1.set_xlabel(\"Count of data strip on Intergenic region\", fontsize=13)\n",
    "    ax1.set_ylabel(\"Count\", fontsize=13)\n",
    "    ax1.grid(b=None)\n",
    "    ax1.xaxis.grid(None)\n",
    "    ax1.yaxis.grid()\n",
    "    \n",
    "    # visualization for ng_css_cnt_all (no. of data strips per chromosome)\n",
    "    ax2=sns.histplot(ng_css_len_all, bins=15, log_scale=True, color=\"maroon\", element=\"step\", fill=False, ax=ax2)\n",
    "    ax2.set_xlabel(\"Length of CSS on Intergenic region\", fontsize=13)\n",
    "    ax2.set_ylabel(\"Count\", fontsize=13)\n",
    "    ax2.grid(b=None)\n",
    "    plt.grid(False)\n",
    "            \n",
    "    return ng_css_cnt_all,ng_css_len_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edd56eb",
   "metadata": {},
   "source": [
    "### 3-3-3. Genic or Non-genic raw-length CSS to unit-length CSS\n",
    "\n",
    "* For the genic and intergenic region, the css is the raw length, not the unit length. To keep the same training data condition, the data should be formed as unit length (200-bp).\n",
    "* So, the purpose is to convert `css_Ngene_lst_all` and `css_gene_lst_all` into the unit-length version of them.\n",
    "* To do this job, 2 functions are required : `long2unitCSS` and `Convert2unitCSS_main`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f9f16f",
   "metadata": {},
   "source": [
    "#### Function (preliminary) : `long2unitCSS` (included in the main function)\n",
    "\n",
    "* As the **preliminary** function, `long2unitCSS`, investigates \n",
    "    1. The sequence of the state (letter) appears -> as a list of string\n",
    "    2. How many times the state appears -> as a list of list (numbers)   \n",
    "\n",
    "* Input: `long_css_lst` which is a list of string.\n",
    "\n",
    "* Output\n",
    "    1. `let_str_lst_all`: The list of string that only shows the sequence of the css \n",
    "    2. `unit_cnt_lst_all`: The list of list of unit-length of each state in the list `let_str_lst_all`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3e649ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "################## this is obsolete, use Convert2unitCSS_main_new instead\n",
    "\n",
    "# the idea is to separate, count, combine\n",
    "def long2unitCSS(long_css_lst, unit=200):\n",
    "    \"\"\"\n",
    "    * description *\n",
    "    long_css is the result of the function \"df2longcss\" (real length css), \n",
    "    and this function aims to convert it into the result of the function \"df2unitcss\",\n",
    "    which is shortest possible version of the css.\n",
    "    Why? because pre-train data for ChromBERT is done by unit-length, \n",
    "    and the genic/intergenic css is acquired as a long-css\n",
    "    \n",
    "    Input: long_css_lst (type=list) acquired by df2longcss(df) and the unit length bp (default=200 bp)\n",
    "    Output: let_str_lst_all (list of unit state) and unit_cnt_lst_all (list of list)\n",
    "    \"\"\"\n",
    "    assert type(long_css_lst)==list, \"Check the input type: it should be a list, but now it's {}\".format(type(long_css_lst))\n",
    "    assert type(long_css_lst[0])==str, \"Check the type of input element: it should be a string, but it's {}\".format(type(long_css_lst[0]))\n",
    "    let_str_lst_all=[]\n",
    "    unit_cnt_lst_all=[]\n",
    "    for elm in long_css_lst:\n",
    "        unit_str=''\n",
    "        unit_cnt_lst=[]\n",
    "        unit_cnt=0\n",
    "        for i, let_str in enumerate(elm):\n",
    "            if i==0:     # handling the first letter\n",
    "                unit_str+=let_str\n",
    "                unit_cnt=1\n",
    "            elif i==len(elm)-1:    # handling the final letter\n",
    "                unit_cnt+=1\n",
    "                unit_cnt_lst.append(int(unit_cnt/unit)) \n",
    "            elif let_str==elm[i-1]:\n",
    "                unit_cnt+=1      \n",
    "            elif (let_str!=elm[i-1] and i!=len(elm)-1):\n",
    "                unit_str+=let_str            \n",
    "                unit_cnt+=1\n",
    "                unit_cnt_lst.append(int(unit_cnt/unit))  \n",
    "                unit_cnt=1\n",
    "            else:\n",
    "                continue\n",
    "        let_str_lst_all.append(unit_str)\n",
    "        unit_cnt_lst_all.append(unit_cnt_lst)\n",
    "    return let_str_lst_all, unit_cnt_lst_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd9dab2",
   "metadata": {},
   "source": [
    "#### Function (main): `Convert2unitCSS_main`\n",
    "* Input: `css_gene_lst_all` or `css_Ngene_lst_all`, the raw-length css on genic and non-genic regions, and the unit (default=200, as the css are annotated per )\n",
    "* Output: `css_unit_lst_all`, the list of chromosome-wise list of unit-length css."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d3697fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Convert2unitCSS_main(css_lst_all, unit=200): # should be either css_gene_lst_all or css_Ngene_lst_all\n",
    "#     \"\"\"\n",
    "#     Input: css_gene_lst_all or css_Ngene_lst_all, the list of chromosome-wise list of the css in genic, intergenic regions.\n",
    "#     Output: css_gene_unit_lst_all or css_Ngene_unit_lst_all\n",
    "#     \"\"\"\n",
    "#     print(\"Converting css from the raw length into unit-length ... \")\n",
    "#     css_unit_lst_all=[]\n",
    "#     for chr_no in tqdm_notebook(range(len(css_lst_all))):\n",
    "#         css_chr_lst=css_lst_all[chr_no]\n",
    "#         css_chr_unit_lst=[]\n",
    "#         let_str_lst_all, unit_cnt_lst_all=long2unitCSS(css_chr_lst, unit=unit)\n",
    "#         unit_css_lst=['']*len(let_str_lst_all)\n",
    "#         for i, let_str in enumerate(let_str_lst_all):\n",
    "#             for j in range(len(let_str)-1):\n",
    "#                 unit_css_lst[i]+=let_str[j]*unit_cnt_lst_all[i][j] # only unit will be multiplied!\n",
    "#         unit_css_lst=[css for css in unit_css_lst if css!='']  # remove the empty element\n",
    "#         css_unit_lst_all.append(unit_css_lst)\n",
    "#     print(\"Done!\")\n",
    "#     return css_unit_lst_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d21c81f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "################## this is obsolete, use Convert2unitCSS_main_new instead\n",
    "\n",
    "def Convert2unitCSS_main(css_lst_all, unit=200): # should be either css_gene_lst_all or css_Ngene_lst_all\n",
    "    \"\"\"\n",
    "    Input: css_gene_lst_all or css_Ngene_lst_all, the list of chromosome-wise list of the css in genic, intergenic regions.\n",
    "    Output: css_gene_unit_lst_all or css_Ngene_unit_lst_all\n",
    "    \"\"\"\n",
    "    print(\"Converting css from the raw length into unit-length ... \")\n",
    "    css_unit_lst_all=[]\n",
    "    for chr_no in tqdm_notebook(range(len(css_lst_all))):\n",
    "        css_chr_lst=css_lst_all[chr_no]\n",
    "        css_chr_unit_lst=[]\n",
    "        let_str_lst_all, unit_cnt_lst_all=long2unitCSS(css_chr_lst, unit=unit)\n",
    "        unit_css_lst=['']*len(let_str_lst_all)\n",
    "        for i, let_str in enumerate(let_str_lst_all):\n",
    "#             for j in range(len(let_str)-1):   ###fixed 29. June. 2023, not yet good to go\n",
    "            for j in range(len(let_str)): ###fixed 29. June. 2023\n",
    "                unit_css_lst[i]+=let_str[j]*unit_cnt_lst_all[i][j] # only unit will be multiplied!\n",
    "        unit_css_lst=[css for css in unit_css_lst if css!='']  # remove the empty element\n",
    "        css_unit_lst_all.append(unit_css_lst)\n",
    "    print(\"Done!\")\n",
    "    return css_unit_lst_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1216e0",
   "metadata": {},
   "source": [
    "Now following files are saved at : `../database/temp_files/` \n",
    "* `css_gene_unit_lst_all` : The unit-length css on the genic area\n",
    "* `css_Ngene_unit_lst_all`: The unit-length css on the intergenic area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949eb048",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27c1a864",
   "metadata": {},
   "source": [
    "### 3-3-3-0. Small code modifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9830b74d",
   "metadata": {},
   "source": [
    "### Genic anc Intergenic re-saved by following functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23814aab",
   "metadata": {},
   "source": [
    "The series of following functions were written to manage the discrepancies in chromosome numbers created by th e previous function, which is caused by some cells without Y chromosme (female cells). All functions to save the genic css and intergenic css were conducted and stored, thus no need to redo (so far)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9501d37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shorten_string(s, factor):\n",
    "    # This regular expression matches groups of the same character.\n",
    "    pattern = re.compile(r'(.)\\1*')\n",
    "\n",
    "    # This function will be used to replace each match.\n",
    "    def replacer(match):\n",
    "        # The group that was matched.\n",
    "        group = match.group()\n",
    "\n",
    "        # Calculate the new length, rounding as necessary.\n",
    "        new_length = round(len(group) / factor)\n",
    "\n",
    "        # Return the character repeated the new number of times.\n",
    "        return group[0] * new_length\n",
    "\n",
    "    # Use re.sub to replace each match in the string.\n",
    "    return pattern.sub(replacer, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce3c9a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Convert2unitCSS_main_new(css_lst_all, unit=200):# should be either css_gene_lst_all or css_Ngene_lst_all\n",
    "    \"\"\"\n",
    "    Input: css_gene_lst_all or css_Ngene_lst_all, the list of chromosome-wise list of the css in genic, intergenic regions.\n",
    "    Output: css_gene_unit_lst_all or css_Ngene_unit_lst_all\n",
    "    \"\"\"\n",
    "    reduced_all=[]\n",
    "    for i in range(len(css_lst_all)):\n",
    "        reduced_chr=[]\n",
    "        for j in range(len(css_lst_all[i])):\n",
    "            reduced=shorten_string(css_lst_all[i][j], unit)\n",
    "            reduced_chr.append(reduced)\n",
    "        reduced_all.append(reduced_chr)\n",
    "    return reduced_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1f08f588",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### fixed Jul 6. 2023\n",
    "def compGene2css_work(whole_gene_file,df): \n",
    "    \"\"\"\n",
    "    Input: Reference gene file, df (CSS)\n",
    "    Output: list of chromosome-wise list that contains the css at \"genic\" area only.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Extracting the CSS on the genic region ...\")\n",
    "\n",
    "    ########### new fancy gene table without overlap ###########\n",
    "#     new_gene_lst_all=gene_removeDupl(whole_gene_file) ##### fixed June 29. 2023\n",
    "    g_df_chr_lst=whGene2GLChr(whole_gene_file)  ##### fixed June 29. 2023\n",
    "    new_gene_lst_all=merge_intervals(g_df_chr_lst) ##### fixed June 29. 2023\n",
    "    ############################################################\n",
    "    \n",
    "    #### Remove chrM ###########################################\n",
    "    contains_chrM = df['chromosome'].str.contains('chrM').any()  #check whether it contains M\n",
    "    if contains_chrM:\n",
    "        df= df[~df['chromosome'].str.contains('chrM')]\n",
    "    \n",
    "    contains_chrY = df['chromosome'].str.contains('chrY').any()\n",
    "    \n",
    "    ##### if the target file does not contain Y, remove Y in the gene list file\n",
    "    if not contains_chrY:\n",
    "        new_gene_lst_all=new_gene_lst_all[:-1] ## the final element is for Y\n",
    "    ############################################################\n",
    "    \n",
    "    assert len(df[\"chromosome\"].unique())==len(new_gene_lst_all)\n",
    "        \n",
    "    css_lst_chr=df2longcss(df) # list of long css per chromosome\n",
    "    total_chr=len(new_gene_lst_all)\n",
    "    \n",
    "    css_gene_lst_all=[]\n",
    "    for i in tqdm_notebook(range(total_chr)):\n",
    "        css=css_lst_chr[i]   # long css of i-th chromosome\n",
    "        gene_df=new_gene_lst_all[i] # gene df of i-th chromosome\n",
    "        \n",
    "        css_gene_lst_chr=[]\n",
    "        for j in range(len(gene_df)):\n",
    "            g_start=gene_df[\"TxStart\"].iloc[j]-1  # python counts form 0\n",
    "            g_end=gene_df[\"TxEnd\"].iloc[j]+1      # python excludes the end\n",
    "            \n",
    "            css_gene=css[g_start:g_end]           # cut the gene area only\n",
    "            css_gene_lst_chr.append(css_gene)     # store in the list\n",
    "          \n",
    "        css_gene_lst_all.append(css_gene_lst_chr)  # list of list\n",
    "    \n",
    "    assert len(css_gene_lst_all)==total_chr\n",
    "    print(\"Done!\")\n",
    "    return css_gene_lst_all  ## long version css"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "295b1b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### fixed June 29. 2023\n",
    "def compNonGene2css_work(whole_gene_file,df): \n",
    "    \"\"\"\n",
    "    Input: Reference gene file, df (CSS)\n",
    "    Output: list of chromosome-wise list that contains the css at \"non-genic\" area only.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Extracting the CSS on the intergenic region ...\")\n",
    "\n",
    "    ########### new fancy gene table without overlap ###########\n",
    "#     new_gene_lst_all=gene_removeDupl(whole_gene_file) ##### fixed June 29. 2023\n",
    "    g_df_chr_lst=whGene2GLChr(whole_gene_file)  ##### fixed June 29. 2023\n",
    "    new_gene_lst_all=merge_intervals(g_df_chr_lst) ##### fixed June 29. 2023\n",
    "    ############################################################\n",
    "    \n",
    "    #### Remove chrM ###########################################\n",
    "    contains_chrM = df['chromosome'].str.contains('chrM').any()  #check whether it contains M\n",
    "    if contains_chrM:\n",
    "        df= df[~df['chromosome'].str.contains('chrM')]\n",
    "    \n",
    "    contains_chrY = df['chromosome'].str.contains('chrY').any()\n",
    "    \n",
    "    ##### if the target file does not contain Y, remove Y in the gene list file\n",
    "    if not contains_chrY:\n",
    "        new_gene_lst_all=new_gene_lst_all[:-1] ## the final element is for Y\n",
    "    ############################################################\n",
    "    \n",
    "    assert len(df[\"chromosome\"].unique())==len(new_gene_lst_all)\n",
    "        \n",
    "    css_lst_chr=df2longcss(df) # list of long css per chromosome\n",
    "    total_chr=len(new_gene_lst_all)\n",
    "    \n",
    "    css_Ngene_lst_all=[]\n",
    "        \n",
    "    for i in tqdm_notebook(range(total_chr)):\n",
    "        css=css_lst_chr[i]   # long css of i-th chromosome\n",
    "        gene_df=new_gene_lst_all[i] # gene df of i-th chromosome\n",
    "        \n",
    "#         assert gene_df[\"TxStart\"].iloc[0]>=1, \"Gene starts from the very first location at {}-th chromosome.\".format(i)\n",
    "#         assert gene_df[\"TxEnd\"].iloc[-1]<=len(css), \"Gene ends at the very last location at {}-th chromosome.\".format(i)  \n",
    "        ### asertion was removed because it produces an error when trying to apply to cells without Y chr.        \n",
    "    \n",
    "        css_Ngene_lst_chr=[]        \n",
    "        for j in range(len(gene_df)):\n",
    "            if j==0:\n",
    "                ng_start=1 # to avoid any \"zero\" causing problem \n",
    "                ng_end=gene_df[\"TxStart\"].iloc[j]\n",
    "#                 print(\"j: {} | ng_start: {} - ng_end: {} \".format(j, ng_start, ng_end)) # for checking\n",
    "            elif j==len(gene_df)-1: \n",
    "                ng_start=gene_df[\"TxEnd\"].iloc[j]\n",
    "                ng_end=len(css)\n",
    "#                 print(\"j: {} | ng_start: {} - ng_end: {} \".format(j, ng_start, ng_end)) # for checking\n",
    "            else:\n",
    "                ng_start=gene_df[\"TxEnd\"].iloc[j-1]\n",
    "                ng_end=gene_df[\"TxStart\"].iloc[j]\n",
    "#                 print(\"j: {} | ng_start: {} - ng_end: {} \".format(j, ng_start, ng_end)) # for checking \n",
    "        \n",
    "            css_Ngene=css[ng_start:ng_end]\n",
    "            css_Ngene_lst_chr.append(css_Ngene)\n",
    "        \n",
    "        css_Ngene_lst_all.append(css_Ngene_lst_chr) \n",
    "        \n",
    "    assert len(css_Ngene_lst_all)==total_chr\n",
    "    print(\"Done!\")\n",
    "    \n",
    "    return css_Ngene_lst_all   ## long version css"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e4c10736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now working on here\n",
    "def pickled_df2gene_unit_css_new(df_pickled_path=\"../database/roadmap/df_pickled/\", output_path=\"../database/roadmap/\", verbose=True):\n",
    "    \"\"\"\n",
    "    Save unit CSS for genic, for the entire 127 epigenomes\n",
    "    \"\"\"\n",
    "    df_pickled_files = [os.path.join(df_pickled_path, df) for df in sorted(os.listdir(df_pickled_path))]\n",
    "    \n",
    "    def load_pickled_df(df_pickled_file):\n",
    "        with open(df_pickled_file, \"rb\") as f:\n",
    "            df = pickle.load(f)\n",
    "        return df\n",
    "    \n",
    "    for file in df_pickled_files:\n",
    "        cell_id = file.split(\"/\")[-1][:4]  \n",
    "\n",
    "        gene_output_name = output_path +\"gene_css_unit_pickled/\"+ cell_id + \"_gene_css_pickled.pkl\"\n",
    "        df=load_pickled_df(file)\n",
    "\n",
    "        css_gene_lst_all=compGene2css_work(whole_gene_file,df)  # use existing one for genic regions\n",
    "        css_gene_unit_lst_all=Convert2unitCSS_main_new(css_gene_lst_all, unit=200)\n",
    "\n",
    "        with open(gene_output_name, 'wb') as g:\n",
    "            pickle.dump(css_gene_unit_lst_all, g)\n",
    "\n",
    "        if verbose:\n",
    "            print(cell_id+\" is done\")\n",
    "\n",
    "    return print(\"All done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3ac66ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickled_df2Ngene_unit_css_new(df_pickled_path=\"../database/roadmap/df_pickled/\", output_path=\"../database/roadmap/\", verbose=True):\n",
    "    \"\"\"\n",
    "    Save unit CSS for Intergenic, for the entire 127 epigenomes\n",
    "    \"\"\"\n",
    "    df_pickled_files = [os.path.join(df_pickled_path, df) for df in sorted(os.listdir(df_pickled_path))]\n",
    "    \n",
    "    def load_pickled_df(df_pickled_file):\n",
    "        with open(df_pickled_file, \"rb\") as f:\n",
    "            df = pickle.load(f)\n",
    "        return df\n",
    "    \n",
    "    for file in df_pickled_files:\n",
    "        cell_id = file.split(\"/\")[-1][:4]  \n",
    "        \n",
    "#         if int(cell_id[1:])>115:  # temp\n",
    "\n",
    "        Ngene_output_name = output_path +\"Ngene_css_unit_pickled/\"+ cell_id + \"_Ngene_css_pickled.pkl\"\n",
    "        df=load_pickled_df(file)\n",
    "\n",
    "        css_Ngene_lst_all=compNonGene2css_work(whole_gene_file,df)\n",
    "        css_Ngene_unit_lst_all=Convert2unitCSS_main_new(css_Ngene_lst_all, unit=200)\n",
    "\n",
    "        with open(Ngene_output_name, 'wb') as g:\n",
    "            pickle.dump(css_Ngene_unit_lst_all, g)\n",
    "\n",
    "        if verbose:\n",
    "            print(cell_id+\" is done\")\n",
    "\n",
    "    return print(\"All done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b85d0e",
   "metadata": {},
   "source": [
    "### Just to save entire long-version css per chromosome, except for chrM "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb44403",
   "metadata": {},
   "source": [
    "`save_longcss` was conducted and the files are saved at `\"/data1/chromatin_state/database_backup/roadmap_long_css/\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2e8c2e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeChrM(df):\n",
    "    #### Remove chrM ###########################################\n",
    "    contains_chrM = df['chromosome'].str.contains('chrM').any()  #check whether it contains M\n",
    "    if contains_chrM:\n",
    "        df= df[~df['chromosome'].str.contains('chrM')]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7536bd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_longcss(df_pickled_path, output_path=\"/data1/chromatin_state/database_backup/roadmap_long_css/\", verbose=True):\n",
    "    file_lst = [os.path.join(df_pickled_path,file) for file in sorted(os.listdir(df_pickled_path))]\n",
    "    counter = 0  # Add a counter\n",
    "    if verbose:\n",
    "        print(\"output path = \", output_path)\n",
    "    for file in file_lst:\n",
    "        cell_id = file.split(\"/\")[-1][:4]\n",
    "        with open(file,\"rb\") as f:\n",
    "            df = pickle.load(f)\n",
    "        df = removeChrM(df)\n",
    "        long_css = df2longcss(df)        \n",
    "        output_file_name = cell_id + \"_longcss_woChrM.pkl\"\n",
    "        with open(os.path.join(output_path, output_file_name),\"wb\") as g:  # Use os.path.join\n",
    "            pickle.dump(long_css, g)\n",
    "        counter += 1  # Increment the counter\n",
    "        if verbose and counter % 10 == 0:  # If counter is divisible by 10\n",
    "            print(f\"{counter} files have been saved.\")\n",
    "    print(\"All saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636a9c60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3096f438",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce034a88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6542ce2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3781b83",
   "metadata": {},
   "source": [
    "### 3-3-3-1. CSS for 57 Epigenomes Genic regions are saved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95587ce5",
   "metadata": {},
   "source": [
    "#### Function:` extGenic_byCell`\n",
    "* Input: output path\n",
    "* This function cut CSS of each cell type by Genic area, and reduce it as unit length\n",
    "* Output: function has been already executed, and pickled at `../database/temp_files/whole_gene_unit/`\n",
    "    * The saved file names are like `E003_css_gene_unit_lst_all.pkl`\n",
    "* **Note** that it takes up to 10 hours to complete if you use macbook pro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb451f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the whole gene area of the 57 epigenomes, in CSS unit sequences (total no. 56, because no E000 for CSS)\n",
    "# Following function has been already executed, and pickled at \"../database/temp_files/whole_gene_unit/\"\n",
    "\n",
    "def extGenic_byCell(output_path=\"../database/temp_files/whole_gene_unit/\", verbose=True):\n",
    "    \"\"\"\n",
    "    Extract the genic area CSS from the designated 57 epigenome in EG.name.txt\n",
    "    and save them at \"../database/temp_files/whole_gene_unit/\"\n",
    "    \"\"\"\n",
    "    # note that EG.name.txt contains E000 (which is not in CSS bed file)\n",
    "    bed_file_path=\"../database/bed/unzipped/\"\n",
    "    epi_name_path=\"../database/bed/gene_expression/EG.name.txt\"\n",
    "\n",
    "    epi_name_df=pd.read_csv(epi_name_path, names=[\"epi_num\",\"epi_name\"], sep=\"\\t\", header=None, index_col=False)\n",
    "    epi_name_df=epi_name_df.dropna()\n",
    "    epi_num=epi_name_df[\"epi_num\"].dropna().to_list() # number, 0th field\n",
    "    epi_name=epi_name_df[\"epi_name\"].dropna().to_list() # name, 1st field\n",
    "    bed_file_lst=sorted(os.listdir(bed_file_path))\n",
    "    \n",
    "    # list comprehension for extract the bed files that corresponds to the target epigenome\n",
    "    epi_target_tuple=[(num, bed_file) for num in epi_num for bed_file in bed_file_lst if num in bed_file]\n",
    "    epi_target=[tup[1] for tup in epi_target_tuple]\n",
    "    path=\"../database/bed/unzipped/\"\n",
    "    \n",
    "#     print(epi_name_df)\n",
    "    for epi in epi_target:\n",
    "        cell_type=epi_name_df.loc[epi_name_df[\"epi_num\"]==epi[:4],\"epi_name\"].values[0]\n",
    "        if verbose: \n",
    "            print(\"{}: {} is now processed ...\".format(epi, cell_type))\n",
    "        \n",
    "        df_epi=bed2df_expanded(path+epi)  # create df of the css for the cell\n",
    "        css_epi_gene_lst_all=compGene2css(whole_gene_file,df_epi) # list of the css on the genic region\n",
    "        css_epi_gene_unit_lst_all=Convert2unitCSS_main(css_epi_gene_lst_all,unit=200) # make css to unit length \n",
    "        # note that the above list is chromosome-wise list\n",
    "        \n",
    "        # total number of genes        \n",
    "        print(\"Total number of genes: {}\".format(len(flatLst(css_epi_gene_unit_lst_all))))\n",
    "        \n",
    "        # pickle it!\n",
    "        epi_gene_css_name=output_path+epi[:4]+\"_css_gene_unit_lst_all.pkl\"\n",
    "        with open(epi_gene_css_name, \"wb\") as f:\n",
    "            pickle.dump(css_epi_gene_unit_lst_all,f)\n",
    "\n",
    "    return print(\"Files are pickled at {}.\".format(output_path))   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a637573c",
   "metadata": {},
   "source": [
    "### 3-3-4. Cut the unit-length css into trainable size and kmerize it\n",
    "\n",
    "#### Function: `chr_css_CUT_Kmer`\n",
    "* Input: Unit-length css list of chromosome-wise list (e.g. `css_gene_unit_lst_all` or `css_Ngene_unit_lst_all`)\n",
    "* Output: \n",
    "    1. `splitted` : List of strings before kmerization (to visualize later)\n",
    "    2. `kmerized_unit_css` :  List of strings after kmerization (to use as a trinable data)\n",
    " \n",
    "* Usage (e.g. Generate a 3-mer traning data from 2nd chromosome in intergenic area)\n",
    "> `splitted, kmerized_unit_css=chr_css_CUT_Kmer(css_Ngene_unit_lst_all, 2, 510, 3)`\n",
    "* And the data can be stored like \n",
    "> `with open(\"../database/fine_tune/genic_and_intergenic/3mer/chr2_Ngene.txt\", \"w\") as f:         f.write(\"\\n\".join(kmerized_unit_css))`\n",
    "       \n",
    "* The reason why the above code for saving is not included is because it takes too much time.. dunno why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9ccd5df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut the unit-length string (input: unit-css, not df)\n",
    "def chr_css_CUT_Kmer(unit_css, chr_no, cut_thres, k):\n",
    "    \"\"\"    \n",
    "    Prepare kmer dataset for unit_css, as is if length<=510, else cut it to be length>510   \n",
    "    Usage: chr_css_CUT_Kmer(unit_css, chr_no, cut_thres, k)\n",
    "    \n",
    "    - unit_css: list of chromosome-wise list of unit-length css (e.g. css_gene_unit_lst_all)\n",
    "    - chr_no: no. of chromosome\n",
    "    - cut_thres: length of split, default=510\n",
    "    - k: kmer\n",
    "    \n",
    "    Output: 1. splitted (before kmerization) 2. kmerized_unit_css (after kmerization) \n",
    "    \"\"\"    \n",
    "    chr_unit_css=unit_css[chr_no]   # designated chromosome no.    \n",
    "    splitted=[] # bucket for the all the splitted strings   \n",
    "    cnt_short, cnt_long=0,0\n",
    "    for css_elm in chr_unit_css:\n",
    "        if len(css_elm) <=cut_thres:\n",
    "            splitted.append(css_elm)\n",
    "            cnt_short+=1\n",
    "        else:\n",
    "            cnt_long+=1\n",
    "            prev=0\n",
    "            while True:\n",
    "                splitted.append(css_elm[prev:prev+cut_thres])\n",
    "                prev+=cut_thres\n",
    "                if prev>=len(css_elm)-1:\n",
    "                    break                   \n",
    "    kmerized_unit_css=[seq2kmer(item, k) for item in splitted]\n",
    "    long_pro=cnt_long/(cnt_long+cnt_short)\n",
    "    \n",
    "    return splitted, kmerized_unit_css"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259161eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "afa94a39",
   "metadata": {},
   "source": [
    "#### Function: `saveCUTs_all`\n",
    "\n",
    "* Simply save the file created from the above fucntion: k-merized genic and intergenic unit-length css\n",
    "* 3mer, 4mer files are already stored at `../database/fine_tune/genic_and_intergenic/`\n",
    "* Usage\n",
    "> `saveCUTs_all(css_gene_unit_lst_all, 510, 3, gene=True)`\n",
    "> saves the css on the genic region after 3-merization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "699c464e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveCUTs_all(unit_css, cut_thres, k, gene=True):\n",
    "    for chr_no in range(len(unit_css)):        \n",
    "        _, kmerized=chr_css_CUT_Kmer(unit_css, chr_no, cut_thres, k)\n",
    "        chr_num=str(chr_no+1)\n",
    "        if gene:\n",
    "            g='gene'\n",
    "        else:\n",
    "            g='Ngene'\n",
    "   \n",
    "        path=\"../database/fine_tune/genic_and_intergenic/\"\n",
    "        kmer=str(k)+'mer/'\n",
    "        folder=g+\"/\"\n",
    "        name=\"chr\"+chr_num+\"_\"+g+\".txt\"\n",
    "        f_name=path+kmer+folder+name\n",
    "        \n",
    "        with open(f_name, \"w\") as f:\n",
    "            f.write(\"\\n\".join(kmerized))\n",
    "    return print(\"{}merized files for {} are saved at {}.\".format(k,unit_css,path+kmer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca5711d",
   "metadata": {},
   "source": [
    "### 3-3-5. Fine-tuning data: Dataframe version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412271f3",
   "metadata": {},
   "source": [
    "#### Function: `prepFT_gNg`\n",
    "* Create a dataframe version of dataset, accommodating the same number of genic and non-genic region unit css.\n",
    "* Input: `path` (for the specific task), `k`, `sampling_no` (number of chromosome you want to pick as a random no.)\n",
    "* Output: `df_g_ng_all` the dataframe containing same amount of genic/non-genic css strips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9dca7216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing the dataframe-version for generating train and dev dataset\n",
    "def prepFT_gNg(path=\"../database/fine_tune/genic_and_intergenic/\", k=4, sampling_no=10):\n",
    "    dir_k=path+str(k)+\"mer/\"\n",
    "    \n",
    "    dir_g=dir_k+\"gene/\"\n",
    "    dir_ng=dir_k+\"Ngene/\"\n",
    "    g_files=os.listdir(dir_g)\n",
    "    ng_files=os.listdir(dir_ng)\n",
    "    all_g_files=file_list_maker(dir_g,g_files)\n",
    "    all_ng_files=file_list_maker(dir_ng,ng_files)\n",
    "    \n",
    "    g_len_all,ng_len_all=[],[]\n",
    "    df_ng_all,df_g_all=[],[]\n",
    "    \n",
    "    ### for Ngene data\n",
    "    for chr_ng in all_ng_files:\n",
    "        df_ng=pd.read_csv(chr_ng, header=None, names=[\"sequence\"], sep=\"\\n\")\n",
    "        df_ng[\"label\"]=0        \n",
    "        ng_len=len(df_ng)  # only for checking length\n",
    "        ng_len_all.append(ng_len)  # only for checking length\n",
    "        \n",
    "        df_ng_all.append(df_ng) \n",
    "    df_ng_concat=pd.concat(df_ng_all)  # for ng, concatenate all the list\n",
    "    \n",
    "    ### for gene data\n",
    "    sample=random.sample([i for i, elm in enumerate(all_g_files)], sampling_no)\n",
    "    print(\"Sampled chromosome for genic region: {}\".format(sample))\n",
    "    for i, chr_g in enumerate(all_g_files):\n",
    "        df_g=pd.read_csv(chr_g, header=None, names=[\"sequence\"], sep=\"\\n\")\n",
    "        df_g[\"label\"]=1\n",
    "        g_len=len(df_g)  # only for checking length\n",
    "        g_len_all.append(g_len)  # only for checking length\n",
    "        \n",
    "        if i in sample:   # sampling \n",
    "            df_g_all.append(df_g)\n",
    "        else:\n",
    "            continue\n",
    "    df_g_concat=pd.concat(df_g_all)\n",
    "    \n",
    "    ### for the length adjustment ###\n",
    "    if len(df_g_concat)>len(df_ng_concat):\n",
    "        df_g_concat=df_g_concat[:len(df_ng_concat)] \n",
    "    elif len(df_g_concat)<len(df_ng_concat):\n",
    "        df_ng_concat=df_ng_concat[:len(df_g_concat)]\n",
    "    assert len(df_g_concat)==len(df_ng_concat)\n",
    "    \n",
    "    df_g_ng_all=pd.concat([df_ng_concat,df_g_concat]).sample(frac=1).reset_index(drop=True)  # shuffling    \n",
    "    \n",
    "    ### for visualization purpose ###\n",
    "#     fig, ax = plt.subplots(1,1,figsize=(6,4))\n",
    "#     ax=sns.histplot(g_len_all, color=\"teal\", element=\"step\", bins=10, fill=False) #cumulative=True\n",
    "#     ax=sns.histplot(ng_len_all, color=\"orange\", element=\"step\", bins=4, fill=False)\n",
    "#     plt.title(\"Cumulative plot of genic/intergenic data size\", fontsize=13)\n",
    "#     ax.set_xlabel(\"Length of data\", fontsize=13)\n",
    "#     ax.legend([\"genic\",\"intergenic\"])\n",
    "#     plt.show()   \n",
    "        \n",
    "    return df_g_ng_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e52dbe5",
   "metadata": {},
   "source": [
    "### 3-3-6. Fine-tuning data: save files as .tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa3488c",
   "metadata": {},
   "source": [
    "#### Function: `saveTF_gNg`\n",
    "* Fine-tuning files for classifying genic and intergenic area already are saved at `\"../database/fine_tune/genic_and_intergenic/\"` (4mer only)\n",
    "* Input: `df_g_ng_all` (Result from the function `prepFT_gNg`), `path`, `k`, `len_train`, `len_dev`\n",
    "* Output: Files are saved at \"`path/kmer/`\" folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8184f04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveTF_gNg(df_g_ng_all, path=\"../database/fine_tune/genic_and_intergenic/\",k=4,len_train=30000,len_dev=1000):\n",
    "    dir_k=path+str(k)+\"mer/\"\n",
    "    df_g_ng_train=df_g_ng_all[:len_train]\n",
    "    df_g_ng_dev=df_g_ng_all[len_train:len_train+len_dev]    \n",
    "    \n",
    "    train_name=dir_k+\"train.tsv\"\n",
    "    dev_name=dir_k+\"dev.tsv\"\n",
    "    \n",
    "    df_g_ng_train.to_csv(train_name, sep=\"\\t\", index=False)\n",
    "    df_g_ng_dev.to_csv(dev_name, sep=\"\\t\", index=False)\n",
    "    \n",
    "    return print(\"train.tsv and dev.tsv Files are saved at '{}'.\". format(dir_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082bb889",
   "metadata": {},
   "source": [
    "## 3-4. Count the number of 15th states in genic and non-genic region"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5117b2",
   "metadata": {},
   "source": [
    "#### Function: `QnonQforCell`\n",
    "\n",
    "* Calculate the numbers of genes that contain/ not contain 15th state (Quiescent) for all 127 cells\n",
    "* Caution: it takes tremendous of time. Just use pickled output at `\"../database/temp_files/\"`\n",
    "* Input: cell file list, whole gene file\n",
    "* Output: `q_cnt_lst` (The number of gene that contains 15th state) / `not_q_cnt_lst` (genes do not have 15th state)\n",
    "* Note that you need to flatten it when use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "df3b6bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for cell-wise count : how many 15th-including genes are there per cell\n",
    "\n",
    "# caution: takes tremendous of time!\n",
    "# better make it for a single cell?\n",
    "# No, it was required, and the result files are pickled at ./temp_files\n",
    "\n",
    "def QnonQforCell(all_files=all_files,whole_gene_file=whole_gene_file):\n",
    "    total_cells=len(all_files)\n",
    "    \n",
    "    q_cnt_lst=[]\n",
    "    not_q_cnt_lst=[]\n",
    "#     for i in range(total_cells):\n",
    "    for i in tqdm_notebook(range(total_cells)):\n",
    "        cell_path=all_files[i]\n",
    "        df=bed2df_expanded(cell_path)\n",
    "        css_gene_lst_all=compGene2css(whole_gene_file,df)\n",
    "        \n",
    "        q_cnt=0\n",
    "        not_q_cnt=0\n",
    "        for j in range(len(css_gene_lst_all)):\n",
    "            css_gene_lst=css_gene_lst_all[j]\n",
    "            for k in range(len(css_gene_lst)):\n",
    "                css_gene=css_gene_lst[k]\n",
    "                if \"O\" in css_gene:\n",
    "                    q_cnt+=1\n",
    "                else:\n",
    "                    not_q_cnt+=1\n",
    "        q_cnt_lst.append(q_cnt)\n",
    "        not_q_cnt_lst.append(not_q_cnt)\n",
    "    return q_cnt_lst, not_q_cnt_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a836e0",
   "metadata": {},
   "source": [
    "#### Function: `QnonQforChr`\n",
    "* Similar to `QnonQforCell`, but it is a flatten version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "688cff7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for chromosome-wise list of list -> flatten list\n",
    "\n",
    "def QnonQforChr(all_files=all_files,whole_gene_file=whole_gene_file):\n",
    "#     import itertools\n",
    "    total_cells=len(all_files)\n",
    "    \n",
    "    q_cnt_lst_all=[]\n",
    "    not_q_cnt_lst_all=[]\n",
    "#     for i in range(total_cells):\n",
    "    for i in tqdm_notebook(range(total_cells)):\n",
    "        cell_path=all_files[i]\n",
    "        df=bed2df_expanded(cell_path)\n",
    "        css_gene_lst_all=compGene2css(whole_gene_file,df)\n",
    "        \n",
    "        q_cnt_lst=[]\n",
    "        not_q_cnt_lst=[]\n",
    "        for j in range(len(css_gene_lst_all)):\n",
    "            css_gene_lst=css_gene_lst_all[j]\n",
    "            \n",
    "            q_cnt=0\n",
    "            not_q_cnt=0\n",
    "            for k in range(len(css_gene_lst)):\n",
    "                css_gene=css_gene_lst[k]\n",
    "                if \"O\" in css_gene:\n",
    "                    q_cnt+=1\n",
    "                else:\n",
    "                    not_q_cnt+=1\n",
    "                    \n",
    "            q_cnt_lst.append(q_cnt)\n",
    "            not_q_cnt_lst.append(not_q_cnt)        \n",
    "        q_cnt_lst_all.append(q_cnt_lst)\n",
    "        not_q_cnt_lst_all.append(not_q_cnt_lst)\n",
    "\n",
    "#     flatten the list of list and make it into list\n",
    "    q_cnt_lst_all=list(itertools.chain.from_iterable(q_cnt_lst_all))\n",
    "    not_q_cnt_lst_all=list(itertools.chain.from_iterable(not_q_cnt_lst))\n",
    "        \n",
    "    return q_cnt_lst_all, not_q_cnt_lst_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f301f779",
   "metadata": {},
   "source": [
    "#### Function: `QnonQforCellHistT1`\n",
    "\n",
    "* Input: `q_cnt_lst`, `not_q_cnt_lst` (they are pickled at `\"../database/temp_files/\"`)\n",
    "* How to load the pickled data\n",
    "    > `with open(\"path\", \"rb\") as f:`  <br>\n",
    "    > `data=pickle.load(f)`\n",
    "* Output: Histogram of the numbers of gene per cell that contains/ don't contain 15th state in the all cell types\n",
    "<br><br>\n",
    "\n",
    "<img src=\"./desc_img/qnonq_hist1.png\" width=\"400\" height=\"150\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ad5fc2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw a histogram type1 (group by data)\n",
    "def QnonQforCellHistT1(q_cnt_lst, not_q_cnt_lst, bin_size=20):\n",
    "    \"\"\"Run this after executing QnonQforCell\"\"\"\n",
    "    data_w=q_cnt_lst\n",
    "    data_wo=not_q_cnt_lst\n",
    "\n",
    "    mu_w, std_w=norm.fit(data_w)\n",
    "    mu_wo, std_wo=norm.fit(data_wo)\n",
    "\n",
    "    fig=plt.figure(figsize=(8,4))\n",
    "    ax=fig.add_subplot(1,1,1)\n",
    "    ax.hist(data_w, bins=bin_size, alpha=0.3, color=\"k\")\n",
    "    ax.hist(data_wo, bins=bin_size, alpha=0.5, color=\"r\")\n",
    "\n",
    "    title='Number of Genic region with/without Quiescent state'\n",
    "    \n",
    "    ax.set_title(title, fontsize=15)\n",
    "    ax.set_xlabel(\"No. of Genes\", fontsize=15)\n",
    "    plt.xticks(fontsize=12)\n",
    "    ax.set_ylabel(\"Counts\", fontsize=15)\n",
    "    ax.legend([\"With Q\", \"Without Q\"])\n",
    "    plt.yticks(fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e0a824",
   "metadata": {},
   "source": [
    "#### Function: `QnonQforCellHistT2`\n",
    "\n",
    "* Input: `q_cnt_lst`, `not_q_cnt_lst` and `bin_size` (they are pickled at `\"../database/temp_files/\"`)\n",
    "* How to load the pickled data\n",
    "    > `with open(\"path\", \"rb\") as f:`  <br>\n",
    "    > `data=pickle.load(f)`\n",
    "* Output: Histogram of the numbers of gene per cell that contains/ don't contain 15th state in the all cell types that is grouped by bin (Well, I don't know why I wrote this code..)\n",
    "<br><br>\n",
    "\n",
    "<img src=\"./desc_img/qnonq_hist2.png\" width=\"400\" height=\"150\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a5cd9203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw a histogram type2 (group by bin)\n",
    "def QnonQforCellHistT2(q_cnt_lst, not_q_cnt_lst,bin_size):\n",
    "    \"\"\"Run this after executing QnonQforCell\"\"\"\n",
    "    data_w=q_cnt_lst\n",
    "    data_wo=not_q_cnt_lst\n",
    "\n",
    "    mu_w, std_w=norm.fit(data_w)\n",
    "    mu_wo, std_wo=norm.fit(data_wo)\n",
    "\n",
    "    fig=plt.figure(figsize=(8,4))\n",
    "    ax=fig.add_subplot(1,1,1)\n",
    "    ax.hist([data_w,data_wo], bins=bin_size, alpha=0.5, color=[\"teal\",\"orange\"], label=[\"with Quiescent state\",\"without Quiescent state\"])\n",
    "    \n",
    "    ax.legend(loc=\"upper left\")\n",
    "\n",
    "    title='Number of Genic region with/without Quiescent state'\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"No. of Genes\")\n",
    "    plt.ylabel(\"Counts\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e784b4ca",
   "metadata": {},
   "source": [
    "#### Fuction: `QnonQforCellSwarmp`\n",
    "* Create a dataframe of two lists (below) and draw a dual swarmp graph in a single figure.\n",
    "* Input: `q_cnt_lst` and `not_q_cnt_lst` (find them pickled at `\"../database/temp_files/\"`)\n",
    "* Output: `q_cnt_data` (dataframe of the two lists) and the graph\n",
    "\n",
    "<img src=\"./desc_img/qnonq_swarmp.png\" width=\"400\" height=\"150\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "29aaa812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def QnonQforCellSwarmp(q_cnt_lst, not_q_cnt_lst):\n",
    "    q_cnt_data=pd.DataFrame({\"q_cnt\":q_cnt_lst, \"not_q_cnt\":not_q_cnt_lst}) # create a dataframe\n",
    "    fig=plt.figure(figsize=(6,4))\n",
    "    sns.swarmplot(data=q_cnt_data, palette=\"bone\")\n",
    "    plt.grid(b=None)\n",
    "    plt.ylabel(\"Counts\", fontsize=12)\n",
    "    plt.show()\n",
    "    return q_cnt_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84043e2",
   "metadata": {},
   "source": [
    "#### Function: `cntQinGene`\n",
    "* This function generates three lists\n",
    "    1. 15th state-including gene count\n",
    "    2. 15th state-including gene length\n",
    "    3. Proportion of 15th state in the 15th state-including gene\n",
    "* Input: `css_gene_lst_all` (pickled at `\"../database/temp_files/\"`, note that it's 2.8Gb)\n",
    "* Output: \n",
    "    1. `cnt_o_lst`: 15th state-including gene count\n",
    "    2. `gene_len_lst`: 15th state-including gene length\n",
    "    3. `pro_o_lst`: Proportion of 15th state in the 15th state-including gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d4ae54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate three lists: 15th state-including gene count, gene length, proportion of 15th state per gene\n",
    "def cntQinGene(css_gene_lst_all):\n",
    "    \"\"\"run this after executing compGene2css(whole_gene_file,df)\n",
    "       [Input]\n",
    "       css_gene_lst_all : list of css list of each chromosome\n",
    "       [Output]\n",
    "       cnt_o_lst : list of Quiescent state counts list per chromosome\n",
    "       gene_len_lst : list of gene length (in terms of chromatin state Anno.200bps) list per chromosome\n",
    "       pro_o_lst : list of proportion of Quiescent state per gene list per chromosome\n",
    "    \"\"\"\n",
    "    cnt_o_lst=[]\n",
    "    gene_len_lst=[]\n",
    "    pro_o_lst=[]\n",
    "    for i in range(len(css_gene_lst_all)):\n",
    "        css_gene_lst=css_gene_lst_all[i]\n",
    "        \n",
    "        cnt_o_chr=[]\n",
    "        gene_len_chr=[]\n",
    "        pro_o_chr=[]\n",
    "        for j in range(len(css_gene_lst)):\n",
    "            css_gene=css_gene_lst[j]\n",
    "            cnt_o=css_gene.count(\"O\")\n",
    "            gene_len=len(css_gene)\n",
    "            pro_o=cnt_o/gene_len\n",
    "            \n",
    "            cnt_o_chr.append(cnt_o)\n",
    "            gene_len_chr.append(gene_len)\n",
    "            pro_o_chr.append(pro_o)\n",
    "            \n",
    "        cnt_o_lst.append(cnt_o_chr)\n",
    "        gene_len_lst.append(gene_len_chr)\n",
    "        pro_o_lst.append(pro_o_chr)\n",
    "        \n",
    "    return cnt_o_lst, gene_len_lst, pro_o_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1b6bf5",
   "metadata": {},
   "source": [
    "#### Function: `cntQinGeneVis1`\n",
    "* For visualization of the result of the function `cntQinGene`.\n",
    "* Input: `cnt_o_lst`, `gene_len_lst`, and `pro_o_lst` (result of `cntQinGene`), for more info, see that function.\n",
    "* Output: Letter-value histogram of `cnt_o_lst` and `gene_len_lst`, and violin plot for `pro_o_lst`\n",
    "<img src=\"./desc_img/cntQinGeneVis1.png\" width=\"500\" height=\"150\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "591d42aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cntQinGeneVis1(cnt_o_lst, gene_len_lst, pro_o_lst):\n",
    "    \"\"\"\n",
    "    Input: cnt_o_lst, gene_len_lst, pro_o_lst (the result lists of cntQinGene(css_gene_lst_all). To load the css_gene_lst_all, find the file at \"../database/temp_files/\")\n",
    "    Output: Dataframe of those 3 lists, and the visualization of the above lists using histogram\n",
    "    \"\"\"\n",
    "    def flatLst(lst):\n",
    "        flatten_lst=[elm for sublst in lst for elm in sublst]\n",
    "        return flatten_lst\n",
    "\n",
    "    cnt_o_lst_flat=flatLst(cnt_o_lst)\n",
    "    gene_len_lst_flat=flatLst(gene_len_lst)\n",
    "    pro_o_lst_flat=flatLst(pro_o_lst)\n",
    "    \n",
    "    three_df=pd.DataFrame({\"gene_len\":gene_len_lst_flat, \"cnt_o\":cnt_o_lst_flat, \"o_proportion\":pro_o_lst_flat})\n",
    "    \n",
    "    fig, (ax1,ax2) = plt.subplots(1,2,figsize=(10,5), sharey=False)\n",
    "    ax1=sns.boxenplot(data=three_df[[\"gene_len\",\"cnt_o\"]],palette=\"viridis\", width=0.6, linewidth=0.01, scale=\"linear\", ax=ax1)\n",
    "    ax1.set_ylabel(\"Count\", fontsize=15)\n",
    "    \n",
    "    ax2=sns.violinplot(data=three_df[[\"o_proportion\"]], linewidth=0.6, inner=\"box\", width=0.6, color=\"lightgray\", ax=ax2)  \n",
    "    ax2.set_ylabel(\"Proportion\", fontsize=15)\n",
    "    ax2.grid()\n",
    "    plt.grid(b=None)\n",
    "    \n",
    "    return three_df   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee0837f",
   "metadata": {},
   "source": [
    "## 3-5. Complexity of CSS in genic area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82de6f2",
   "metadata": {},
   "source": [
    "**[back to index](#Index)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941ed854",
   "metadata": {},
   "source": [
    "### 3-5-1. Create a matrix to show the statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae4d733",
   "metadata": {},
   "source": [
    "#### Function: `complexity_overview_mat`\n",
    "\n",
    "* Usage: Produce a dataframe describing the complexity of the CSS pattern\n",
    "* Input: list of css (Here, `gene_css_all` which is pickled at `\"../database/temp_files/\"`)\n",
    "* Columns: `[\"length\",\"uniq\",\"switch\",\"uniq_pro\",\"switch_pro\"]`\n",
    "* `length`: gene length\n",
    "* `uniq`: How many unique states are \n",
    "* `switch`: How many times the states changed\n",
    "* `uniq_pro`: Proportion of `uniq` per gene length\n",
    "* `switch_pro`: Proportion of `switch` per gene length\n",
    "* Output: dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc7db6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complexity_overview_mat(chr_gene_css):\n",
    "    abs_uniq_all=[]\n",
    "    abs_switch_all=[]\n",
    "    gene_len_all=[]\n",
    "    compl_uniq_all=[]\n",
    "    compl_swit_all=[]\n",
    "    for num in range(len(chr_gene_css)):\n",
    "        gene_css=chr_gene_css[num]\n",
    "        gene_css_len=len(gene_css)\n",
    "        css_uniq=len(set(gene_css)) # only the unique css (min=1, max=gene_css_len)\n",
    "        \n",
    "        tot_char=\"\"\n",
    "        for i, char in enumerate(gene_css):\n",
    "            if i==0 or char!=gene_css[i-1]:\n",
    "                tot_char+=char\n",
    "            css_switch=len(tot_char) # num. of swtiching in css (min=1, max=gene_css_len)\n",
    "            complexity_uniq=css_uniq/gene_css_len\n",
    "            complexity_swit=css_switch/gene_css_len\n",
    "        \n",
    "        gene_len_all.append(gene_css_len)\n",
    "        abs_uniq_all.append(css_uniq)\n",
    "        abs_switch_all.append(css_switch)\n",
    "        compl_uniq_all.append(complexity_uniq)\n",
    "        compl_swit_all.append(complexity_swit)\n",
    "        \n",
    "    data=list(zip(gene_len_all,abs_uniq_all, abs_switch_all,compl_uniq_all,compl_swit_all))\n",
    "    df=pd.DataFrame(data,columns=[\"length\",\"uniq\",\"switch\",\"uniq_pro\",\"switch_pro\"])\n",
    "    df=df[df[\"length\"]>=2]  # remove when the length = 1 unit (=200 bps)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d90957e",
   "metadata": {},
   "source": [
    "### 3-5-2. Extract the complex and less complex css on gene"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564e0090",
   "metadata": {},
   "source": [
    "#### Function: `extract_complex_css`\n",
    "\n",
    "* Usage: Return two lists (css on complex gene / less complex gene) \n",
    "* Input: list of css (Here, `gene_css_all` which is pickled as `\"../database/temp_files/css_gene_unit_lst_all\"`)\n",
    "* Output: `comp_gene_css_all`,`less_comp_gene_css_all`\n",
    "* Above output files are stored as pickle, at `\"../database/temp_files/complexity` using following commands:\n",
    "\n",
    "`with open(\"../database/temp_files/complexity/thres_mean/comp\", \"wb\") as f:\n",
    "    pickle.dump(comp_gene_css_all,f)`\n",
    "    \n",
    "`with open(\"../database/temp_files/complexity/thres_mean/less_comp\", \"wb\") as g:\n",
    "    pickle.dump(less_comp_gene_css_all,g)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1abea07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract according to the complexity\n",
    "\n",
    "def extract_complex_css(gene_css_all, thres=\"mean\"):\n",
    "    '''\n",
    "    Load the file first by `pickle.load(open(\"../database/temp_files/css_gene_unit_lst_all\",\"rb\"))`\n",
    "    This function will extract the css of gene which is defined as complex in css pattern.\n",
    "    '''\n",
    "    tot_gene_css=flatLst(gene_css_all) # flatten it from 24 chromosomes\n",
    "    tot_gene_css=[gene_css for gene_css in tot_gene_css if len(gene_css)>=2] # length<2 removed\n",
    "    \n",
    "    df=complexity_overview_mat(tot_gene_css) # from the process, length<2 was removed\n",
    "    # df columns=[\"length\",\"uniq\",\"switch\",\"uniq_pro\",\"switch_pro\"]     \n",
    "    assert len(tot_gene_css)==len(df), \"length of tot_gene_css and df do not match\"\n",
    "    \n",
    "    df[\"css\"]=tot_gene_css # add new column with css (per gene)\n",
    "        \n",
    "    comp_gene_css_all=[]\n",
    "    less_comp_gene_css_all=[]\n",
    "    \n",
    "    if thres==\"mean\":\n",
    "        thres_val=np.mean(df[\"switch_pro\"])\n",
    "    \n",
    "    for i, css in enumerate(tot_gene_css):\n",
    "        if df[\"switch_pro\"].iloc[i]>=thres_val:\n",
    "            comp_gene_css_all.append(df[\"css\"].iloc[i])\n",
    "        else:\n",
    "            less_comp_gene_css_all.append(df[\"css\"].iloc[i])\n",
    "        \n",
    "    return comp_gene_css_all,less_comp_gene_css_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ed9ac8",
   "metadata": {},
   "source": [
    "### 3-5-2-1. CSS for 57 Epigenomes Complex and Less Complex Genic regions are saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8266c402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the complex and less complex genic area of the 57 epigenomes, in CSS unit sequences\n",
    "# Following function has been already executed, and pickled at \"../database/temp_files/complexity/thres_mean/byCellType/\"\n",
    "\n",
    "def extCompGenic_byCell(output_path=\"../database/temp_files/complexity/\", thres=\"mean\", all_file=True, verbose=True, **kwargs):\n",
    "    \"\"\"\n",
    "    This function extract CSS complex and less-complex genic region, according to the threshold.\n",
    "    (1) To process all the .pkl file in ../database/temp_files/whole_gene_unit/, set 'all_file=True'.\n",
    "        If you want to process only one file at a time, set e.g.) 'file=E003_css_gene_unit_lst_all.pkl'\n",
    "    \"\"\"\n",
    "    \n",
    "    css_gene_path=\"../database/temp_files/whole_gene_unit/\"\n",
    "    if thres==\"mean\":\n",
    "        output_path_mod=output_path+\"thres_\"+thres+\"/byCellType/\"\n",
    "    else:\n",
    "        print(\"No threshold other than 'mean'.\")\n",
    "    \n",
    "    # File list of CSS on genic region for all cell types\n",
    "    files_under_folder=sorted(os.listdir(css_gene_path))\n",
    "    cell_gene_css_all=[file for file in files_under_folder if file.startswith('E') and file.endswith('.pkl')]\n",
    "    \n",
    "    if all_file:\n",
    "        if verbose: print(\"processing all files ...\")\n",
    "        for epi_css in tqdm_notebook(cell_gene_css_all):             \n",
    "            epi_num=epi_css[:4] # e.g.) E003\n",
    "            if verbose: print(\"{} is now processed ...\".format(epi_num))\n",
    "            file_path=css_gene_path+epi_css\n",
    "            with open(file_path,\"rb\") as f:\n",
    "                cell_gene_css=pickle.load(f)\n",
    "            comp_gene_css,less_comp_gene_css=extract_complex_css(cell_gene_css, thres=thres)\n",
    "            comp_name=output_path_mod+epi_num+\"_comp_gene_css.pkl\"\n",
    "            less_name=output_path_mod+epi_num+\"_less_comp_gene_css.pkl\"\n",
    "            with open(comp_name,\"wb\") as g:\n",
    "                pickle.dump(comp_gene_css, g)\n",
    "            with open(less_name,\"wb\") as h:\n",
    "                pickle.dump(less_comp_gene_css, h)  \n",
    "                           \n",
    "    elif len(kwargs)>0:\n",
    "        for file_key, file_name in kwargs.items():            \n",
    "            epi_num=file_name[:4]\n",
    "            file_path=css_gene_path+file_name\n",
    "            if verbose: print(\"all_file=False, processing single case for {}.\".format(epi_num))\n",
    "            with open(file_path,\"rb\") as f:\n",
    "                cell_gene_css=pickle.load(f)\n",
    "            comp_gene_css,less_comp_gene_css=extract_complex_css(cell_gene_css, thres=thres)\n",
    "            comp_name=output_path_mod+epi_num+\"_comp_gene_css.pkl\"\n",
    "            less_name=output_path_mod+epi_num+\"_less_comp_gene_css.pkl\"\n",
    "            with open(comp_name,\"wb\") as g:\n",
    "                pickle.dump(comp_gene_css, g)\n",
    "            with open(less_name,\"wb\") as h:\n",
    "                pickle.dump(less_comp_gene_css, h)               \n",
    "    else:\n",
    "        raise ValueError(\"Set all_file=True, or desginate any file name to proceed!\")\n",
    "    \n",
    "    return print(\"Results are stored at {}\".format(output_path_mod))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebc161c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4b3f3dc",
   "metadata": {},
   "source": [
    "### 3-5-3. Cut into Kmer and save"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17143094",
   "metadata": {},
   "source": [
    "#### Function: `css_CUT_Kmer` (general form of `chr_css_CUT_Kmer`)\n",
    "\n",
    "* Usage: For any list of CSS, cut them when it is longer than `cut_thres`, and make it `k`-mer\n",
    "* Input: list of css (Here, `comp_gene_css_all` which is generated from the above fnt `extract_complex_css`)\n",
    "* Output: `splitted` (raw splitted list),`kmerized_unit_css` (k-merized form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2e95380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut if it is longer than 510\n",
    "def css_CUT_Kmer(css, cut_thres=510, k=5):\n",
    "    \"\"\" \n",
    "    A GENERAL version of `chr_css_CUT_Kmer` and updated to remove any nan in sequence\n",
    "    Prepare kmer dataset for unit_css, as is if length<=510, else cut it to be length>510   \n",
    "    Usage: css_CUT_Kmer(css, cut_thres, k)\n",
    "    \n",
    "    - css: unit-length css (e.g. comp_gene_css_all)\n",
    "    - cut_thres: length of split, default=510\n",
    "    - k: kmer\n",
    "    \n",
    "    Output: 1. splitted (before kmerization) 2. kmerized_unit_css (after kmerization) \n",
    "    \"\"\"    \n",
    "    splitted=[] # bucket for the all the splitted strings   \n",
    "    for css_elm in css:\n",
    "        if len(css_elm) <k:  # if the length of css_elm is shorter than k (cannot create k-mer)\n",
    "            continue\n",
    "        elif len(css_elm) <=cut_thres:\n",
    "            splitted.append(css_elm)\n",
    "        else:  \n",
    "            prev=0\n",
    "            while True:\n",
    "                splitted.append(css_elm[prev:prev+cut_thres])\n",
    "                prev+=cut_thres\n",
    "                if prev>=len(css_elm)-1:\n",
    "                    break      \n",
    "\n",
    "    kmerized_unit_css_raw=[seq2kmer(item, k) for item in splitted] # k-merize here\n",
    "    \n",
    "    ### this part is updated to prevent any empty string to be generated ###\n",
    "    kmerized_unit_css=[item for item in kmerized_unit_css_raw if item!=\"\"]\n",
    "    ########################################################################\n",
    "    \n",
    "    return splitted, kmerized_unit_css"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a03ddb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cut if it is longer than 510\n",
    "# def css_CUT_Kmer(css, cut_thres=510, k=5):\n",
    "#     \"\"\" \n",
    "#     A GENERAL version of `chr_css_CUT_Kmer`\n",
    "#     Prepare kmer dataset for unit_css, as is if length<=510, else cut it to be length>510   \n",
    "#     Usage: css_CUT_Kmer(css, cut_thres, k)\n",
    "    \n",
    "#     - css: unit-length css (e.g. comp_gene_css_all)\n",
    "#     - cut_thres: length of split, default=510\n",
    "#     - k: kmer\n",
    "    \n",
    "#     Output: 1. splitted (before kmerization) 2. kmerized_unit_css (after kmerization) \n",
    "#     \"\"\"    \n",
    "#     splitted=[] # bucket for the all the splitted strings   \n",
    "#     for css_elm in css:\n",
    "#         if len(css_elm) <k:  # if the length of css_elm is shorter than k (cannot create k-mer)\n",
    "#             continue\n",
    "#         elif len(css_elm) <=cut_thres:\n",
    "#             splitted.append(css_elm)\n",
    "#         else:  \n",
    "#             prev=0\n",
    "#             while True:\n",
    "#                 splitted.append(css_elm[prev:prev+cut_thres])\n",
    "#                 prev+=cut_thres\n",
    "#                 if prev>=len(css_elm)-1:\n",
    "#                     break      \n",
    "            \n",
    "#     kmerized_unit_css=[seq2kmer(item, k) for item in splitted] # k-merize here\n",
    "    \n",
    "#     return splitted, kmerized_unit_css"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6685b9d",
   "metadata": {},
   "source": [
    "#### Function: `save_as_txt` \n",
    "\n",
    "* Usage: simply save the list as txt file, under the path, with the designated file name.\n",
    "* Input: list of css (Here, `comp_gene_css_all` which is generated from the fnt `extract_complex_css`)\n",
    "* Remarks: This file includes the above function `css_CUT_Kmer`\n",
    "* Output: None, just displaying that it is saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5b92032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_txt(css, path=\"../database/wo_telo/\", filename=\"complex_gene_all\", cut_thres=510, k=5):\n",
    "    \n",
    "    _, kmerized_unit_css=css_CUT_Kmer(css, cut_thres, k)\n",
    "    \n",
    "    full_path=path+filename+\"_\"+str(k)+\".txt\"\n",
    "    with open(full_path,\"w\") as save_file:\n",
    "        save_file.write(\"\\n\".join(kmerized_unit_css))\n",
    "    return print(\"{} is saved at {}\".format(filename, path))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fec478d",
   "metadata": {},
   "source": [
    "### 3-5-4. Show the composition for each case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51937b52",
   "metadata": {},
   "source": [
    "#### Function: `css_composition_piechart` \n",
    "\n",
    "* Usage: After running `css_CUT_Kmer`, show the composition of CSS in either complex or less complex genic area\n",
    "* Input: splitted_lst can be the first production of the function `css_CUT_Kmer`\n",
    "* complexity: `True`=splitted (produced from `comp_gene_css_all`, `False`=less_splitted (produced from `less_comp_gene_css_all`) \n",
    "* show_pct: threshold to show the percentage in pie chart (default=5)\n",
    "* Output: None, just displaying the pie chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f0a573e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def css_composition_piechart(splitted_lst, complexity=True, show_pct=5):\n",
    "    \"\"\"\n",
    "    Usage: css_composition_piechart(splitted_lst, complexity=True, show_pct=5)\n",
    "    Input: splitted_lst can be the first production of the function \"css_CUT_Kmer\"\n",
    "    complexity: True=splitted (produced from comp_gene_css_all, False=less_splitted (produced from less_comp_gene_css_all)\n",
    "    show_pct: threshold to show the percentage in pie chart\n",
    "    \"\"\"\n",
    "    state_count = {chr(i): 0 for i in range(ord('A'), ord('O')+1)}\n",
    "    for elm in splitted_lst:\n",
    "        for state in elm:\n",
    "            if state in state_count:\n",
    "                state_count[state] += 1  # create a dictionary, value of which is the no. of state appeared overall\n",
    "    total = sum(state_count.values())\n",
    "    sizes = [i/sum(state_count.values())*100 for i in state_count.values()] # percentage of occupation\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "    ax.pie(state_count.values(),colors=[state_col_dict[label] for label in state_count.keys()], autopct=lambda p: '{:.2f}%'.format(p) if p > show_pct else '')\n",
    "\n",
    "    if complexity:\n",
    "        title=\"Complex gene CS composition,\"+\" total:\"+\" \"+str(total)\n",
    "    else:\n",
    "        title=\"Less complex gene CS composition,\"+\" total:\"+\" \"+str(total)\n",
    "    \n",
    "    for t in ax.texts:\n",
    "        t.set_color(\"white\")\n",
    "        t.set_fontsize(20)\n",
    "\n",
    "    ax.set_title(title,fontsize=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2c5898",
   "metadata": {},
   "source": [
    "### 3-5-5. Prepare and save Fine-tuning for Complex gene CSS and others"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147c0ba3",
   "metadata": {},
   "source": [
    "#### Function: `prep_and_saveTF_CompNcomp` \n",
    "\n",
    "* Usage: Prerpare and save the fine-tuning data for **complex** and **less complex gene css**\n",
    "* Input files are loaded inside the function, which are pickled at `\"../database/temp_files/complexity/thres_mean/\"`\n",
    "* Output: None, just displaying the report that the file is saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e3b7949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now for compG and nonCompG (the function covers from prepration to save)\n",
    "def prep_and_saveTF_CompNcomp(condition=\"thres_mean\", cut_thres=510, k=5, save_path=\"CompG_and_lessCompG\",len_tr=20000, len_dev=1000):\n",
    "    \"\"\"\n",
    "    prepare fine tuning data for [the complex gene css / less complex gene css]\n",
    "    \"\"\"\n",
    "    print(\"* Project name: \", save_path)\n",
    "    print(\"* condition: \", condition)\n",
    "    print(\"* Cut threshold length: \", cut_thres)\n",
    "    print(\"* k-merization: \", k)\n",
    "    print(\"* train: dev = {} : {}\".format(len_tr,len_dev))\n",
    "    \n",
    "    comp_path=\"../database/temp_files/complexity/\"+condition+\"/comp\"\n",
    "    comp=pickle.load(open(comp_path, \"rb\"))\n",
    "    less_comp_path=\"../database/temp_files/complexity/\"+condition+\"/less_comp\"\n",
    "    less_comp=pickle.load(open(less_comp_path, \"rb\"))\n",
    "    \n",
    "    # kmerization\n",
    "    _, comp_kmerized=css_CUT_Kmer(comp, cut_thres, k)\n",
    "    _, less_comp_kmerized=css_CUT_Kmer(less_comp, cut_thres, k)\n",
    "    \n",
    "    # make it dataframe\n",
    "    df_comp=pd.DataFrame(comp_kmerized, columns=[\"sequence\"])\n",
    "    df_comp[\"label\"]=1\n",
    "    df_less_comp=pd.DataFrame(less_comp_kmerized, columns=[\"sequence\"])\n",
    "    df_less_comp[\"label\"]=0\n",
    "    \n",
    "    # make them have the same length\n",
    "    if len(df_comp)>len(df_less_comp):\n",
    "        df_comp=df_comp[:len(df_less_comp)] \n",
    "    elif len(df_comp)<len(df_less_comp):\n",
    "        df_less_comp=df_less_comp[:len(df_comp)]\n",
    "    assert len(df_comp)==len(df_less_comp), \"Check the data length.\"\n",
    "    \n",
    "    # shuffling ...\n",
    "    df_comp_all=pd.concat([df_comp,df_less_comp]).sample(frac=1).reset_index(drop=True)  \n",
    "\n",
    "    # cutting into train and dev\n",
    "    assert len(df_comp_all)> len_tr+len_dev, \"Not enough data length.\"\n",
    "    df_comp_train=df_comp_all[:len_tr]\n",
    "    df_comp_dev=df_comp_all[len_tr:len_tr+len_dev]    \n",
    "  \n",
    "    path=\"../database/fine_tune/\"+save_path+\"/\"+str(k)+\"mer/\"\n",
    "    train_name=path+\"train.tsv\"\n",
    "    dev_name=path+\"dev.tsv\"\n",
    "    \n",
    "    df_comp_train.to_csv(train_name, sep=\"\\t\", index=False)\n",
    "    df_comp_dev.to_csv(dev_name, sep=\"\\t\", index=False)\n",
    "\n",
    "    return print(\"Fine-tuning data for {} are {}merized and saved at {}.\".format(save_path,k,path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2565df7f",
   "metadata": {},
   "source": [
    "#### Function: `prep_and_saveTF_CompNgene` \n",
    "\n",
    "* Usage: Prerpare and save the fine-tuning data for **complex** and **None gene css**\n",
    "* Input files are loaded inside the function, which are pickled at `\"../database/temp_files/complexity/thres_mean/\"` for complex gene, and at `\"../database/temp_files/css_Ngene_unit_lst_all\"` for intergenic area (a.k.a. Ngene)\n",
    "* Output: None, just displaying the report that the file is saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72e759e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now,  for compG and non gene (the function covers from prepration to save)\n",
    "def prep_and_saveTF_CompNgene(condition=\"thres_mean\", cut_thres=510, k=5, save_path=\"CompG_and_intergenic\",len_tr=20000, len_dev=1000):\n",
    "    \"\"\"\n",
    "    prepare fine tuning data for [the complex gene css / none gene css]\n",
    "    \"\"\"\n",
    "    print(\"* Project name: \", save_path)\n",
    "    print(\"* condition: \", condition)\n",
    "    print(\"* Cut threshold length: \", cut_thres)\n",
    "    print(\"* k-merization: \", k)\n",
    "    print(\"* train: dev = {} : {}\".format(len_tr,len_dev))\n",
    "    \n",
    "    comp_path=\"../database/temp_files/complexity/\"+condition+\"/comp\"\n",
    "    comp=pickle.load(open(comp_path, \"rb\"))\n",
    "    Ngene_path=\"../database/temp_files/css_Ngene_unit_lst_all\"\n",
    "    Ngene=pickle.load(open(Ngene_path, \"rb\"))\n",
    "    #flatten\n",
    "    Ngene=flatLst(Ngene)\n",
    "    \n",
    "    # kmerization\n",
    "    _, comp_kmerized=css_CUT_Kmer(comp, cut_thres, k)\n",
    "    _, Ngene_kmerized=css_CUT_Kmer(Ngene, cut_thres, k)\n",
    "    \n",
    "    # make it dataframe\n",
    "    df_comp=pd.DataFrame(comp_kmerized, columns=[\"sequence\"])\n",
    "    df_comp[\"label\"]=1\n",
    "    df_Ngene=pd.DataFrame(Ngene_kmerized, columns=[\"sequence\"])\n",
    "    df_Ngene[\"label\"]=0\n",
    "    \n",
    "    # make them have the same length\n",
    "    if len(df_comp)>len(df_Ngene):\n",
    "        df_comp=df_comp[:len(df_Ngene)] \n",
    "    elif len(df_comp)<len(df_Ngene):\n",
    "        df_Ngene=df_Ngene[:len(df_comp)]\n",
    "    assert len(df_comp)==len(df_Ngene), \"Check the data length.\"\n",
    "    \n",
    "    # shuffling ...\n",
    "    df_compNgene=pd.concat([df_comp,df_Ngene]).sample(frac=1).reset_index(drop=True)  \n",
    "\n",
    "    # cutting into train and dev\n",
    "    assert len(df_compNgene)> len_tr+len_dev, \"Not enough data length.\"\n",
    "    df_compNgene_train=df_compNgene[:len_tr]\n",
    "    df_compNgene_dev=df_compNgene[len_tr:len_tr+len_dev]    \n",
    "  \n",
    "    path=\"../database/fine_tune/\"+save_path+\"/\"+str(k)+\"mer/\"\n",
    "    train_name=path+\"train.tsv\"\n",
    "    dev_name=path+\"dev.tsv\"\n",
    "    \n",
    "    df_compNgene_train.to_csv(train_name, sep=\"\\t\", index=False)\n",
    "    df_compNgene_dev.to_csv(dev_name, sep=\"\\t\", index=False)\n",
    "\n",
    "    return print(\"Fine-tuning data for {} are {}merized and saved at {}.\".format(save_path,k,path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f34a8a8",
   "metadata": {},
   "source": [
    "## 3-6. Gene expression classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f281fb8",
   "metadata": {},
   "source": [
    "For more difficult tasks, gene expression can be one of the criteria to prepare fine tuning data. First, using the gene expression level from RNA-seq, highly expressed "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a68f0eb",
   "metadata": {},
   "source": [
    "### 3-6-1. Gene expression file into the list of dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566e76a2",
   "metadata": {},
   "source": [
    "#### Function: `Gexp_Gene2GLChr`\n",
    "\n",
    "* This function only checks a single file.\n",
    "* Usage: After the gene expression files such as `gene_highlyexpressed.refFlat` are acquired by `/database/bed/gene_expression/classifygenes_ROADMAP_RPKM.py`, apply this function to obtain the list of dataframe per chromosome contains the transcription start and end indices.\n",
    "* Input: gene expression (high/low/not) file\n",
    "* Output: a chromosome-wise list of dataframe containing `TxStart` and `TxEnd`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3628ef37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for preprocess the whole gene data and produce chromosome-wise gene lists\n",
    "# each element is dataframe\n",
    "\n",
    "### this function is not essential, but just to check by create df from .refFlat\n",
    "def Gexp_Gene2GLChr(exp_gene_file='../database/bed/gene_expression/E050/gene_highlyexpressed.refFlat'):\n",
    "    print(\"Extracting the gene file ...\")\n",
    "    g_fn=exp_gene_file\n",
    "    g_df_raw=pd.read_csv(g_fn, sep='\\t', index_col=False, header=0)\n",
    "    g_df=g_df_raw\n",
    "    g_df=g_df.iloc[:,1:]\n",
    "    g_df.rename(columns={\"name\":\"gene_id\"}, inplace=True)\n",
    "    g_df.rename(columns={\"#geneName\":\"geneName\"}, inplace=True)\n",
    "    g_df.rename(columns={\"txStart\":\"TxStart\"}, inplace=True) # to make it coherent to my previous codes\n",
    "    g_df.rename(columns={\"txEnd\":\"TxEnd\"}, inplace=True)\n",
    "#     g_df=g_df_raw.rename(columns={0:\"geneName\",1:\"gene_id\",2:\"chrom\",3:\"strand\",4:\"txStart\",5:\"txEnd\",\n",
    "#                                       6:\"cdsStart\",7:\"cdsEnd\",8:\"exonCount\",9:\"exonStart\",10:\"exonEnds\",\n",
    "#                                       11:\"gene type\",12:\"transcript type\",13:\"reference transcript name\",\n",
    "#                                       14:\"reference transcription id\"})\n",
    "    ## string to the list of \"int\", for exon start/end ##\n",
    "    g_df_temp=g_df # copy for processing\n",
    "    exon_start_int_lst=[]\n",
    "    for i, str_lst in enumerate(g_df_temp[\"exonStarts\"]):\n",
    "        int_lst=[int(elm) for elm in str_lst.replace(\"[\",\"\").replace(\"]\",\"\").split(\",\")]\n",
    "        assert g_df_temp[\"exonCount\"][i]==len(int_lst) # make sure the no. element in exon st count\n",
    "        exon_start_int_lst.append(int_lst)    \n",
    "    g_df_temp[\"exonStarts\"]=exon_start_int_lst\n",
    "\n",
    "    exon_end_int_lst=[]\n",
    "    for i, str_lst in enumerate(g_df_temp[\"exonEnds\"]):\n",
    "        int_lst=[int(elm) for elm in str_lst.replace(\"[\",\"\").replace(\"]\",\"\").split(\",\")]\n",
    "        assert g_df_temp[\"exonCount\"][i]==len(int_lst) # make sure the no. element in exon start = count\n",
    "        exon_end_int_lst.append(int_lst)    \n",
    "    g_df_temp[\"exonEnds\"]=exon_end_int_lst    \n",
    "    g_df=g_df_temp # and make it back the original name\n",
    "        \n",
    "    g_df=g_df[[\"geneName\",\"gene_id\",\"chrom\",\"TxStart\",\"TxEnd\"]] # extract these only\n",
    "    \n",
    "    # Remove other than regular chromosomes\n",
    "    chr_lst=['chr1','chr2','chr3','chr4','chr5','chr6','chr7','chr8','chr9','chr10',\n",
    "             'chr11','chr12','chr13','chr14','chr15','chr16','chr17','chr18','chr19',\n",
    "             'chr20','chr21','chr22','chrX','chrY']\n",
    "    g_df=g_df.loc[g_df[\"chrom\"].isin(chr_lst)]\n",
    "    \n",
    "    # Create a list of chromosome-wise dataframe \n",
    "    g_df_chr_lst=[]\n",
    "    for num in range(len(chr_lst)):\n",
    "        chr_num=chr_lst[num]\n",
    "        g_chr_df='g_'+chr_num  # name it as \"g_\"\n",
    "        locals()[g_chr_df]=g_df[g_df[\"chrom\"]==chr_num]\n",
    "        g_chr_df=locals()[g_chr_df]\n",
    "        g_chr_df=g_chr_df.sort_values(\"TxStart\")\n",
    "        g_df_chr_lst.append(g_chr_df)\n",
    "        \n",
    "    # Remove the overlapped area (using removeOverlapDF function in css_utility.py)\n",
    "    g_df_chr_collapsed_lst=[]\n",
    "    for g_df_chr in g_df_chr_lst:\n",
    "        g_df_chr_collapsed=removeOverlapDF(g_df_chr)\n",
    "        assert len(g_df_chr)>=len(g_df_chr_collapsed)\n",
    "        g_df_chr_collapsed_lst.append(g_df_chr_collapsed)\n",
    "    print(\"Done!\")\n",
    "    \n",
    "    return g_df_chr_collapsed_lst  # list of dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d585f5c4",
   "metadata": {},
   "source": [
    "### 3-6-1-1. Not expressed refFlat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afbdf13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de699376",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76914040",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b573fbe",
   "metadata": {},
   "source": [
    "### 3-6-2. Matching to CSS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d361ead",
   "metadata": {},
   "source": [
    "#### Function: `comp_expGene2css`\n",
    "\n",
    "* Usage: modified from `compGene2css`, Use it like  `css_gene_lst_all=comp_expGene2css(\"../database/bed/gene_expression/gene_highlyexpressed.refFlat\",df_e050)`\n",
    "* Input: \n",
    "    * (highly/low/not) expressed gene, such as `\"../database/bed/gene_expression/gene_highlyexpressed.refFlat\"`\n",
    "    * df, acquired from css created by bed2df_expanded\n",
    "* Output\n",
    "    * list of chromosome-wise list that contains the css at (highly/low/not) genic area only.\n",
    "* **caution!** Do not forget to conduct `Convert2unitCSS_main(css_gene_lst_all, unit=200)`, to convert the result into 200-bps unit length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80c7ec5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_expGene2css(exp_gene_file,df):   # df indicates css, created by bed2df_expanded\n",
    "    \"\"\"\n",
    "    modified from `compGene2css`\n",
    "    Input: Reference gene file, df (CSS)\n",
    "    Output: list of chromosome-wise list that contains the css at (expressed) genic area only.\n",
    "    \"\"\"\n",
    "    g_lst_chr=Gexp_Gene2GLChr(exp_gene_file)\n",
    "#     g_lst_chr=whGene2GLChr(whole_gene_file) # list of gene table df per chromosome\n",
    "    css_lst_chr=df2longcss(df) # list of long css per chromosome\n",
    "#     total_chr=len(g_lst_chr)\n",
    "    total_chr=len(css_lst_chr)\n",
    "#     print(\"total_chr=\",total_chr)\n",
    "    \n",
    "    print(\"Matching to the chromatin state sequence data ...\")\n",
    "    css_gene_lst_all=[]\n",
    "    for i in tqdm_notebook(range(total_chr)):\n",
    "        css=css_lst_chr[i]   # long css of i-th chromosome\n",
    "        gene_df=g_lst_chr[i] # gene df of i-th chromosome\n",
    "        \n",
    "        css_gene_lst_chr=[]\n",
    "        for j in range(len(gene_df)):\n",
    "            g_start=gene_df[\"TxStart\"].iloc[j]-1  # python counts form 0\n",
    "            g_end=gene_df[\"TxEnd\"].iloc[j]+1      # python excludes the end\n",
    "            \n",
    "            css_gene=css[g_start:g_end]           # cut the gene area only\n",
    "            css_gene_lst_chr.append(css_gene)     # store in the list\n",
    "          \n",
    "        css_gene_lst_all.append(css_gene_lst_chr)  # list of list\n",
    "    \n",
    "    assert len(css_gene_lst_all)==total_chr\n",
    "    \n",
    "    # remove chromosome if it is empty (e.g. chrY for female)\n",
    "    css_gene_lst_all=[elm for elm in css_gene_lst_all if elm!=[]] \n",
    "            \n",
    "    print(\"Done!\")\n",
    "    return css_gene_lst_all ## this is the original length! reduce it at Convert2unitCSS_main(css_lst_all, unit=200)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc6ae1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f27b03f",
   "metadata": {},
   "source": [
    "### 3-6-2-1. CSS for various gene expression cases are saved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e0abbc",
   "metadata": {},
   "source": [
    "#### Function `extExpGenic_byCell_1_ver01`\n",
    "* From the css bed file for each cell, expressed genic region and highly expressed genic region `refFlat` data are saved by running the \"classifygenes_ROADMAP_RPKM.py\". To complete, execute `extExpGenic_byCell_2`.\n",
    "* Input: output path\n",
    "* Usage example: `extExpGenic_byCell_1_ver01(output_path=\"../database/temp_files/expressed/byCellType/refFlat/\", all_file=False, high_only=True, verbose=True, exp=0, high_exp=10, file=\"E050_15_coreMarks_stateno.bed\")`\n",
    "* In `ver01`, the argument `high_only` is added to produce highly_expressed case only, as the \"expressed\" is the same (rpkm > 0)\n",
    "* This function was executed and the result is already saved. See `../database/bed/gene_expression/byCellType/refFlat/rpkm10`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d3c36ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extExpGenic_byCell_1_ver01(output_path=\"../database/temp_files/expressed/byCellType/refFlat/\", all_file=True, high_only=True, verbose=True, exp=0, high_exp=50, **kwargs):\n",
    "    \"\"\"\n",
    "    RUN THE SECOND function 'extExpGenic_byCell_2' after running this function.\n",
    "    This function extract CSS expressed genic region, mainly for \"expressed\" and \"highly-expressed\"\n",
    "    (1) To process all the  ... set 'all_file=True'.\n",
    "        If you want to process only one file at a time, set e.g.) all_file=False, file=\"E050_15_coreMarks_stateno.bed\"\n",
    "    (2) High_only = True will only produce the highly expressed cases (default) \n",
    "    (3) Outputs are e.g.) \"E112_gene_expressed.refFlat\", \"E112_gene_highlyexpressed.refFlat\" at output path\n",
    "    \"\"\"\n",
    "    \n",
    "    output_path_mod=output_path+\"rpkm\"+str(high_exp)+\"/\"\n",
    "    \n",
    "    path=\"../database/bed/gene_expression/\"\n",
    "    script=\"classifygenes_ROADMAP_RPKM.py\"\n",
    "    epi_rpkm_tsv=\"57epigenomes.RPKM.pc.tsv\"\n",
    "    gene_ref=\"chr.gene.refFlat\"\n",
    "    original_path=\"~/Work/chromatin_state/NSP/\"\n",
    "    \n",
    "    save_path=\"./byCellType/refFlat/\"+\"rpkm\"+str(high_exp)+\"/\"\n",
    "    css_bed_path=\"../database/bed/unzipped/\"\n",
    "\n",
    "    if all_file:\n",
    "        css_gene_path=\"../database/temp_files/whole_gene_unit/\"\n",
    "        # File list of CSS on genic region for all cell types\n",
    "        files_under_folder=sorted(os.listdir(css_gene_path))\n",
    "        cell_gene_css_all=[file for file in files_under_folder if file.startswith('E') and file.endswith('.pkl')]\n",
    "        \n",
    "#         all_css_bed_file=sorted(os.listdir(css_bed_path)) # all css bed file, we need to choose the target\n",
    "#         # list comprehension to choose the targets (57 epigenomes)    \n",
    "#         target_cell_gene_css=[css_bed for css_bed in all_css_bed_file for epi in cell_gene_css_all if css_bed[:4]==epi[:4]]\n",
    "        \n",
    "        if verbose: print(\"processing all files ...\")\n",
    "        for epi_css in tqdm_notebook(cell_gene_css_all):             \n",
    "            epi_num=epi_css[:4] # e.g.) E003\n",
    "            \n",
    "            if verbose: print(\"{} is now processed ...\".format(epi_num))\n",
    "            file_path=css_bed_path+epi_css\n",
    "#             df=bed2df_expanded(file_path)  # css df\n",
    "\n",
    "            ######## Running the script at working path and come back to the original path #########\n",
    "            %cd -q {path}\n",
    "            %run {script} --thre_expressed {exp} --thre_highlyexpressed {high_exp} {epi_rpkm_tsv} {epi_num} {gene_ref}\n",
    "\n",
    "            if not high_only:\n",
    "                exp_file_name=save_path+epi_num+\"_\"+\"gene_expressed.refFlat\"\n",
    "            hexp_file_name=save_path+epi_num+\"_\"+\"gene_highlyexpressed.refFlat\"\n",
    "            %mv \"gene_expressed.refFlat\" {exp_file_name}\n",
    "            %mv \"gene_highlyexpressed.refFlat\" {hexp_file_name}\n",
    "            %cd -q {original_path}\n",
    "            ########################################################################################\n",
    "                \n",
    "        \n",
    "    elif len(kwargs)>0:       \n",
    "        for file_key, file_name in kwargs.items():            \n",
    "            epi_num=file_name[:4]\n",
    "            if verbose: print(\"all_file=False, processing single case for {}.\".format(epi_num))\n",
    "\n",
    "            file_path=css_bed_path+file_name\n",
    "#             df=bed2df_expanded(file_path)  # css df for the designated file\n",
    "            \n",
    "            ######## Running the script at working path and come back to the original path #########\n",
    "            %cd -q {path}\n",
    "            %run {script} --thre_expressed {exp} --thre_highlyexpressed {high_exp} {epi_rpkm_tsv} {epi_num} {gene_ref}\n",
    "\n",
    "            if not high_only:\n",
    "                exp_file_name=save_path+epi_num+\"_\"+\"gene_expressed.refFlat\"\n",
    "            hexp_file_name=save_path+epi_num+\"_\"+\"gene_highlyexpressed.refFlat\"\n",
    "            %mv \"gene_expressed.refFlat\" {exp_file_name}\n",
    "            %mv \"gene_highlyexpressed.refFlat\" {hexp_file_name}\n",
    "            %cd -q {original_path}\n",
    "            ########################################################################################\n",
    "            \n",
    "    else:\n",
    "        raise ValueError(\"Set all_file=True, or desginate any file name to proceed!\")\n",
    "    assert os.getcwd()[-3:]==\"NSP\", \"Check the current working directory.\"\n",
    "    \n",
    "    return print(\"Results are stored at {}, and current working directory is : {}\".format(output_path_mod, os.getcwd()))\n",
    "                           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e6ed08",
   "metadata": {},
   "source": [
    "#### Function `extExpGenic_byCell_2_ver01`\n",
    "* Expressed genic region, highly expressed genic region's css data are saved.\n",
    "* Input: output path, `high_only` for selecting whether just \"expressed\" will be included. `high_exp` is for designating the RPKM\n",
    "* Output: output folder name will be like `rpkm50`\n",
    "* This function was executed and the result is already saved.\n",
    "* To check the result, visit the output path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f455c4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extExpGenic_byCell_2_ver01(output_path=\"../database/temp_files/expressed/byCellType/\",all_file=True, high_only=True, high_exp=50, verbose=True, **kwargs):\n",
    "    \"\"\"\n",
    "    Should be executed after extExpGenic_byCell_1_ver01\n",
    "    modified the previous version to make it applicalbe to highly_expressed only extraction\n",
    "    with high_only=True, highly expressed gene according to the high_exp value (RPKM) are extracted.\n",
    "    \"\"\"\n",
    "    exp_ref_path=\"../database/bed/gene_expression/byCellType/refFlat/\"\n",
    "    hexp_ref_path=exp_ref_path+\"rpkm\"+str(high_exp)+\"/\"\n",
    "    \n",
    "    ref_exp_file_all=sorted(os.listdir(exp_ref_path))\n",
    "    ref_hexp_file_all=sorted(os.listdir(hexp_ref_path))\n",
    "    \n",
    "    ref_exp_all=[elm for elm in ref_exp_file_all if '_expressed' in elm and elm.startswith('E')]\n",
    "    ref_hexp_all=[elm for elm in ref_hexp_file_all if 'high' in elm and elm.startswith('E')]\n",
    "      \n",
    "    css_gene_path=\"../database/temp_files/whole_gene_unit/\"\n",
    "    css_bed_path=\"../database/bed/unzipped/\"\n",
    "    css_bed_file_all=sorted(os.listdir(css_bed_path))    \n",
    "\n",
    "    if all_file:\n",
    "        if verbose: print(\"processing all files ...\")\n",
    "        for epi_css in tqdm_notebook(ref_hexp_all):\n",
    "            epi_num=epi_css[:4]\n",
    "            if verbose: print(\"{} is now processed ...\".format(epi_num))\n",
    "            # preparing df from bed\n",
    "            target_bed=[elm for elm in css_bed_file_all if elm[:4]==epi_num]\n",
    "            bed_path=css_bed_path+target_bed[0]\n",
    "            df=bed2df_expanded(bed_path)\n",
    "            # preparing ref from exp_refs\n",
    "            target_hexp_ref=[elm for elm in ref_hexp_all if elm[:4]==epi_num]\n",
    "            target_exp_ref=[elm for elm in ref_exp_all if elm[:4]==epi_num]\n",
    "            hexp=hexp_ref_path+target_hexp_ref[0]\n",
    "            exp=exp_ref_path+target_exp_ref[0]\n",
    "\n",
    "            if not high_only:  # extract just 'expressed' case if high_only is False (default=True)\n",
    "                css_exp_gene_lst=comp_expGene2css(exp,df)\n",
    "                css_exp_gene_unit_lst=flatLst(Convert2unitCSS_main(css_exp_gene_lst, unit=200))\n",
    "                with open(output_path+\"expressed/\"+epi_num+\"_exp_gene_css.pkl\",\"wb\") as g:\n",
    "                    pickle.dump(css_exp_gene_unit_lst,g)\n",
    "                    \n",
    "            css_hexp_gene_lst=comp_expGene2css(hexp,df)\n",
    "            css_hexp_gene_unit_lst=flatLst(Convert2unitCSS_main(css_hexp_gene_lst, unit=200))\n",
    "            with open(output_path+\"rpkm\"+str(high_exp)+\"_highly_expressed/\"+epi_num+\"_highly_exp_gene_css.pkl\",\"wb\") as f:\n",
    "                pickle.dump(css_hexp_gene_unit_lst,f)\n",
    "            \n",
    "    elif \"file\" in kwargs:\n",
    "        file_name=kwargs[\"file\"]\n",
    "#         for file_key, file_name in kwargs.items():            \n",
    "        epi_num=file_name[:4]\n",
    "        if verbose: print(\"all_file=False, processing single case for {}.\".format(epi_num))\n",
    "        # preparing df from bed\n",
    "        target_bed=[elm for elm in css_bed_file_all if elm[:4]==epi_num]\n",
    "        bed_path=css_bed_path+target_bed[0]\n",
    "        df=bed2df_expanded(bed_path)\n",
    "        # preparing ref from exp_refs\n",
    "        target_hexp_ref=[elm for elm in ref_hexp_all if elm[:4]==epi_num]\n",
    "        target_exp_ref=[elm for elm in ref_exp_all if elm[:4]==epi_num]\n",
    "        hexp=hexp_ref_path+target_hexp_ref[0]\n",
    "        exp=exp_ref_path+target_exp_ref[0]\n",
    "        \n",
    "        if not high_only:  # extract just 'expressed' case if high_only is False (default=True)\n",
    "            css_exp_gene_lst=comp_expGene2css(exp,df)\n",
    "            css_exp_gene_unit_lst=flatLst(Convert2unitCSS_main(css_exp_gene_lst, unit=200))\n",
    "            with open(output_path+\"expressed/\"+epi_num+\"_exp_gene_css.pkl\",\"wb\") as g:\n",
    "                pickle.dump(css_exp_gene_unit_lst,g)\n",
    "\n",
    "        css_hexp_gene_lst=comp_expGene2css(hexp,df)\n",
    "        css_hexp_gene_unit_lst=flatLst(Convert2unitCSS_main(css_hexp_gene_lst, unit=200))\n",
    "        with open(output_path+\"rpkm\"+str(high_exp)+\"_highly_expressed/\"+epi_num+\"_highly_exp_gene_css.pkl\",\"wb\") as f:\n",
    "            pickle.dump(css_hexp_gene_unit_lst,f)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Set all_file=True, or desginate any file name to proceed!\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f499dc0",
   "metadata": {},
   "source": [
    "#### VER02, just to change the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbaa6d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extExpGenic_byCell_1_ver02(output_path=\"../database/roadmap/gene_exp/refFlat_byCellType/\", all_file=True, high_only=True, verbose=True, exp=0, high_exp=50, **kwargs):\n",
    "    \"\"\"\n",
    "    RUN THE SECOND function 'extExpGenic_byCell_2_ver02' after running this function.\n",
    "    This pipeline is to extract CSS expressed genic region, mainly for \"expressed\" and \"highly-expressed\"\n",
    "    In this function, the refFlat file for each epigenomes are extracted and saved at output path\n",
    "    \n",
    "    **** You need to create the folder first, at the save path\n",
    "    \n",
    "    (1) To process all the  ... set 'all_file=True'.\n",
    "        If you want to process only one file at a time, set e.g.) all_file=False, file=\"E050_15_coreMarks_stateno.bed\"\n",
    "    (2) High_only = True will only produce the highly expressed cases (default) \n",
    "    (3) Outputs are e.g.) \"E112_gene_expressed.refFlat\", \"E112_gene_highlyexpressed.refFlat\" at output path\n",
    "    \"\"\"\n",
    "    \n",
    "    output_path_mod=output_path+\"rpkm\"+str(high_exp)+\"/\"\n",
    "    \n",
    "    path=\"../database/roadmap/gene_exp/\"\n",
    "    script=\"classifygenes_ROADMAP_RPKM.py\"\n",
    "    epi_rpkm_tsv=\"57epigenomes.RPKM.pc.tsv\"\n",
    "    gene_ref=\"chr.gene.refFlat\"\n",
    "    original_path=\"~/Work/chromatin_state/NSP/\"\n",
    "    \n",
    "    save_path=\"./refFlat_byCellType/\"+\"rpkm\"+str(high_exp)+\"/\"\n",
    "    css_bed_path=\"../database/bed/unzipped/\"\n",
    "\n",
    "    if all_file:\n",
    "        css_gene_path=\"../database/temp_files/whole_gene_unit/\"\n",
    "        # File list of CSS on genic region for all cell types\n",
    "        files_under_folder=sorted(os.listdir(css_gene_path))\n",
    "        cell_gene_css_all=[file for file in files_under_folder if file.startswith('E') and file.endswith('.pkl')]\n",
    "    \n",
    "        if verbose: print(\"processing all files ...\")\n",
    "        for epi_css in tqdm_notebook(cell_gene_css_all):             \n",
    "            epi_num=epi_css[:4] # e.g.) E003\n",
    "            \n",
    "            if verbose: print(\"{} is now processed ...\".format(epi_num))\n",
    "            file_path=css_bed_path+epi_css\n",
    "#             df=bed2df_expanded(file_path)  # css df\n",
    "\n",
    "            ######## Running the script at working path and come back to the original path #########\n",
    "            %cd -q {path}\n",
    "            %run {script} --thre_expressed {exp} --thre_highlyexpressed {high_exp} {epi_rpkm_tsv} {epi_num} {gene_ref}\n",
    "\n",
    "            if not high_only:\n",
    "                exp_file_name=save_path+epi_num+\"_\"+\"gene_expressed.refFlat\"\n",
    "            hexp_file_name=save_path+epi_num+\"_\"+\"gene_highlyexpressed.refFlat\"\n",
    "            %mv \"gene_expressed.refFlat\" {exp_file_name}\n",
    "            %mv \"gene_highlyexpressed.refFlat\" {hexp_file_name}\n",
    "            %cd -q {original_path}\n",
    "            ########################################################################################\n",
    "                \n",
    "        \n",
    "    elif len(kwargs)>0:       \n",
    "        for file_key, file_name in kwargs.items():            \n",
    "            epi_num=file_name[:4]\n",
    "            if verbose: print(\"all_file=False, processing single case for {}.\".format(epi_num))\n",
    "\n",
    "            file_path=css_bed_path+file_name\n",
    "#             df=bed2df_expanded(file_path)  # css df for the designated file\n",
    "            \n",
    "            ######## Running the script at working path and come back to the original path #########\n",
    "            %cd -q {path}\n",
    "            %run {script} --thre_expressed {exp} --thre_highlyexpressed {high_exp} {epi_rpkm_tsv} {epi_num} {gene_ref}\n",
    "\n",
    "            if not high_only:\n",
    "                exp_file_name=save_path+epi_num+\"_\"+\"gene_expressed.refFlat\"\n",
    "            hexp_file_name=save_path+epi_num+\"_\"+\"gene_highlyexpressed.refFlat\"\n",
    "            %mv \"gene_expressed.refFlat\" {exp_file_name}\n",
    "            %mv \"gene_highlyexpressed.refFlat\" {hexp_file_name}\n",
    "            %cd -q {original_path}\n",
    "            ########################################################################################\n",
    "            \n",
    "    else:\n",
    "        raise ValueError(\"Set all_file=True, or desginate any file name to proceed!\")\n",
    "    assert os.getcwd()[-3:]==\"NSP\", \"Check the current working directory.\"\n",
    "    \n",
    "    return print(\"Results are stored at {}, and current working directory is : {}\".format(output_path_mod, os.getcwd()))\n",
    "                           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9c9a69",
   "metadata": {},
   "source": [
    "#### VER02, just to change the path (and the function `Convert2unitCSS_main_new`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c372782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extExpGenic_byCell_2_ver02(output_path=\"../database/roadmap/gene_exp/css_byCellType/\",all_file=True, high_only=True, high_exp=50, verbose=True, **kwargs):\n",
    "    \"\"\"\n",
    "    Should be executed after extExpGenic_byCell_1_ver01\n",
    "    modified the previous version to make it applicalbe to highly_expressed only extraction\n",
    "    with high_only=True, highly expressed gene according to the high_exp value (RPKM) are extracted.\n",
    "    \"\"\"\n",
    "    exp_ref_path=\"../database/roadmap/gene_exp/refFlat_byCellType/rpkm0/\"\n",
    "    hexp_ref_path=\"../database/roadmap/gene_exp/refFlat_byCellType/\"+\"rpkm\"+str(high_exp)+\"/\"\n",
    "    \n",
    "    ref_exp_file_all=sorted(os.listdir(exp_ref_path))\n",
    "    ref_hexp_file_all=sorted(os.listdir(hexp_ref_path))\n",
    "    \n",
    "    ref_exp_all=[elm for elm in ref_exp_file_all if '_expressed' in elm and elm.startswith('E')]\n",
    "    ref_hexp_all=[elm for elm in ref_hexp_file_all if 'high' in elm and elm.startswith('E')]\n",
    "      \n",
    "    css_gene_path=\"../database/roadmap/gene_css_unit_pickled/\"  # this is without chrM\n",
    "    css_bed_path=\"../database/bed/unzipped/\"\n",
    "    css_bed_file_all=sorted(os.listdir(css_bed_path))    \n",
    "\n",
    "    if all_file:\n",
    "        if verbose: print(\"processing all files ...\")\n",
    "        for epi_css in tqdm_notebook(ref_hexp_all):\n",
    "            epi_num=epi_css[:4]\n",
    "            if verbose: print(\"{} is now processed ...\".format(epi_num))\n",
    "#             ########### preparing df from bed\n",
    "#             target_bed=[elm for elm in css_bed_file_all if elm[:4]==epi_num]\n",
    "#             bed_path=css_bed_path+target_bed[0]\n",
    "#             df=bed2df_expanded(bed_path)\n",
    "            \n",
    "            ## load pickled df, to reduce the computation load\n",
    "            epi_df_path=\"../database/roadmap/df_pickled/\"+epi_num+\"_df_pickled.pkl\"\n",
    "            with open(epi_df_path, \"rb\") as f:\n",
    "                df=pickle.load(f)\n",
    "            df = df[df['chromosome'] != 'chrM']   # to remove the chromosome M\n",
    "\n",
    "            # preparing ref from exp_refs\n",
    "            target_hexp_ref=[elm for elm in ref_hexp_all if elm[:4]==epi_num]\n",
    "            target_exp_ref=[elm for elm in ref_exp_all if elm[:4]==epi_num]\n",
    "            hexp=hexp_ref_path+target_hexp_ref[0]\n",
    "            exp=exp_ref_path+target_exp_ref[0]\n",
    "\n",
    "            if not high_only:  # extract just 'expressed' case if high_only is False (default=True)\n",
    "                css_exp_gene_lst=comp_expGene2css(exp,df)  \n",
    "                css_exp_gene_unit_lst=flatLst(Convert2unitCSS_main_new(css_exp_gene_lst, unit=200)) # new\n",
    "                with open(output_path+\"rpkm0/\"+epi_num+\"_exp_gene_css.pkl\",\"wb\") as g:\n",
    "                    pickle.dump(css_exp_gene_unit_lst,g)\n",
    "                    \n",
    "            css_hexp_gene_lst=comp_expGene2css(hexp,df)\n",
    "            css_hexp_gene_unit_lst=flatLst(Convert2unitCSS_main_new(css_hexp_gene_lst, unit=200)) #new\n",
    "            with open(output_path+\"rpkm\"+str(high_exp)+\"/\"+epi_num+\"_rpkm\"+str(high_exp)+\"_exp_gene_css.pkl\",\"wb\") as f:\n",
    "                pickle.dump(css_hexp_gene_unit_lst,f)\n",
    "            \n",
    "    elif \"file\" in kwargs:\n",
    "        file_name=kwargs[\"file\"]\n",
    "#         for file_key, file_name in kwargs.items():            \n",
    "        epi_num=file_name[:4]\n",
    "        if verbose: print(\"all_file=False, processing single case for {}.\".format(epi_num))\n",
    "        # preparing df from bed\n",
    "        target_bed=[elm for elm in css_bed_file_all if elm[:4]==epi_num]\n",
    "        bed_path=css_bed_path+target_bed[0]\n",
    "        df=bed2df_expanded(bed_path)\n",
    "        # preparing ref from exp_refs\n",
    "        target_hexp_ref=[elm for elm in ref_hexp_all if elm[:4]==epi_num]\n",
    "        target_exp_ref=[elm for elm in ref_exp_all if elm[:4]==epi_num]\n",
    "        hexp=hexp_ref_path+target_hexp_ref[0]\n",
    "        exp=exp_ref_path+target_exp_ref[0] \n",
    "        \n",
    "        if not high_only:  # extract just 'expressed' case if high_only is False (default=True)\n",
    "            css_exp_gene_lst=comp_expGene2css(exp,df)\n",
    "            css_exp_gene_unit_lst=flatLst(Convert2unitCSS_main_new(css_exp_gene_lst, unit=200))\n",
    "            with open(output_path+\"rpkm0/\"+epi_num+\"_exp_gene_css.pkl\",\"wb\") as g:\n",
    "                pickle.dump(css_exp_gene_unit_lst,g)\n",
    "\n",
    "        css_hexp_gene_lst=comp_expGene2css(hexp,df)\n",
    "        css_hexp_gene_unit_lst=flatLst(Convert2unitCSS_main_new(css_hexp_gene_lst, unit=200))\n",
    "        with open(output_path+\"rpkm\"+str(high_exp)+\"/\"+epi_num+\"_rpkm\"+str(high_exp)+\"_exp_gene_css.pkl\",\"wb\") as f:\n",
    "            pickle.dump(css_hexp_gene_unit_lst,f)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Set all_file=True, or desginate any file name to proceed!\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a7a13c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9389576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5d87817",
   "metadata": {},
   "source": [
    "#### Function `extNOTexp_Genic_byCell`\n",
    "* NOT expressed genic region's css data are saved.\n",
    "* Input: output path\n",
    "* This function was executed and the result is already saved.\n",
    "* To check the result, visit the output path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "78fafee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extNOTexp_Genic_byCell(output_path=\"../database/temp_files/expressed/byCellType/not_expressed/\", all_file=True, verbose=True, **kwargs):\n",
    "#   # This function only compares the whole genic with expressed genic and subtract them.\n",
    "#   # Perhaps should be changed later?\n",
    "#     css_exp_path=\"../database/temp_files/expressed/byCellType/expressed/\"\n",
    "#     css_whole=\"../database/temp_files/whole_gene_unit/\"\n",
    "#     whole_gene_files=sorted(glob.glob(css_whole+\"*.pkl\"))\n",
    "#     exp_gene_files=sorted(glob.glob(css_exp_path+\"*.pkl\"))\n",
    "\n",
    "#     if all_file: \n",
    "#         if verbose: print(\"processing all files ...\")\n",
    "#         for gene_file in tqdm_notebook(whole_gene_files):\n",
    "#             pattern=r'E[0-9]+'\n",
    "#             epi_num=re.findall(pattern, gene_file)[0] # e.g.) 'E003'\n",
    "#             # take expressed gene list for the same cell type\n",
    "#             exp_gene_file=[file for file in exp_gene_files if epi_num in file][0]\n",
    "#             with open(gene_file,\"rb\") as f:\n",
    "#                 whole_gene=flatLst(pickle.load(f))\n",
    "#             with open(exp_gene_file, \"rb\") as g:\n",
    "#                 exp_gene=pickle.load(g)\n",
    "#             not_exp_gene_all=[]\n",
    "#             not_exp_gene=[gene for gene in whole_gene if gene not in exp_gene]\n",
    "#             not_exp_gene_all.append(not_exp_gene)\n",
    "#             with open(output_path+epi_num+\"_not_exp_gene_css.pkl\",\"wb\") as h:\n",
    "#                 pickle.dump(not_exp_gene,h)\n",
    "    \n",
    "#     elif \"file\" in kwargs:\n",
    "#         exp_gene_file=kwargs[\"file\"]    \n",
    "#         epi_num=exp_gene_file[:4]\n",
    "#         exp_gene_file_w_path=css_exp_path+exp_gene_file\n",
    "#         assert epi_num[0]==\"E\", \"File name should start with 'E'. Remove any path before the file name.\"\n",
    "#         if verbose: print(\"all_file=False, processing single case for {}.\".format(epi_num))\n",
    "        \n",
    "#         gene_file=[elm for elm in whole_gene_files if epi_num in elm][0]        \n",
    "#         with open(gene_file,\"rb\") as f:\n",
    "#             whole_gene=flatLst(pickle.load(f))\n",
    "#         with open(exp_gene_file_w_path, \"rb\") as g:\n",
    "#             exp_gene=pickle.load(g)\n",
    "#         not_exp_gene=[gene for gene in whole_gene if gene not in exp_gene]\n",
    "#         with open(output_path+epi_num+\"_not_exp_gene_css.pkl\",\"wb\") as h:\n",
    "#             pickle.dump(not_exp_gene,h)\n",
    "#     else:\n",
    "#         pass\n",
    "#     return print(\"files are saved at {}\".format(output_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ad8edd",
   "metadata": {},
   "source": [
    "#### Function `extNOTexp_Genic_byCell_ver02`\n",
    "* This function is written for produce new not_expressed gene css according to new df, refFlat, as it drops now chrM and chrY if it is female cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9f81e29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extNOTexp_Genic_byCell_ver02(output_path=\"../database/roadmap/gene_exp/css_byCellType/not_exp/\", verbose=True):\n",
    "  # This function only compares the whole genic with expressed genic and subtract them.\n",
    "  # Perhaps should be changed later?\n",
    "    css_exp_path=\"../database/roadmap/gene_exp/css_byCellType/rpkm0/\"\n",
    "    css_whole=\"../database/roadmap/gene_css_unit_pickled/\"\n",
    "    whole_gene_files=sorted(glob.glob(css_whole+\"*.pkl\"))  # 127 cells\n",
    "    exp_gene_files=sorted(glob.glob(css_exp_path+\"*.pkl\")) # 57 cells\n",
    "\n",
    "    if verbose: print(\"processing all files ...\")\n",
    "    for exp in exp_gene_files:\n",
    "        pattern=r'E[0-9]+'\n",
    "        epi_num=re.findall(pattern, exp)[0] # e.g.) 'E003'\n",
    "#         if epi_num==\"E004\":break for test\n",
    "        # take expressed gene list for the same cell type\n",
    "        gene_file=[file for file in whole_gene_files if epi_num in file][0]\n",
    "        with open(gene_file,\"rb\") as f:\n",
    "            whole_gene=flatLst(pickle.load(f))\n",
    "        with open(exp, \"rb\") as g:\n",
    "            exp_gene=pickle.load(g)\n",
    "        not_exp_gene_all=[]\n",
    "        not_exp_gene=[gene for gene in whole_gene if gene not in exp_gene]\n",
    "        not_exp_gene_all.append(not_exp_gene)\n",
    "        with open(output_path+epi_num+\"_not_exp_gene_css.pkl\",\"wb\") as h:\n",
    "            pickle.dump(not_exp_gene,h)\n",
    "    return print(\"files are saved at {}\".format(output_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf40922",
   "metadata": {},
   "source": [
    "### 3-6-3. Cut into Kmer and save"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae219eab",
   "metadata": {},
   "source": [
    "#### Function `save_kmers_ver01`\n",
    "* **Note** that this function for highly_expressed case is not useful because the pretrain is conducted for whole_cell\n",
    "* Input: output path, k for kmerization, kwargs should include \"kind\"\n",
    "* Usage: e.g.) `save_kmers(k=4,kind=\"whole_gene\")`\n",
    "* Output: none, **note** that this function is already executed and `.txt` files for the pretraining have been saved. Visit the output path indicated in the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e52dd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_kmers_ver01(output_path=\"../database/pretrain/expressed/\", high_exp=50, k=4,**kwargs):\n",
    "    \"\"\"\n",
    "    \"kind\" for kwargs can be chosen among (\"whold_gene\",\"not_expressed\",\"expressed\", \"highly_expressed\")\n",
    "    if \"kind\" is highly_expressed, RPKM value should be provided as high_exp.\n",
    "    But this is not very meaningful, because pretrain is conducted with whole_gene only...\n",
    "    \"\"\"\n",
    "    input_path=\"../database/temp_files/\"\n",
    "    epi_num_lst=pd.read_csv(\"../database/temp_files/whole_gene_unit/epigenome_lst.txt\", header=None, names=[\"num\"])\n",
    "    epi_num=epi_num_lst[\"num\"].tolist()\n",
    "    if high_exp:\n",
    "        print(\"The threshold for highly expressed is set as RPKM={}\".format(high_exp))\n",
    "    for num in tqdm_notebook(epi_num):   \n",
    "        if 'kind' in kwargs:\n",
    "            gene_type=kwargs[\"kind\"]\n",
    "            if gene_type==\"whole_gene\":\n",
    "                file_name=input_path+gene_type+\"_unit/\"+num+\"_css_gene_unit_lst_all.pkl\"\n",
    "            elif gene_type==\"not_expressed\":\n",
    "                file_name=input_path+\"expressed/byCellType/\"+gene_type+\"/\"+num+\"_not_exp_gene_css.pkl\"\n",
    "            elif gene_type==\"expressed\":\n",
    "                file_name=input_path+\"expressed/byCellType/\"+gene_type+\"/\"+num+\"_exp_gene_css.pkl\"\n",
    "            ### note that there is subfolder for highly expressed case\n",
    "            elif gene_type==\"highly_expressed\":\n",
    "                file_name=input_path+\"expressed/byCellType/\"+\"rpkm\"+str(high_exp)+\"_\"+gene_type+\"/\"+num+\"_highly_exp_gene_css.pkl\"\n",
    "            else:\n",
    "                pass\n",
    "            with open(file_name, \"rb\") as f:\n",
    "                target=pickle.load(f)\n",
    "                ####### whole_gene is not flat list #######\n",
    "                if gene_type==\"whole_gene\":\n",
    "                    target=flatLst(target)\n",
    "                ###########################################\n",
    "                _, kmerized_unit_css=css_CUT_Kmer(target, k=k)\n",
    "            \n",
    "        if gene_type==\"highly_expressed\":\n",
    "            output_path_mod=output_path+str(k)+\"mer/\"+\"rpkm\"+str(high_exp)+\"_\"+gene_type+\"/\"+num+\"_\"+gene_type+\".txt\"\n",
    "        else:\n",
    "            output_path_mod=output_path+str(k)+\"mer/\"+gene_type+\"/\"+num+\"_\"+gene_type+\".txt\"\n",
    "        with open(output_path_mod,\"w\") as g:\n",
    "            g.write(\"\\n\".join(kmerized_unit_css))           \n",
    "    return \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261a4ecd",
   "metadata": {},
   "source": [
    "#### Function `save_kmers`\n",
    "* The simplest version?\n",
    "* usage: `save_kmers(k=4,kind=\"whole_gene\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1cee494",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_kmers(output_path=\"../database/pretrain/\",k=4,**kwargs):\n",
    "    input_path=\"../database/temp_files/\"\n",
    "    epi_num_lst=pd.read_csv(\"../database/temp_files/whole_gene_unit/epigenome_lst.txt\", header=None, names=[\"num\"])\n",
    "    epi_num=epi_num_lst[\"num\"].tolist()\n",
    "    for num in tqdm_notebook(epi_num):   \n",
    "        if 'kind' in kwargs:\n",
    "            gene_type=kwargs[\"kind\"]\n",
    "            if gene_type==\"whole_gene\":\n",
    "                file_name=input_path+gene_type+\"_unit/\"+num+\"_css_gene_unit_lst_all.pkl\"\n",
    "            elif gene_type==\"not_expressed\":\n",
    "                file_name=input_path+\"expressed/byCellType/\"+gene_type+\"/\"+num+\"_not_exp_gene_css.pkl\"\n",
    "            elif gene_type==\"expressed\":\n",
    "                file_name=input_path+\"expressed/byCellType/\"+gene_type+\"/\"+num+\"_exp_gene_css.pkl\"\n",
    "            elif gene_type==\"highly_expressed\":\n",
    "                file_name=input_path+\"expressed/byCellType/\"+gene_type+\"/\"+num+\"_highly_exp_gene_css.pkl\"\n",
    "            else:\n",
    "                pass\n",
    "            with open(file_name, \"rb\") as f:\n",
    "                target=pickle.load(f)\n",
    "                ####### whole_gene is not flat list #######\n",
    "                if gene_type==\"whole_gene\":\n",
    "                    target=flatLst(target)\n",
    "                ###########################################\n",
    "                _, kmerized_unit_css=css_CUT_Kmer(target, k=k)\n",
    "            output_path_mod=output_path+\"expressed/\"+str(k)+\"mer/\"+gene_type+\"/\"+num+\"_\"+gene_type+\".txt\"\n",
    "            with open(output_path_mod,\"w\") as g:\n",
    "                g.write(\"\\n\".join(kmerized_unit_css))\n",
    "           \n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a455f0a2",
   "metadata": {},
   "source": [
    "### 3-6-4. Fine-tuning data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d603c3",
   "metadata": {},
   "source": [
    "#### Function: `prep_and_saveTF_ver01`\n",
    "* Save the fine-tuning data for gene expression\n",
    "* Three different binary classifications are possible: exp vs. not exp, rpkmNN_highly exp vs. exp, rpkmNN_highly exp vs. not exp\n",
    "* Can be used with following inputs, for example:\n",
    "    <blockquote>\n",
    "    input_path=\"../database/temp_files/expressed/byCellType/\" <br>\n",
    "    output_path=\"../database/fine_tune/gene_exp/4mer/Gexp_or_not\" <br>\n",
    "    cl1=\"expressed\" <br>\n",
    "    cl2=\"not_expressed\" <br>\n",
    "    epi_num_lst=[\"E003\",\"E128\"] <br>\n",
    "    </blockquote>\n",
    "* This function already executed for the above conditions. See `../database/fine_tune/gene_exp/4mer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99b276d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For saving gene expression fine-tuning data\n",
    "def prep_and_saveTF_ver01(input_path, output_path, cl1, cl2, epi_num_lst, cut_thres=510, k=4, len_tr=20000, len_dev=1000):\n",
    "    \"\"\"\n",
    "    * Generallized function for preparing fine tuning data.\n",
    "    * Input path will be in the temp_files\n",
    "    * cl1 and cl2 refer to the name of class you want to classify in binary classification.\n",
    "    * cl1 and cl2 are any of \"expressed\", \"not_expressed\", \"rpkmNN_highly_expressed\" (NN is number)\n",
    "    * epi_num_lst should contain the name of epigenomes like \"E003.\" If you need more, then add like [\"E003\", \"E004\", ...]\n",
    "    \"\"\"\n",
    "    print(\"* Input path: \", input_path)\n",
    "    print(\"* Binary classification for '{}' and '{}'\".format(cl1, cl2))\n",
    "#     ans= \"yes\" if incl_hexp else \"no\"\n",
    "#     print(\"* Including highly expressed case: {}\".format(ans))\n",
    "    print(\"* Output path: \", output_path)\n",
    "    print(\"* Cut threshold length: \", cut_thres)\n",
    "    print(\"* k-merization: \", k)\n",
    "    print(\"* train: dev = {} : {}\".format(len_tr,len_dev))\n",
    "    \n",
    "    cl1_path=input_path+cl1+\"/\"\n",
    "    cl2_path=input_path+cl2+\"/\"\n",
    "    \n",
    "    cl1_concat=[]\n",
    "    cl2_concat=[]\n",
    "    \n",
    "    suffix_dict = {}\n",
    "    for cl in [cl1, cl2]:\n",
    "        if \"highly\" in cl:\n",
    "#             rpkm_no=re.search(r'rpkm(\\d+)',cl).group(1) # no.. this is not required. already inside the name of cl1 an cl2\n",
    "            suffix_dict[cl] = \"_highly_exp_gene_css.pkl\"\n",
    "        elif \"not\" in cl:\n",
    "            suffix_dict[cl] = \"_not_exp_gene_css.pkl\"\n",
    "        else:\n",
    "            suffix_dict[cl] = \"_exp_gene_css.pkl\"\n",
    "    \n",
    "    for cl, concat_lst in [(cl1, cl1_concat), (cl2, cl2_concat)]:\n",
    "        for epi_num in epi_num_lst:\n",
    "            file_path = input_path + cl + \"/\" + epi_num + suffix_dict[cl]\n",
    "            concat_lst.extend(pickle.load(open(file_path, \"rb\")))\n",
    "    \n",
    "    # kmerization\n",
    "    _, cl1_kmerized=css_CUT_Kmer(cl1_concat, cut_thres, k)\n",
    "    _, cl2_kmerized=css_CUT_Kmer(cl2_concat, cut_thres, k)\n",
    "    \n",
    "    # make it dataframe\n",
    "    df_cl1=pd.DataFrame(cl1_kmerized, columns=[\"sequence\"])\n",
    "    df_cl1[\"label\"]=1\n",
    "    df_cl2=pd.DataFrame(cl2_kmerized, columns=[\"sequence\"])\n",
    "    df_cl2[\"label\"]=0\n",
    "    \n",
    "    # make them have the same length\n",
    "    if len(df_cl1)>len(df_cl2):\n",
    "        df_cl1=df_cl1[:len(df_cl2)] \n",
    "    elif len(df_cl1)<len(df_cl2):\n",
    "        df_cl2=df_cl2[:len(df_cl1)]\n",
    "    assert len(df_cl1)==len(df_cl2), \"Check the data length.\"\n",
    "    \n",
    "    # shuffling ...\n",
    "    df_all=pd.concat([df_cl1,df_cl2]).sample(frac=1).reset_index(drop=True)  \n",
    "\n",
    "    # cutting into train and dev\n",
    "    assert len(df_all)> len_tr+len_dev, \"Not enough data length.\"\n",
    "    df_train=df_all[:len_tr]\n",
    "    df_dev=df_all[len_tr:len_tr+len_dev]    \n",
    "  \n",
    "    #path=\"../database/fine_tune/\"+save_path+\"/\"+str(k)+\"mer/\"\n",
    "    \n",
    "    by_tr_len=str(\"{:.0f}\".format(len_tr/1000))\n",
    "    output_path_mod=output_path+\"tr_len_\"+by_tr_len+\"k/\"\n",
    "    \n",
    "    # create a destination folder if it does not exist.\n",
    "    if os.path.exists(output_path_mod):\n",
    "        raise ValueError(\"Folder already exists:{}\".format(output_path_mod))\n",
    "    else:\n",
    "        os.makedirs(output_path_mod)\n",
    "    \n",
    "    train_name=output_path_mod+\"train.tsv\"\n",
    "    dev_name=output_path_mod+\"dev.tsv\"\n",
    "    \n",
    "    df_train.to_csv(train_name, sep=\"\\t\", index=False)\n",
    "    df_dev.to_csv(dev_name, sep=\"\\t\", index=False)\n",
    "\n",
    "    return print(\"Fine-tuning data for {} and {} (epigenome no. {}) are {}merized and saved at {}.\".format(cl1, cl2, epi_num_lst, k, output_path_mod))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10956b62",
   "metadata": {},
   "source": [
    "### 3-6-5. Pie chart statistics: generalized verion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a14e5a",
   "metadata": {},
   "source": [
    "#### Funtion `css_composition_piechart_Gen`\n",
    "* Input: path for .pkl or the list of \"splitted\" acquired directly from the function `css_CUT_Kmer` \n",
    "    * Either one of the path for .pkl or splitted shold be provided. \n",
    "* Usage\n",
    "    * Create a piechar to show the composition of each state in a certain list of css.\n",
    "    * e.g.) `css_composition_piechart_Gen(load_pkl=True, pkl_path=\"../database/temp_files/expressed/byCellType/highly_expressed/\",show_pct=5, title=\"highly_expressed\")`\n",
    "* Output: Just a piechart for showing the composition of the css list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9842d119",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generalized version, for splitted (the result of css_CUT_Kmer) or from the pkl file saved \n",
    "# e.g.) css_composition_piechart_Gen(load_pkl=True, pkl_path=\"../database/temp_files/expressed/byCellType/highly_expressed/\",show_pct=5, title=\"highly_expressed\")\n",
    "def css_composition_piechart_Gen(load_pkl=True, pkl_path=None, splitted=None, show_pct=5, **kwargs):\n",
    "    \"\"\"\n",
    "    Usage: css_composition_piechart using the data from either .pkl or splitted (after running css_CUT_Kmer)\n",
    "    Input: .pkl file path or2for , splitted_lst can be the first production of the function \"css_CUT_Kmer\"\n",
    "    show_pct: threshold to show the percentage in pie chart\n",
    "    \"\"\"\n",
    "    ### case 1. when you load .pkl which is usually stored at ../database/temp_files\n",
    "    if load_pkl:\n",
    "        if pkl_path is None:\n",
    "            raise ValueError(\"Path for the folder including .pkl files is required if load_pkl is True.\")\n",
    "        else:\n",
    "            pkl_files = sorted([f for f in os.listdir(pkl_path) if f.endswith('.pkl')])\n",
    "            css_concat=[]\n",
    "            for pkl_file in pkl_files:\n",
    "                with open(pkl_path + pkl_file, \"rb\") as f:\n",
    "                    css = pickle.load(f)\n",
    "                    if isinstance(css[0], list):\n",
    "                        css_flat = flatLst(css)\n",
    "                        css_concat.extend(css_flat)\n",
    "                    else:\n",
    "                        css_concat.extend(css)\n",
    "        splitted=css_concat\n",
    "\n",
    "    ### case 2. when you use splitted, the first one of the results from the function css_CUT_kmer\n",
    "    else:\n",
    "        if splitted is None:\n",
    "            raise ValueError(\"Splitted is required. Run the css_CUT_Kmer first.\")\n",
    "    \n",
    "    splitted_lst=splitted\n",
    "    num_elm=len(splitted_lst)\n",
    "    print(\"total {} of fragments.\".format(num_elm))\n",
    "    \n",
    "    state_count = {chr(i): 0 for i in range(ord('A'), ord('O')+1)}\n",
    "    for elm in splitted_lst:\n",
    "        for state in elm:\n",
    "            if state in state_count:\n",
    "                state_count[state] += 1  # create a dictionary, value of which is the no. of state appeared overall\n",
    "    total = sum(state_count.values())\n",
    "    sizes = [i/sum(state_count.values())*100 for i in state_count.values()] # percentage of occupation\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2,figsize=(12, 6))\n",
    "\n",
    "    ax1.pie(state_count.values(),colors=[state_col_dict[label] for label in state_count.keys()], autopct=lambda p: '{:.2f}%'.format(p) if p > show_pct else '')\n",
    "\n",
    "    if \"title\" in kwargs:\n",
    "        ax1.set_title(kwargs[\"title\"], fontsize=15)\n",
    "    \n",
    "    for t in ax1.texts:\n",
    "        t.set_color(\"white\")\n",
    "        t.set_fontsize(15)\n",
    "        \n",
    "    # print the list of percentages and states\n",
    "    # uncomment this if you want to use text rather than picture-table\n",
    "#     for state, size in zip(state_count.keys(), sizes):\n",
    "#         num_states = int(round(size * total / 100))\n",
    "#         print(f\"{state}. {num_states} ({size:.2f}%)\")\n",
    "\n",
    "    # Hide axis\n",
    "    ax2.axis('off')\n",
    "\n",
    "    # Create table\n",
    "    table = ax2.table(cellText=list(zip(state_count.keys(), [f\"{size:.2f}\" for size in sizes])),\n",
    "                     colLabels=['State', 'Proportion'],\n",
    "                     cellLoc='center', loc='center')\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(12)\n",
    "    table.scale(0.5, 1)\n",
    "    \n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ecac13",
   "metadata": {},
   "source": [
    "## 3-7. Promoter classification\n",
    "**[back to index](#Index)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c60dd1",
   "metadata": {},
   "source": [
    "### 3-7-1. Prmototer region extraction by location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24deee2f",
   "metadata": {},
   "source": [
    "#### Function `remove_chrM_and_trim_gene_file_accordingly`\n",
    "* remove the chromosome M from the all chromosome per cell, and trim the gene file\n",
    "* outputs now have the same list of chromosomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5664d0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_chrM_and_trim_gene_file_accordingly(whole_gene_file,df):\n",
    "    \n",
    "    ########### new fancy gene table without overlap ###########\n",
    "    g_df_chr_lst=whGene2GLChr(whole_gene_file)  ##### fixed June 29. 2023\n",
    "    new_gene_lst_all=merge_intervals(g_df_chr_lst) ##### fixed June 29. 2023\n",
    "    ############################################################\n",
    "\n",
    "    #### Remove chrM ###########################################\n",
    "    contains_chrM = df['chromosome'].str.contains('chrM').any()  #check whether it contains M\n",
    "    if contains_chrM:\n",
    "        df= df[~df['chromosome'].str.contains('chrM')]\n",
    "\n",
    "    contains_chrY = df['chromosome'].str.contains('chrY').any()\n",
    "\n",
    "    ##### if the target file does not contain Y, remove Y in the gene list file\n",
    "    if not contains_chrY:\n",
    "        new_gene_lst_all=new_gene_lst_all[:-1] ## the final element is for Y\n",
    "    ############################################################\n",
    "\n",
    "    assert len(df[\"chromosome\"].unique())==len(new_gene_lst_all)\n",
    "    return new_gene_lst_all, df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6ee8ff",
   "metadata": {},
   "source": [
    "#### Function `ext_TSS_by_loc`\n",
    "* This function extracts the TSS regions with respect to gene location\n",
    "* Run this function for a cell\n",
    "* Output css are all reduced to unit length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5cc1b1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ext_TSS_by_loc(whole_gene_file, df, up_num=2000, down_num=4000, gene_init=2000, unit=200):\n",
    "    \"\"\"\n",
    "    extract TSS region by location estimation. \n",
    "    input: (1) whole_gene_file: the raw gene bed file (2) df: per cell (3) up_num: upstream (4) down_num: downstream (5) gene_init: how long the initial region would be\n",
    "    output: (1) gene_start_lst_all: only gene start point per chr (2) tss_by_loc_css_unit_all: window_based (3) \n",
    "    \"\"\"\n",
    "    new_gene_lst_all, trimmed_df = remove_chrM_and_trim_gene_file_accordingly(whole_gene_file, df)\n",
    "    \n",
    "    css_lst_chr = df2longcss(trimmed_df) # list of long css per chromosome\n",
    "    total_chr = len(new_gene_lst_all)\n",
    "    \n",
    "    gene_start_lst_all = []\n",
    "    tss_by_loc_css_all = []\n",
    "    tss_by_init_css_all = []\n",
    "    for i in range(total_chr):\n",
    "        gene_start_lst = new_gene_lst_all[i][\"TxStart\"]\n",
    "        gene_start_lst_all.append(gene_start_lst) ### Gene start point only\n",
    "        css_lst = css_lst_chr[i]\n",
    "        \n",
    "        tss_by_loc_css_chr = []\n",
    "        tss_by_init_css_chr = []\n",
    "        for j in range(len(gene_start_lst)):\n",
    "            gene_start = gene_start_lst[j]\n",
    "            win_start = max(0, gene_start - up_num)  # use max to prevent negative index\n",
    "            win_end = min(len(css_lst), gene_start + down_num)  # use min to prevent index out of range\n",
    "\n",
    "            tss_by_loc_css = css_lst[win_start:win_end]\n",
    "            tss_by_loc_css_chr.append(tss_by_loc_css)\n",
    "            \n",
    "            tss_by_init_css = css_lst[gene_start:gene_start+gene_init]\n",
    "            tss_by_init_css_chr.append(tss_by_init_css)\n",
    "            \n",
    "        tss_by_loc_css_all.append(tss_by_loc_css_chr)\n",
    "        tss_by_init_css_all.append(tss_by_init_css_chr)\n",
    "        \n",
    "    tss_by_loc_css_unit_all=Convert2unitCSS_main_new(tss_by_loc_css_all, unit=unit)  \n",
    "    tss_by_init_css_unit_all=Convert2unitCSS_main_new(tss_by_init_css_all,unit=unit)\n",
    "        \n",
    "    return gene_start_lst_all, tss_by_loc_css_unit_all, tss_by_init_css_unit_all   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fb6015",
   "metadata": {},
   "source": [
    "#### Function `css_freq_len`\n",
    "* Input: a list of data strip, for example, genic region data strips (genes) in css\n",
    "* Output: dataframe (index: each chromatin state / columns: `count`,`lengths`,`relative_position`\n",
    "    * (1) count: how frquently it appears per data strip\n",
    "    * (2) lengths: how long it lasts per data strip\n",
    "    * (3) relative_position: where it appears with respect to the total length of the data strip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6db793e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def css_freq_len(css_lst, unit=200):\n",
    "    strings=[item for item in css_lst if item!='']\n",
    "    result = defaultdict(lambda: {'count': [], 'lengths': [], 'relative_position': []})\n",
    "    for string in strings:  # Iterate over each string in the list\n",
    "        total_length = len(string)\n",
    "        for char in set(string):  # loop through unique characters in the string\n",
    "            pattern = re.compile(f'{char}+')\n",
    "            matches = pattern.findall(string)\n",
    "            count = len(matches)\n",
    "            lengths = [len(match)*unit for match in matches]  # multiplied by unit to make it real length\n",
    "            for match in matches:\n",
    "                relative_position = round(((string.index(match) / total_length) * 100) + 1, 2)\n",
    "                result[char]['relative_position'].append(relative_position)\n",
    "            result[char]['count'].append(count)\n",
    "            result[char]['lengths'].extend(lengths)  # Use extend instead of append here\n",
    "    result = dict(result)\n",
    "    # Sort dictionary\n",
    "    sorted_result = OrderedDict(sorted(result.items()))\n",
    "\n",
    "    # Convert the dictionary to a DataFrame\n",
    "    df_cs_wise = pd.DataFrame(sorted_result).transpose()  # transpose to have letters as the index\n",
    "\n",
    "    return df_cs_wise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb587cbc",
   "metadata": {},
   "source": [
    "### 3-7-2. Chromatin state per data strip visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5522a070",
   "metadata": {},
   "source": [
    "#### Function `df_cs_wise2fig`\n",
    "To investigate how each chromatin state (A to O were placed in datasets, e.g. genic regions). <br>\n",
    "This function visualize \n",
    "* (1) count: How frequently a certain chroamtin state appears\n",
    "* (2) lengths: How long it lasts\n",
    "* (3) relative_position: Where it appears  (with respect to the total length)\n",
    "\n",
    "And produces\n",
    "* (1) The distribution of three items above\n",
    "* (2) Correlation between the lengths and relative positions\n",
    "\n",
    "This function can be conducted as followings\n",
    "* (1) `with open(\"../database/roadmap/gene_css_unit_pickled/E001_gene_css_pickled.pkl\",\"rb\") as f:\n",
    "g_e001=pickle.load(f)`\n",
    "* (2) `g_e001_all=flatLst(g_e001)`\n",
    "* (3) `df_g_e001=css_freq_len(g_e001_all, unit=200)`\n",
    "* (4) `df_cs_wise2fig(df_g_e001, chromatin_state=\"A\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79495e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_cs_wise2fig(df_cs_wise, chromatin_state=\"A\"):\n",
    "    color=state_col_dict[chromatin_state]\n",
    "    count_cs=df_cs_wise.loc[chromatin_state][\"count\"]\n",
    "    len_cs=df_cs_wise.loc[chromatin_state][\"lengths\"]\n",
    "    rel_pos_cs=df_cs_wise.loc[chromatin_state][\"relative_position\"]\n",
    "\n",
    "    #### scaler for Z score = (x-mean)/std ####\n",
    "    def standard_scaler(data):\n",
    "        data_np = np.array(data)  # Convert to numpy array\n",
    "        return (data_np - np.mean(data_np)) / np.std(data_np)\n",
    "    ###########################################\n",
    "    \n",
    "    norm_len_cs = standard_scaler(len_cs)\n",
    "    norm_rel_pos_cs = standard_scaler(rel_pos_cs)\n",
    "    \n",
    "    df_len_rel_pos = pd.DataFrame({'norm_len': norm_len_cs, 'norm_rel_pos': norm_rel_pos_cs})\n",
    "    # Calculate the correlation matrix\n",
    "    len_rel_pos_corr = df_len_rel_pos.corr()\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 3, figsize=(7, 2.8))\n",
    "    plt.subplots_adjust(wspace=0.5, hspace=0.5)\n",
    "\n",
    "    sns.violinplot(count_cs, color=color, linewidth=0.8, ax=axs[0])\n",
    "    axs[0].set_xlabel('Count')\n",
    "    axs[0].set_xticklabels([])  # Remove xtick labels\n",
    "    mean_count_cs = np.mean(count_cs)  # Calculate the mean\n",
    "    axs[0].annotate('Mean: {:.2f}'.format(mean_count_cs), xy=(0, 1.05), xycoords=axs[0].transAxes)  # Annotate the mean\n",
    "    axs[0].tick_params(axis='y', labelsize='small')\n",
    "\n",
    "    def thousands(x, pos):\n",
    "        \"\"\"The two args are the value and tick position\"\"\"\n",
    "        return '%1.0fK' % (x * 1e-3) if x >= 1000 else '%1.0f' % x\n",
    "\n",
    "    formatter = ticker.FuncFormatter(thousands)\n",
    "\n",
    "    sns.violinplot(len_cs, color=color,  linewidth=0.8, ax=axs[1])\n",
    "    axs[1].set_xlabel('Length (bps)')\n",
    "\n",
    "    axs[1].yaxis.set_major_formatter(formatter)\n",
    "\n",
    "    axs[1].set_xticklabels([])  # Remove xtick labels\n",
    "    mean_len_cs = np.mean(len_cs)  # Calculate the mean\n",
    "    axs[1].annotate('Mean: {:.1f}'.format(mean_len_cs), xy=(0, 1.05), xycoords=axs[1].transAxes)  # Annotate the mean\n",
    "    axs[1].tick_params(axis='y', labelsize='small')\n",
    "\n",
    "    \n",
    "    sns.violinplot(rel_pos_cs, color=color, linewidth=0.8, ax=axs[2])\n",
    "    axs[2].set_xlabel('Rel_pos (%)')\n",
    "    axs[2].set_xticklabels([])  # Remove xtick labels\n",
    "    mean_rel_pos_cs = np.mean(rel_pos_cs) # Calculate the mean\n",
    "    axs[2].annotate('Mean: {:.1f}'.format(mean_rel_pos_cs), xy=(0, 1.05), xycoords=axs[2].transAxes)  # Annotate the mean\n",
    "    axs[2].tick_params(axis='y', labelsize='small')\n",
    "    \n",
    "    fig2,axs2=plt.subplots(1, 2, figsize=(7, 3))\n",
    "    sns.heatmap(len_rel_pos_corr, annot=True, cmap='Blues',  ax=axs2[0])    \n",
    "    sns.scatterplot(x=norm_len_cs,y=norm_rel_pos_cs, ax=axs2[1])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return len_rel_pos_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fa893a",
   "metadata": {},
   "source": [
    "#### Function `save_TSS_by_loc`\n",
    "* Input: from path for df_pickled\n",
    "* Output: 6k (upstream 2kbs, downstream 4kbs for each gene)\n",
    "* This function is executed, no need to rerun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91714c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_TSS_by_loc(whole_gene_file, input_path=\"../database/roadmap/df_pickled/\",output_path=\"../database/roadmap/prom/up2kdown4k/\", up_num=2000, down_num=4000, unit=200):\n",
    "    \"\"\"\n",
    "    extract TSS region by location estimation. \n",
    "    input: (1) whole_gene_file: the raw gene bed file (2) input_path: pickled df per cell\n",
    "    output: save tss_by_loc_css_unit_all at the output path\n",
    "    \"\"\"\n",
    "    file_lst=os.listdir(input_path)\n",
    "    all_files=[os.path.join(input_path,file) for file in file_lst]\n",
    "    for file in all_files:\n",
    "        cell_num=file.split(\"/\")[-1][:4]\n",
    "#         if cell_num==\"E002\": break  # for test \n",
    "        with open(file,\"rb\") as f:\n",
    "            df_pickled=pickle.load(f)\n",
    "        # align the gene file and the df file according to their availability(some cells does not have chr Y)\n",
    "        new_gene_lst_all, trimmed_df=remove_chrM_and_trim_gene_file_accordingly(whole_gene_file,df_pickled)\n",
    "        css_lst_chr = df2longcss(trimmed_df) # list of long css per chromosome\n",
    "        total_chr = len(new_gene_lst_all)       \n",
    "        tss_by_loc_css_all = []\n",
    "        for i in range(total_chr):\n",
    "            gene_start_lst = new_gene_lst_all[i][\"TxStart\"]\n",
    "            css_lst = css_lst_chr[i]\n",
    "            tss_by_loc_css_chr = []\n",
    "            for j in range(len(gene_start_lst)):\n",
    "                gene_start = gene_start_lst[j]\n",
    "                win_start = max(0, gene_start - up_num)  # use max to prevent negative index\n",
    "                win_end = min(len(css_lst), gene_start + down_num)  # use min to prevent index out of range\n",
    "                tss_by_loc_css = css_lst[win_start:win_end]\n",
    "                tss_by_loc_css_chr.append(tss_by_loc_css)               \n",
    "            tss_by_loc_css_all.append(tss_by_loc_css_chr)\n",
    "        tss_by_loc_css_unit_all=Convert2unitCSS_main_new(tss_by_loc_css_all, unit=unit)  \n",
    "        output_file_name=os.path.join(output_path,cell_num+\"_prom_up2kdown4k.pkl\")\n",
    "        with open(output_file_name,\"wb\") as g:\n",
    "            pickle.dump(tss_by_loc_css_unit_all,g)\n",
    "\n",
    "    return print(\"All done!\") #tss_by_loc_css_unit_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f54510",
   "metadata": {},
   "source": [
    "#### Function `prom_stat1`\n",
    "* Extract the strings which has a specific chromatin states (e.g. \"A\" in the promoter regions)\n",
    "* And check the proportion of those strings in total\n",
    "* *updated* for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82c03487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def prom_stat1(prom_path=\"../database/roadmap/prom/up2kdown4k/\", chromatin_state=\"A\"):\n",
    "#     file_lst=os.listdir(prom_path)\n",
    "#     all_files=sorted([os.path.join(prom_path,file) for file in file_lst])\n",
    "    \n",
    "#     occu_cs_all=[]\n",
    "#     prom_cs_all=[]\n",
    "#     for file in all_files:\n",
    "#         cell_num=file.split(\"/\")[-1][:4]\n",
    "# #         if cell_num==\"E004\": break   ### for test\n",
    "#         with open(file,\"rb\") as f:\n",
    "#             prom=pickle.load(f)\n",
    "#         prom=flatLst(prom) #### flatten for all chromosomes       \n",
    "#         prom_cs=[item for item in prom if chromatin_state in item]\n",
    "#         prom_cs_all.append(prom_cs)\n",
    "        \n",
    "#         total_entry=len(prom)\n",
    "#         cs_entry=len(prom_cs)\n",
    "#         occu_cs=cs_entry/total_entry ### percentage of proms which include certain CS\n",
    "#         occu_cs_all.append(occu_cs)\n",
    "        \n",
    "#     return prom_cs_all, occu_cs_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "db5230eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prom_stat1(prom_path=\"../database/roadmap/prom/up2kdown4k/all_genes/\", chromatin_state=\"A\"):\n",
    "    file_lst=os.listdir(prom_path)\n",
    "    all_files=sorted([os.path.join(prom_path,file) for file in file_lst])\n",
    "    \n",
    "    total_css=[]\n",
    "    occu_cs_all=[]\n",
    "    prom_cs_all=[]\n",
    "    for file in all_files:\n",
    "        cell_num=file.split(\"/\")[-1][:4]\n",
    "#         if cell_num==\"E004\": break   ### for test\n",
    "        with open(file,\"rb\") as f:\n",
    "            prom=pickle.load(f)\n",
    "        prom=flatLst(prom) #### flatten for all chromosomes       \n",
    "        prom_cs=[item for item in prom if chromatin_state in item]\n",
    "        prom_cs_all.append(prom_cs)\n",
    "        \n",
    "        total_entry=len(prom)\n",
    "        total_css.append(prom)\n",
    "        cs_entry=len(prom_cs)\n",
    "        occu_cs=cs_entry/total_entry ### percentage of proms which include certain CS\n",
    "        occu_cs_all.append(occu_cs)\n",
    "        \n",
    "    plt.figure(figsize=(3,3))\n",
    "    sns.histplot(occu_cs_all,color=\"teal\", element=\"step\", fill=None)\n",
    "    title_txt=\"Proportion of genes having \" + chromatin_state + \" on prom region\"\n",
    "    plt.title(title_txt) \n",
    "    \n",
    "    dataset_total=flatLst(total_css)\n",
    "    dataset_cs=flatLst(prom_cs_all)\n",
    "    # Flatten the dataset into a single string\n",
    "    data_str_tot = \"\".join(dataset_total)\n",
    "    data_str_cs=\"\".join(dataset_cs)\n",
    "    # Count occurrences of each character\n",
    "    char_counts_tot = Counter(data_str_tot)\n",
    "    char_counts_cs = Counter(data_str_cs)\n",
    "\n",
    "    # Initialize the dictionary for the characters from \"A\" to \"O\"\n",
    "    counts_tot = {chr(i+65): 0 for i in range(15)}\n",
    "    counts_cs = {chr(i+65): 0 for i in range(15)}\n",
    "\n",
    "    # Update the counts for the characters found in the data\n",
    "    counts_tot.update(char_counts_tot)\n",
    "    counts_cs.update(char_counts_cs)\n",
    "    \n",
    "    def my_autopct(pct):\n",
    "        return ('%1.1f%%' % pct) if pct > 2 else ''\n",
    "\n",
    "    fig, ax = plt.subplots(1,2)\n",
    "\n",
    "    # First subplot\n",
    "    ax[0].pie(counts_tot.values(), labels=counts_tot.keys(), colors=[state_col_dict[key] for key in counts_tot.keys()], autopct=my_autopct)\n",
    "    ax[0].axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "    ax[0].set_title(\"Total prom region\")\n",
    "\n",
    "    # Second subplot\n",
    "    ax[1].pie(counts_cs.values(), labels=counts_cs.keys(), colors=[state_col_dict[key] for key in counts_cs.keys()], autopct=my_autopct)\n",
    "    ax[1].axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "    title_txt2=\"Regions having \"+chromatin_state\n",
    "    ax[1].set_title(title_txt2)\n",
    "\n",
    "    plt.show()\n",
    "      \n",
    "    return prom_cs_all, occu_cs_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d443711e",
   "metadata": {},
   "source": [
    "### 3-7-3. Extract Promoter regions from gene with various expression level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121a36cb",
   "metadata": {},
   "source": [
    "#### Pipeline \n",
    "\n",
    "(1) `prom_expGene2css` : cut the prom regions of long css <br>\n",
    "(2) `extProm_wrt_g_exp` : transform css into unit length css <br>\n",
    "(3) `extNsaveProm_g_exp` : load the required file and process all, and save"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe6c2dc",
   "metadata": {},
   "source": [
    "#### Function `prom_expGene2css`\n",
    "* This function produces a long list (not unit length) of css according to the gene expression table, per cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26f4458a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prom_expGene2css(g_lst_chr_merged,df, up_num=2000, down_num=4000):   # df indicates css, created by bed2df_expanded\n",
    "    \"\"\"\n",
    "    modified from `compGene2css`\n",
    "    Input: Reference gene file trimmed for gene expresseion level, df (CSS)\n",
    "    Output: list of chromosome-wise list that contains the css at (expressed) genic area with prom only.\n",
    "    \"\"\"\n",
    "    g_lst_chr=g_lst_chr_merged\n",
    "    df = df[df['chromosome'] != 'chrM']\n",
    "    css_lst_chr=df2longcss(df) # list of long css per chromosome\n",
    "    \n",
    "    g_lst_chr = g_lst_chr[:len(css_lst_chr)]  # adjust the length of list according to length of df (might not have chrY)\n",
    "    total_chr=len(css_lst_chr)\n",
    "    \n",
    "    print(\"Matching to the chromatin state sequence data ...\")\n",
    "    css_prom_lst_all=[]\n",
    "    for i in tqdm_notebook(range(total_chr)):\n",
    "        css=css_lst_chr[i]   # long css of i-th chromosome\n",
    "        gene_df=g_lst_chr[i] # gene df of i-th chromosome\n",
    "        \n",
    "        css_prom_lst_chr=[]\n",
    "        for j in range(len(gene_df)):\n",
    "            prom_start=gene_df[\"TxStart\"].iloc[j]-1-up_num  # python counts form 0\n",
    "            prom_end=prom_start+up_num+down_num+1      # python excludes the end\n",
    "            if gene_df[\"TxEnd\"].iloc[j]<prom_end:  # if longer than gene body, then just gene body\n",
    "                prom_end=gene_df[\"TxEnd\"].iloc[j]+1\n",
    "    \n",
    "            css_prom=css[prom_start:prom_end]           # cut the gene area only\n",
    "            css_prom_lst_chr.append(css_prom)     # store in the list\n",
    "          \n",
    "        css_prom_lst_all.append(css_prom_lst_chr)  # list of list\n",
    "    \n",
    "    assert len(css_prom_lst_all)==total_chr\n",
    "    \n",
    "    # remove chromosome if it is empty (e.g. chrY for female)\n",
    "    css_prom_lst_all=[elm for elm in css_prom_lst_all if elm!=[]] \n",
    "    \n",
    "    print(\"Done!\")\n",
    "    return css_prom_lst_all "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebbf2f0",
   "metadata": {},
   "source": [
    "#### Function `extProm_wrt_g_exp`\n",
    "* This function produces a unit-length css of a cell screened by its gene expression level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "35eaa90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extProm_wrt_g_exp(exp_gene_file, df, up_num=2000, down_num=4000,unit=200):\n",
    "    \"\"\"\n",
    "    extract promoter regions of genes according to gene expression level\n",
    "    \"\"\"\n",
    "    df = df[df['chromosome'] != 'chrM']\n",
    "    g_lst_chr=Gexp_Gene2GLChr(exp_gene_file)\n",
    "    g_lst_chr_merged=merge_intervals(g_lst_chr)\n",
    "    \n",
    "    css_prom_lst_all=prom_expGene2css(g_lst_chr_merged,df, up_num=up_num, down_num=down_num)\n",
    "    css_prom_lst_unit_all=Convert2unitCSS_main_new(css_prom_lst_all, unit=unit)\n",
    "    return css_prom_lst_unit_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3643154",
   "metadata": {},
   "source": [
    "#### Function `extNsaveProm_g_exp`\n",
    "* This function processes the above works (cut the prom region and make it unit length css) per cell\n",
    "* Input\n",
    "    * `exp_gene_dir`: directory where refFlat for each cell (subdir means the sub directory for different gene expression level)\n",
    "    * `df_pickle_dir`: dataframe of each cell\n",
    "    * `rpkm_val`: RPKM value, 10, 20, 30, or 50\n",
    "    * `up_num`: upstream of gene\n",
    "    * `down_num`: from TSS (gene initial part) to cut\n",
    "    * `unit`: because chromatin states are annotated by 200 bps\n",
    "* Output: save the file according to the `rpkm_val` at the output path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "192e2541",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extNsaveProm_g_exp(exp_gene_dir=\"../database/roadmap/gene_exp/refFlat_byCellType/\", df_pickle_dir=\"../database/roadmap/df_pickled/\",output_path=\"../database/roadmap/prom/up2kdown4k/gene_exp/\",rpkm_val=50, up_num=2000, down_num=4000,unit=200):\n",
    "    exp_gene_subdir=os.listdir(exp_gene_dir)\n",
    "    exp_gene_tardir=[os.path.join(exp_gene_dir, subdir) for subdir in exp_gene_subdir if str(rpkm_val) in subdir][0]    \n",
    "    if rpkm_val==0:\n",
    "        exp_gene_tardir=os.path.join(exp_gene_dir, \"rpkm0\")\n",
    "        \n",
    "    exp_gene_files=sorted([os.path.join(exp_gene_tardir,file) for file in os.listdir(exp_gene_tardir)])\n",
    "    \n",
    "    for exp_gene_file in exp_gene_files:\n",
    "        cell_id=exp_gene_file.split(\"/\")[-1][:4]\n",
    "#         if cell_id==\"E004\":break ## for test\n",
    "        df_name=[file for file in os.listdir(df_pickle_dir) if cell_id in file][0]\n",
    "        df_path=os.path.join(df_pickle_dir,df_name)\n",
    "        with open(df_path,\"rb\") as f:\n",
    "            df=pickle.load(f)\n",
    "        css_prom_lst_unit_all=extProm_wrt_g_exp(exp_gene_file, df, up_num=up_num, down_num=down_num,unit=unit)\n",
    "           \n",
    "        output_name=output_path+\"rpkm\"+str(rpkm_val)+\"/\"+cell_id+\"_prom_up2kdown4k.pkl\"\n",
    "        output_dir = os.path.dirname(output_name)\n",
    "        \n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "        with open(output_name, \"wb\") as g:\n",
    "            pickle.dump(css_prom_lst_unit_all,g)\n",
    "    return print(\"Saved at \",output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb2bee0",
   "metadata": {},
   "source": [
    "### 3-7-4. Extract Promoter regions from not expressed genes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e0b380",
   "metadata": {},
   "source": [
    "#### Pipeline \n",
    "\n",
    "(1) `extWholeGeneRef` : Just extract the whole gene location files from `chr.gene.refFlat` <br>\n",
    "(2) `extNOTexp_by_compare` : Extract the not expressed genes by comparing with whole gene with rpkm>0 <br>\n",
    "(3) `extNsaveNOTexp_by_compare` : load the required file and process all, and save refFlat (.pkl) and prom-region css (.pkl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc39139",
   "metadata": {},
   "source": [
    "Basically, these functions are already conducted and no need to rerun. To extract promoter regions with different boundary conditions, then just adjust the numbers and save path in the final functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ac2e68d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extWholeGeneRef(whole_gene_ref=\"../database/roadmap/gene_exp/chr.gene.refFlat\"):\n",
    "    ###### modified from Gexp_Gene2GLChr, this function provides the df of whole genes\n",
    "    ###### note that this file contains Y chromosome\n",
    "    g_fn=whole_gene_ref\n",
    "    g_df=pd.read_csv(g_fn, sep='\\t', index_col=False, header=0)\n",
    "    g_df=g_df.iloc[:,1:]\n",
    "    g_df.rename(columns={\"name\":\"gene_id\"}, inplace=True)\n",
    "    g_df.rename(columns={\"#geneName\":\"geneName\"}, inplace=True)\n",
    "    g_df.rename(columns={\"txStart\":\"TxStart\"}, inplace=True) # to make it coherent to my previous codes\n",
    "    g_df.rename(columns={\"txEnd\":\"TxEnd\"}, inplace=True)     \n",
    "    g_df=g_df[[\"chrom\",\"TxStart\",\"TxEnd\"]] # extract these only\n",
    "    # Remove other than regular chromosomes\n",
    "    chr_lst=['chr1','chr2','chr3','chr4','chr5','chr6','chr7','chr8','chr9','chr10',\n",
    "             'chr11','chr12','chr13','chr14','chr15','chr16','chr17','chr18','chr19',\n",
    "             'chr20','chr21','chr22','chrX','chrY']\n",
    "    g_df=g_df.loc[g_df[\"chrom\"].isin(chr_lst)]\n",
    "    \n",
    "    # Create a list of chromosome-wise dataframe \n",
    "    g_df_chr_lst=[]\n",
    "    for num in range(len(chr_lst)):\n",
    "        chr_num=chr_lst[num]\n",
    "        g_chr_df='g_'+chr_num  # name it as \"g_\"\n",
    "        locals()[g_chr_df]=g_df[g_df[\"chrom\"]==chr_num]\n",
    "#         print(chr_num)\n",
    "        g_chr_df=locals()[g_chr_df]\n",
    "        g_chr_df=g_chr_df.sort_values(\"TxStart\")\n",
    "        g_df_chr_lst.append(g_chr_df)\n",
    "    \n",
    "    # remove any overlap\n",
    "    g_df_chr_lst=merge_intervals(g_df_chr_lst)\n",
    "    return g_df_chr_lst  # list of chromosome-wise df for all gene start and end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "49885e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extNOTexp_by_compare(whole_gene_ref, cell_exp_ref):\n",
    "    \"\"\"\n",
    "    whole_gene_ref=\"../database/roadmap/gene_exp/chr.gene.refFlat\"\n",
    "    \"\"\"\n",
    "    whole_gene_ref_lst=extWholeGeneRef(whole_gene_ref)\n",
    "    cell_exp_lst=Gexp_Gene2GLChr(cell_exp_ref)\n",
    "    cell_exp_lst=merge_intervals(cell_exp_lst) \n",
    "    if len(whole_gene_ref_lst)!=len(cell_exp_lst):\n",
    "        whole_gene_ref_lst=whole_gene_ref_lst[:-1]   \n",
    "    non_exp_gene_lst=[]\n",
    "    for i, whole_gene_chr in enumerate(whole_gene_ref_lst):\n",
    "        exp_gene_mark = whole_gene_chr.merge(cell_exp_lst[i], on=['TxStart', 'TxEnd'])\n",
    "        non_exp_gene_chr=whole_gene_chr.drop(exp_gene_mark.index)\n",
    "        non_exp_gene_lst.append(non_exp_gene_chr)\n",
    "    print(\"total length of non_expressed genes in this cell: \",len(pd.concat(non_exp_gene_lst)))\n",
    "    return non_exp_gene_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c4cc32dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extNsaveNOTexp_by_compare(whole_gene_ref_path=\"../database/roadmap/gene_exp/chr.gene.refFlat\",\n",
    "                              exp_ref_path=\"../database/roadmap/gene_exp/refFlat_byCellType/rpkm0/\",\n",
    "                              df_pickle_dir=\"../database/roadmap/df_pickled/\",\n",
    "                              output_path_ref=\"../database/roadmap/gene_exp/refFlat_byCellType/not_exp/\",\n",
    "                              output_path_prom=\"../database/roadmap/prom/up2kdown4k/gene_exp/not_exp/\",\n",
    "                              up_num=2000,down_num=4000,unit=200):\n",
    "    \n",
    "    exp_ref_file_all=sorted([os.path.join(exp_ref_path,file) for file in os.listdir(exp_ref_path)])\n",
    "    \n",
    "    for exp_ref_file in exp_ref_file_all:\n",
    "        cell_id=exp_ref_file.split(\"/\")[-1][:4]\n",
    "#         if cell_id==\"E004\":break # for test\n",
    "        print(cell_id+\" is now processing...\")\n",
    "            \n",
    "        df_name=[file for file in os.listdir(df_pickle_dir) if cell_id in file][0]\n",
    "        df_path=os.path.join(df_pickle_dir,df_name)\n",
    "        with open(df_path,\"rb\") as f:\n",
    "            df=pickle.load(f)\n",
    "        \n",
    "        non_exp_gene_lst=extNOTexp_by_compare(whole_gene_ref_path, exp_ref_file) # a list of chromosome-wise df\n",
    "        #### refFlat for NOT expressed is pickled as a list of dataframe ####\n",
    "        not_exp_ref_path=output_path_ref+cell_id+\"_gene_not_expressed.pkl\"\n",
    "        with open(not_exp_ref_path,\"wb\") as g:\n",
    "            pickle.dump(non_exp_gene_lst,g)        \n",
    "        \n",
    "        css_prom_lst_all=prom_expGene2css(non_exp_gene_lst, df, up_num=up_num, down_num=down_num)\n",
    "        css_prom_lst_unit_all=Convert2unitCSS_main_new(css_prom_lst_all, unit=unit)\n",
    "        \n",
    "        output_name=output_path_prom+cell_id+\"_not_exp_gene_prom_up2kdown4k.pkl\"\n",
    "        with open(output_name,\"wb\") as h:\n",
    "            pickle.dump(css_prom_lst_unit_all,h)\n",
    "    \n",
    "    return print(\"refFlat is saved at {} and prom is saved at {}.\".format(output_path_ref, output_path_prom))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8462db",
   "metadata": {},
   "source": [
    "### 3-7-5. Strong and Weak promoter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a0bf8d",
   "metadata": {},
   "source": [
    "#### Function `extStrong_prom`\n",
    "* This function saves the strong promoter (w.r.t. the gene expression level of its gene body) for various rpkm value\n",
    "* This function has been conducted. No need to rerun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d81da14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extStrong_prom(prom_path=\"../database/roadmap/prom/up2kdown4k/gene_exp/\", rpkm_val=50, chromatin_state=\"A\"):#, output_path=):\n",
    "    \"\"\"Gather the strong promoter regions at once\"\"\"\n",
    "    prom_path_subdir=os.listdir(prom_path)\n",
    "    prom_path_tardir=[os.path.join(prom_path, subdir) for subdir in prom_path_subdir if str(rpkm_val) in subdir][0]\n",
    "    if rpkm_val==0:\n",
    "        prom_path_tardir=os.path.join(prom_path, \"rpkm0\")\n",
    "        \n",
    "    prom_files=sorted([os.path.join(prom_path_tardir,file) for file in os.listdir(prom_path_tardir)])\n",
    "    \n",
    "    strong_prom_all=[]\n",
    "    for file in prom_files:\n",
    "        cell_id=file.split(\"/\")[-1][:4]\n",
    "#         if cell_id==\"E004\":break ## for test\n",
    "        with open(file,\"rb\") as f:\n",
    "            prom_lst_chr=pickle.load(f) # list by chromosome\n",
    "        prom_all=flatLst(prom_lst_chr) # flattened, now a list of strings (prom)\n",
    "        strong_prom=[]\n",
    "        for prom in prom_all:\n",
    "            if chromatin_state in prom:\n",
    "                strong_prom.append(prom)\n",
    "        strong_prom_all.append(strong_prom)\n",
    "    strong_prom_all=flatLst(strong_prom_all)\n",
    "    print(\"The number of strong promoters detected: \", len(strong_prom_all))\n",
    "    return strong_prom_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3edc19",
   "metadata": {},
   "source": [
    "#### Function `extWeak_prom`\n",
    "* This function saves the weak promoter (w.r.t. the gene expression level of its gene body) for rpkm=0\n",
    "* This function has been conducted. No need to rerun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bedbd500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extWeak_prom(prom_path=\"../database/roadmap/prom/up2kdown4k/gene_exp/not_exp/\", chromatin_state=\"A\"):#, output_path=):\n",
    "    \"\"\"Gather the Weak promoter regions at once\"\"\"   \n",
    "    prom_files=sorted([os.path.join(prom_path,file) for file in os.listdir(prom_path)])\n",
    "    \n",
    "    weak_prom_all=[]\n",
    "    for file in prom_files:\n",
    "        cell_id=file.split(\"/\")[-1][:4]\n",
    "#         if cell_id==\"E004\":break ## for test\n",
    "        with open(file,\"rb\") as f:\n",
    "            prom_lst_chr=pickle.load(f) # list by chromosome\n",
    "        prom_all=flatLst(prom_lst_chr) # flattened, now a list of strings (prom)\n",
    "        weak_prom=[]\n",
    "        for prom in prom_all:\n",
    "            if chromatin_state in prom:\n",
    "                weak_prom.append(prom)\n",
    "        weak_prom_all.append(weak_prom)\n",
    "    weak_prom_all=flatLst(weak_prom_all)\n",
    "    print(\"The number of weak promoters detected: \", len(weak_prom_all))\n",
    "    return weak_prom_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fb63cb",
   "metadata": {},
   "source": [
    "#### Function `prom_css_Kmer_by_cell`\n",
    "* This function saves the kmerized promoter regions (of all genes)\n",
    "* No need to rerun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db240898",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prom_css_Kmer_by_cell(path=\"../database/roadmap/prom/up2kdown4k/all_genes/\", output_path=\"../database/pretrain/prom/up2kdown4k/all_genes/\",k=4):\n",
    "    output_dir=str(k)+\"mer/\"\n",
    "    output_path_fin=os.path.join(output_path, output_dir)\n",
    "    all_files=sorted([os.path.join(path, file) for file in os.listdir(path)]) \n",
    "    \n",
    "    for file in all_files:\n",
    "        prom_kmer_all=[]\n",
    "        cell_id=file.split(\"/\")[-1][:4]\n",
    "#         if cell_id==\"E008\": break # for test use\n",
    "        with open(file, \"rb\") as f:\n",
    "            prom=pickle.load(f)\n",
    "        prom_css=flatLst(prom)  # make a list from list of a list\n",
    "        prom_kmer=[seq2kmer(item,k) for item in prom_css]\n",
    "        prom_kmer_all.append(prom_kmer)\n",
    "        prom_kmer_all_flt=flatLst(prom_kmer_all)\n",
    "        prom_kmer_all_flt_not_zero=[item for item in prom_kmer_all_flt if item!=\"\"]\n",
    "        output_name=cell_id+\"_all_genes_prom_\"+str(k)+\"merized.txt\"\n",
    "        with open(output_path_fin+output_name, \"w\") as g:\n",
    "            g.write(\"\\n\".join(prom_kmer_all_flt_not_zero))\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952102b4",
   "metadata": {},
   "source": [
    "### 3-7-6. Kmerize and save and merge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fbcd97",
   "metadata": {},
   "source": [
    "#### Function `prom_css_g_exp_Kmer_by_cell`\n",
    "* To save the kmerized prom for various gene expression and kmers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "099f0cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prom_css_g_exp_Kmer_by_cell(path=\"../database/roadmap/prom/up2kdown4k/gene_exp/\", \n",
    "                                output_path=\"../database/pretrain/prom/up2kdown4k/gene_exp/\",\n",
    "                                k=4, custom_name=\"_prom_\"):\n",
    "\n",
    "    path_sub=sorted(os.listdir(path))\n",
    "    for sub in path_sub:\n",
    "        input_path=os.path.join(path,sub)\n",
    "        output_path_fin=os.path.join(output_path,str(k)+\"mer\",sub)\n",
    "        all_files=[os.path.join(input_path,file) for file in sorted(os.listdir(input_path))]\n",
    "        for file in all_files:\n",
    "            prom_kmer_all=[]\n",
    "            cell_id=file.split(\"/\")[-1][:4]\n",
    "#             if cell_id==\"E004\": break # for test use\n",
    "            with open(file, \"rb\") as f:\n",
    "                prom=pickle.load(f)\n",
    "            ################# comment it if it is not a list of list\n",
    "            prom_css=flatLst(prom)  # make a list from list of a list\n",
    "            #################\n",
    "            prom_kmer=[seq2kmer(item,k) for item in prom_css]\n",
    "            prom_kmer_all.append(prom_kmer)\n",
    "            prom_kmer_all_flt=flatLst(prom_kmer_all)\n",
    "            prom_kmer_all_flt_not_zero=[item for item in prom_kmer_all_flt if item!=\"\"]\n",
    "            output_name=cell_id+custom_name+sub+\"_\"+str(k)+\"merized.txt\"\n",
    "            with open(output_path_fin+\"/\"+output_name, \"w\") as g:\n",
    "                g.write(\"\\n\".join(prom_kmer_all_flt_not_zero))\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e36b43",
   "metadata": {},
   "source": [
    "#### Function`mergeLst`\n",
    "\n",
    "* Create a merged pretrain data for all genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b9abe5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mergeLst(path=\"../database/pretrain/prom/up2kdown4k/all_genes/\",k=4):\n",
    "#     sub_path=os.path.join(path,str(k)+\"mer/\")\n",
    "#     all_files=[os.path.join(sub_path,file) for file in os.listdir(sub_path)]\n",
    "    \n",
    "#     def mergeNcreate(all_files):  #better use this for units\n",
    "#         all_entries=[]\n",
    "#         for file in all_files:\n",
    "#             with open(file, \"r\") as f:\n",
    "#                 all_entries.extend(f.read().splitlines())\n",
    "#         content=\"\\n\".join(all_entries)\n",
    "#         output_name=path+\"pretrain_\"+str(k)+\"mer_all.txt\"\n",
    "#         with open(output_name,\"w\") as g:\n",
    "#             g.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da520620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeLst(path=\"../database/pretrain/prom/up2kdown4k/all_genes/\",k=4):\n",
    "    sub_path=os.path.join(path,str(k)+\"mer/\")\n",
    "    all_files=[os.path.join(sub_path,file) for file in os.listdir(sub_path)]    \n",
    "    def mergeNcreate(all_files=all_files, path=path, k=k):\n",
    "        all_entries=[]\n",
    "        for file in all_files:\n",
    "            with open(file, \"r\") as f:\n",
    "                all_entries.extend(f.read().splitlines())\n",
    "        content=\"\\n\".join(all_entries)\n",
    "        output_name=path+\"pretrain_\"+str(k)+\"mer_all.txt\"\n",
    "        with open(output_name,\"w\") as g:\n",
    "            g.write(content)\n",
    "    mergeNcreate(all_files=all_files, path=path, k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5caa3cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeNcreate(all_files, output_name):\n",
    "    all_entries=[]\n",
    "    for file in all_files:\n",
    "        with open(file, \"r\") as f:\n",
    "            all_entries.extend(f.read().splitlines())\n",
    "    content=\"\\n\".join(all_entries)       \n",
    "    with open(output_name,\"w\") as g:\n",
    "        g.write(content)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2aa32450",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeLst2(path=\"../database/pretrain/prom/up2kdown4k/gene_exp/\",k=4, rpkm=0):\n",
    "    sub_path=os.path.join(path,str(k)+\"mer/\")\n",
    "    if rpkm==\"not\":\n",
    "        dir_name=\"not_exp\"\n",
    "    elif rpkm==0:\n",
    "        dir_name=\"rpkm0\"\n",
    "    else:       \n",
    "        dir_name=\"rpkm\"+str(rpkm)\n",
    "    tar_path=os.path.join(sub_path, dir_name)\n",
    "    all_files=[os.path.join(tar_path, file) for file in os.listdir(tar_path)]\n",
    "    output_name=\"exp_\"+str(k)+\"mer_\"+dir_name+\"_all.txt\"\n",
    "    output_path=os.path.join(sub_path,output_name)\n",
    "    mergeNcreate(all_files=all_files, output_name=output_path)\n",
    "    return print(\"Saved as \", output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06866823",
   "metadata": {},
   "source": [
    "### 3-7-7. Exclusive case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569b1b4b",
   "metadata": {},
   "source": [
    "#### Function `prom_exclusive`\n",
    "* This function saves the exclusive cases for each expression level. \n",
    "    (e.g. `rpkm10_excl` means that expression level from `rpkm10` to `rpkm20`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b96a7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prom_exclusive(input_path=\"../database/pretrain/prom/up2kdown4k/gene_exp/\",k=4):\n",
    "    \"\"\"\n",
    "    This function generates the exclusive lists of all detected list. \n",
    "    E.g. rpkm10_excl accommodates the elements only in rpkm10, not rpkm20\n",
    "    \"\"\"\n",
    "    tar_path=[os.path.join(input_path, kmer_path) for kmer_path in os.listdir(input_path) if str(k) in kmer_path][0]\n",
    "    all_files=sorted([file for file in os.listdir(tar_path) if \".txt\" in file])\n",
    "\n",
    "    for file in all_files:\n",
    "        f_name=os.path.join(tar_path, file)\n",
    "        \n",
    "        with open(f_name, 'r') as f:\n",
    "            css = [line.strip() for line in f]\n",
    "        if \"not\" in file: not_exp = css\n",
    "        if \"rpkm0\" in file: \n",
    "            rpkm0 = css\n",
    "            rpkm0_name=os.path.join(tar_path,\"exp_\"+str(k)+\"mer\"+\"_rpkm0_excl.txt\")\n",
    "            print(\"length of rpkm0:  \",len(rpkm0))\n",
    "        if \"rpkm10\" in file: \n",
    "            rpkm10 = css\n",
    "            rpkm10_name=os.path.join(tar_path,\"exp_\"+str(k)+\"mer\"+\"_rpkm10_excl.txt\")\n",
    "            print(\"length of rpkm10: \",len(rpkm10))\n",
    "        if \"rpkm20\" in file: \n",
    "            rpkm20 = css\n",
    "            rpkm20_name=os.path.join(tar_path,\"exp_\"+str(k)+\"mer\"+\"_rpkm20_excl.txt\")\n",
    "            print(\"length of rpkm20: \",len(rpkm20))\n",
    "        if \"rpkm30\" in file: \n",
    "            rpkm30 = css\n",
    "            rpkm30_name=os.path.join(tar_path,\"exp_\"+str(k)+\"mer\"+\"_rpkm30_excl.txt\")\n",
    "            print(\"length of rpkm30: \",len(rpkm30))\n",
    "        if \"rpkm50\" in file: \n",
    "            rpkm50 = css\n",
    "            output_name=\"exp\"+str(k)+\"mer\"+\"_rpkm50_excl.txt\"\n",
    "            print(\"length of rpkm50: \",len(rpkm50))\n",
    "    \n",
    "    rpkm0_excl=[item for item in rpkm0 if item not in rpkm10]\n",
    "    rpkm0_excl_str=\"\\n\".join(rpkm0_excl)\n",
    "    with open(rpkm0_name,\"w\") as g1:\n",
    "        g1.write(rpkm0_excl_str)       \n",
    "    print(\"rpkm0_excl is completed.\") \n",
    "    \n",
    "    rpkm10_excl=[item for item in rpkm10 if item not in rpkm20]\n",
    "    rpkm10_excl_str=\"\\n\".join(rpkm10_excl)\n",
    "    with open(rpkm10_name,\"w\") as g2:\n",
    "        g2.write(rpkm10_excl_str)        \n",
    "    print(\"rpkm10_excl is completed.\")\n",
    "    \n",
    "    rpkm20_excl=[item for item in rpkm20 if item not in rpkm30]\n",
    "    rpkm20_excl_str=\"\\n\".join(rpkm20_excl)\n",
    "    with open(rpkm20_name,\"w\") as g3:\n",
    "        g3.write(rpkm20_excl_str)\n",
    "    print(\"rpkm20_excl is completed.\")\n",
    "    \n",
    "    rpkm30_excl=[item for item in rpkm30 if item not in rpkm50]\n",
    "    rpkm30_excl_str=\"\\n\".join(rpkm30_excl)\n",
    "    with open(rpkm30_name,\"w\") as g4:\n",
    "        g4.write(rpkm30_excl_str)\n",
    "    print(\"rpkm30_excl is completed.\")\n",
    "  \n",
    "    return print(\"All exclusive files are saved at \", tar_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4263ae",
   "metadata": {},
   "source": [
    "#### Function `prom_FT_save`\n",
    "* This function prepare the fine tuning data (no. of training and validation = 1:1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e74977b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prom_FT_save(input_path=\"../database/pretrain/prom/up2kdown4k/gene_exp/\",\n",
    "                 output_path=\"../database/fine_tune/prom/up2kdown4k/gene_exp/\",\n",
    "                 cl1=\"rpkm30\",cl2=\"rpkm50\", \n",
    "                 len_tr=20000, len_dev=1000,\n",
    "                 k=4, exclusive=True):\n",
    "    assert cl1 in [\"not\", \"rpkm0\", \"rpkm10\", \"rpkm20\", \"rpkm30\", \"rpkm50\"], 'use \"not\", \"rpkm0\", \"rpkm10\", \"rpkm20\", \"rpkm30\", \"rpkm50\" for cl1'\n",
    "    assert cl2 in [\"not\", \"rpkm0\", \"rpkm10\", \"rpkm20\", \"rpkm30\", \"rpkm50\"], 'use \"not\", \"rpkm0\", \"rpkm10\", \"rpkm20\", \"rpkm30\", \"rpkm50\" for cl2'\n",
    "    \n",
    "    sub_path=os.path.join(input_path,str(k)+\"mer\")\n",
    "    if exclusive:\n",
    "        tar_cl1=[file for file in os.listdir(sub_path) if cl1 in file and \"excl\" in file][0]\n",
    "        cl1_path=os.path.join(sub_path,tar_cl1)\n",
    "        tar_cl2=[file for file in os.listdir(sub_path) if cl2 in file and \"excl\" in file][0]\n",
    "        cl2_path=os.path.join(sub_path,tar_cl2)\n",
    "    else:\n",
    "        tar_cl1=[file for file in os.listdir(sub_path) if cl1 in file and \"all\" in file][0]\n",
    "        cl1_path=os.path.join(sub_path,tar_cl1)\n",
    "        tar_cl2=[file for file in os.listdir(sub_path) if cl2 in file and \"all\" in file][0]\n",
    "        cl2_path=os.path.join(sub_path,tar_cl2)\n",
    "    \n",
    "    with open(cl1_path,\"r\") as f1:\n",
    "        cl1_lst=[line.strip() for line in f1]\n",
    "    with open(cl2_path, \"r\") as f2:\n",
    "        cl2_lst=[line.strip() for line in f2]\n",
    "   \n",
    "    # make it dataframe\n",
    "    df_cl1=pd.DataFrame(cl1_lst, columns=[\"sequence\"])\n",
    "    df_cl1[\"label\"]=0\n",
    "    df_cl2=pd.DataFrame(cl2_lst, columns=[\"sequence\"])\n",
    "    df_cl2[\"label\"]=1\n",
    "\n",
    "    # make them have the same length\n",
    "    if len(df_cl1)>len(df_cl2):\n",
    "        df_cl1=df_cl1.sample(n=len(df_cl2), random_state=1) # use the same random state for reproducibility\n",
    "    elif len(df_cl1)<len(df_cl2):\n",
    "        df_cl2=df_cl2.sample(n=len(df_cl1), random_state=1) # use the same random state for reproducibility\n",
    "    assert len(df_cl1)==len(df_cl2), \"Check the data length.\"\n",
    "\n",
    "    df_all=pd.concat([df_cl1,df_cl2]).sample(frac=1).reset_index(drop=True) \n",
    "\n",
    "    # cutting into train and dev\n",
    "    assert len(df_all)> len_tr+len_dev, \"Not enough data length.\"\n",
    "    df_train=df_all[:len_tr]\n",
    "    df_dev=df_all[len_tr:len_tr+len_dev]    \n",
    "\n",
    "    # save at the fine tuning folder\n",
    "    data_type=cl1+\"_n_\"+cl2\n",
    "    \n",
    "    if exclusive:\n",
    "        output_path_fin=os.path.join(output_path,str(k)+\"mer\",\"excl\",data_type)       \n",
    "    else:\n",
    "        output_path_fin=os.path.join(output_path,str(k)+\"mer\",\"all\",data_type)\n",
    "\n",
    "    # Check if the directory exists\n",
    "    if not os.path.exists(output_path_fin):\n",
    "        # If the directory does not exist, create it\n",
    "        os.makedirs(output_path_fin)\n",
    "    \n",
    "    train_name=os.path.join(output_path_fin,\"train.tsv\")\n",
    "    dev_name=os.path.join(output_path_fin,\"dev.tsv\")\n",
    "\n",
    "    df_train.to_csv(train_name, sep=\"\\t\", index=False)\n",
    "    df_dev.to_csv(dev_name, sep=\"\\t\", index=False)\n",
    "#     print(\"Fine tuning files are saved at \", output_path_fin)\n",
    "    return df_train,df_dev\n",
    "\n",
    "###################################################################################################\n",
    "# ####### Following code was executed and the files are saved at the output path. no need to rerun\n",
    "# kmers=[3,4,5,6]\n",
    "# exp_lst=[\"not\",\"rpkm0\",\"rpkm10\",\"rpkm20\",\"rpkm30\",\"rpkm50\"]\n",
    "# for item in [True,False]:\n",
    "#     for k in kmers:\n",
    "# #         if k==4:break # for test\n",
    "#         for i in range(len(exp_lst)):\n",
    "#             for j in range(i+1, len(exp_lst)):\n",
    "#                 cl1, cl2 = exp_lst[i], exp_lst[j]           \n",
    "#                 prom_FT_save(input_path=\"../database/pretrain/prom/up2kdown4k/gene_exp/\",\n",
    "#                          output_path=\"../database/fine_tune/prom/up2kdown4k/gene_exp/\",\n",
    "#                          cl1=cl1,cl2=cl2, \n",
    "#                          len_tr=20000, len_dev=1000,\n",
    "#                          k=k, exclusive=item)\n",
    "###################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4c12dc",
   "metadata": {},
   "source": [
    "### 3-7-8. Fine tuning result visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72da68b1",
   "metadata": {},
   "source": [
    "#### Function `prom_ft`\n",
    "* Heatmap visualization from the fine tuning result of promoter classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "188b6567",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prom_ft(path=\"../database/ft_result/prom/up2kdown4k/gene_exp/4mer/all/eval_collected/\", fig=False, heatmap=True,cmap=\"coolwarm\"):\n",
    "    eval_files=sorted(os.listdir(path))\n",
    "    cl_name=[]\n",
    "    acc_avg=[]\n",
    "    auc_avg=[]\n",
    "    f1_avg=[]\n",
    "    for file in eval_files:\n",
    "        df=pd.read_csv(os.path.join(path,file), header=None, sep=\"\\s\", engine='python')\n",
    "        df.columns=[\"class\",\"acc\",\"auc\",\"f1\",\"mcc\",\"precision\",\"recall\"]\n",
    "        exp_name=df[\"class\"][0]\n",
    "        cl_name.append(exp_name)\n",
    "        acc_avg.append(round(np.mean(df[\"acc\"]),3))\n",
    "        auc_avg.append(round(np.mean(df[\"auc\"]),3))\n",
    "        f1_avg.append(round(np.mean(df[\"f1\"]),3))\n",
    "        if fig:\n",
    "            fig=plt.figure(figsize=(4,3))\n",
    "            sns.lineplot(df[[\"acc\",\"auc\",\"f1\"]])\n",
    "            plt.ylim(0,1)\n",
    "            plt.title(exp_name)\n",
    "    df_avg=pd.DataFrame({\"class\":cl_name,\"mean_auc\":auc_avg,\"mean_acc\":acc_avg,\"mean_f1\":f1_avg })\n",
    "    if heatmap:\n",
    "        df_heatmap=df_avg.set_index(\"class\")\n",
    "        sns.heatmap(df_heatmap, annot=True, cmap=cmap)\n",
    "        plt.title(path.split(\"/\")[-3])\n",
    "    return df_avg\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb588faf",
   "metadata": {},
   "source": [
    "### 3-7-9. Promoter motif visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfe298d",
   "metadata": {},
   "source": [
    "#### Function `motif_cp1_ext`\n",
    "* Input path: motif result `cp1_init_df.csv`\n",
    "* Output\n",
    "    * `cp1_dic`= dictionary of task and the dataframe of init\n",
    "    * `motif_dic` = dictionary of task and the motif only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3ade4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def motif_cp1_ext(path=\"../database/motif/prom/result/up2kdown4k/gene_exp/4mer/win12min4ins2/\",target=\"excl\"):\n",
    "    if target==\"all\": path_mod=os.path.join(path,\"all\")\n",
    "    if target==\"excl\": path_mod=os.path.join(path,\"excl\")    \n",
    "    sub_path=['not_n_rpkm0','not_n_rpkm10','not_n_rpkm20','not_n_rpkm30','not_n_rpkm50',\n",
    "              'rpkm0_n_rpkm10','rpkm0_n_rpkm20','rpkm0_n_rpkm30','rpkm0_n_rpkm50',\n",
    "              'rpkm10_n_rpkm20','rpkm10_n_rpkm30','rpkm10_n_rpkm50',\n",
    "              'rpkm20_n_rpkm30','rpkm20_n_rpkm50','rpkm30_n_rpkm50']\n",
    "    cp1_dic={}\n",
    "    motif_dic={}\n",
    "    for item in sub_path:\n",
    "        target_path=os.path.join(path_mod,item) \n",
    "        \n",
    "        cp1_dic[item]=pd.DataFrame()\n",
    "        motif_dic[item]=[]\n",
    "        \n",
    "        if item in os.listdir(path_mod):        \n",
    "            if \"cp1_init_df.csv\" in [item for item in os.listdir(target_path)]:\n",
    "                cp1_df=pd.read_csv(os.path.join(target_path,\"cp1_init_df.csv\"))\n",
    "                cp1_df=cp1_df.sort_values(by=\"p\", ascending=True) # sort motif from the lowest p-value\n",
    "                cp1_dic[item]=cp1_df\n",
    "                motif_dic[item]=cp1_df[\"motif\"].to_list()\n",
    "    for key in list(cp1_dic.keys()):\n",
    "        if not cp1_dic[key].empty:\n",
    "            motif_lst=cp1_dic[key][\"motif\"].to_list()\n",
    "            task_name=key.replace(\"_n_\",\"_vs._\")\n",
    "            print(\"---------Task: {} ----------\".format(task_name))\n",
    "            print(motif_lst)\n",
    "    return cp1_dic,motif_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77db2b8",
   "metadata": {},
   "source": [
    "#### Function `motif_stack_graph`\n",
    "* Input: `motif_dic` acquired by `motif_cp1_ext`\n",
    "* Output: motif (in text) stacked per task "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44f82b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def motif_stack_graph(motif_dic, figsize=(19,10)):\n",
    "    \"\"\"\n",
    "    motif_dic is the dictionary acquired by motif_cp1_ext\n",
    "    \"\"\"\n",
    "    data = motif_dic\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    def get_rgb(letter):\n",
    "        if letter in state_col_255_dict:\n",
    "            r, g, b = state_col_255_dict[letter]\n",
    "            return (r/255, g/255, b/255)  # normalize to [0, 1]\n",
    "        return (0, 0, 0) # Default black color if letter is not found\n",
    "\n",
    "    added_to_legend = set()\n",
    "    \n",
    "    for i, (task, strings) in enumerate(data.items()):\n",
    "        y_positions = range(len(strings))\n",
    "        x_positions = [i] * len(strings)\n",
    "        ax.scatter(x_positions, y_positions, marker='', alpha=0)  # No marker, just to define the structure\n",
    "\n",
    "        for j, s in enumerate(strings):\n",
    "            for k, letter in enumerate(s):\n",
    "                rgb = get_rgb(letter)\n",
    "                ax.text(i + (k - len(s)/2) * 0.11, j, letter, ha='center', va='center', color=rgb, fontsize=16, fontweight='bold')\n",
    "                # If the letter hasn't been added to the legend, add it\n",
    "                if letter not in added_to_legend:\n",
    "                    ax.plot([], [], 'o', color=rgb, label=css_dict[letter])  # This creates a dummy plot element for the legend\n",
    "                    added_to_legend.add(letter)\n",
    "\n",
    "    ax.set_xticks(range(len(data)))\n",
    "    ax.set_xticklabels(data.keys(), rotation=45, ha='right',fontsize=18)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_ylim(-1, max(len(v) for v in data.values()))\n",
    "#     ax.set_xlabel('Tasks', fontsize=18)\n",
    "#     ax.set_title('Motif Associated with Each Task', fontsize=22)\n",
    "#     ax.legend(loc='upper right', fontsize=18)  # Add the legend to the plot\n",
    "    ax.legend(loc='upper left', bbox_to_anchor=(1, 1), fontsize=18)\n",
    "    plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00399c2a",
   "metadata": {},
   "source": [
    "#### Function `motif_color_graph`\n",
    "* Input: `motif_dic` acquired by `motif_cp1_ext`\n",
    "* Output: motif (in color) stacked per task "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e642793d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def motif_color_graph(motif_dic, figsize=(19, 10)):\n",
    "    \"\"\"\n",
    "    motif_dic is the dictionary acquired by motif_cp1_ext\n",
    "    \"\"\"\n",
    "    data = motif_dic\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    def get_rgb(letter):\n",
    "        if letter in state_col_255_dict:\n",
    "            r, g, b = state_col_255_dict[letter]\n",
    "            return (r / 255, g / 255, b / 255)\n",
    "        return (0, 0, 0)  # Default black color\n",
    "\n",
    "    # Compute counts for each letter per task\n",
    "    letter_counts_per_task = {}\n",
    "    for task, strings in data.items():\n",
    "        counts = {}\n",
    "        for s in strings:\n",
    "            for letter in s:\n",
    "                counts[letter] = counts.get(letter, 0) + 1\n",
    "        letter_counts_per_task[task] = counts\n",
    "\n",
    "    # Unique legend tracking\n",
    "    added_to_legend = set()\n",
    "\n",
    "    # Draw the stacked bar\n",
    "    for i, (task, letter_counts) in enumerate(letter_counts_per_task.items()):\n",
    "        bottom = 0\n",
    "        for letter, count in letter_counts.items():\n",
    "            label_text = f\"{css_dict[letter]} ({letter})\"\n",
    "            if label_text not in added_to_legend:\n",
    "                ax.bar(i, count, bottom=bottom, color=get_rgb(letter), label=label_text)\n",
    "                added_to_legend.add(label_text)\n",
    "            else:\n",
    "                ax.bar(i, count, bottom=bottom, color=get_rgb(letter))\n",
    "            bottom += count\n",
    "\n",
    "    # Reordering the legend items alphabetically\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    # Extract the letter from each label, use it for sorting\n",
    "    sorted_legend_items = sorted(zip(handles, labels), key=lambda x: x[1].split()[-1])  # assuming the letter is the last element in the label string\n",
    "    sorted_handles, sorted_labels = zip(*sorted_legend_items)\n",
    "\n",
    "    ax.legend(sorted_handles, sorted_labels, loc='upper left',bbox_to_anchor=(1, 1), fontsize=8)\n",
    "\n",
    "    ax.set_xticks(range(len(data)))\n",
    "    ax.set_xticklabels(data.keys(), rotation=45, ha='right', fontsize=8)\n",
    "    ax.set_title('State composition of the motifs in the promoters', fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(right=0.75)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e481f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e318502",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d791e59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f17e8f7",
   "metadata": {},
   "source": [
    "## 3-8. Enhancer classification\n",
    "**[back to index](#Index)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee1548c",
   "metadata": {},
   "source": [
    "### 3-8-1. Enhancer region extraction by location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0eb141",
   "metadata": {},
   "source": [
    "* Initial location was set from 100K to 2K upstream of the nearest TSS\n",
    "* If this area overlaps with the previous genic region, cut the enhancer region not to overlap\n",
    "* Modified from `save_TSS_by_loc` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fbd1395",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_ENH_by_loc(whole_gene_file, input_path=\"../database/roadmap/df_pickled/\",output_path=\"../database/roadmap/enhancer/up100k2k/\", num_1=100000, num_2=2000, unit=200):\n",
    "    \"\"\"\n",
    "    extract Enhancer region (defined 100k - 2 k upstream for the first try) by location estimation. \n",
    "    input: (1) whole_gene_file: the raw gene bed file (2) input_path: pickled df per cell\n",
    "    output: save tss_by_loc_css_unit_all at the output path\n",
    "    \"\"\"\n",
    "    file_lst=os.listdir(input_path)\n",
    "    all_files=[os.path.join(input_path,file) for file in file_lst]\n",
    "    for file in all_files:\n",
    "        cell_num=file.split(\"/\")[-1][:4]\n",
    "        print(cell_num)\n",
    "#         if cell_num==\"E002\": break  # for test \n",
    "        with open(file,\"rb\") as f:\n",
    "            df_pickled=pickle.load(f)\n",
    "        # align the gene file and the df file according to their availability(some cells does not have chr Y)\n",
    "        new_gene_lst_all, trimmed_df=remove_chrM_and_trim_gene_file_accordingly(whole_gene_file,df_pickled)\n",
    "        css_lst_chr = df2longcss(trimmed_df) # list of long css per chromosome\n",
    "        total_chr = len(new_gene_lst_all)       \n",
    "        enh_by_loc_css_all = []\n",
    "        for i in range(total_chr):\n",
    "#             if i>=3: break  # for test \n",
    "            gene_start_lst = new_gene_lst_all[i][\"TxStart\"]\n",
    "            gene_end_lst = new_gene_lst_all[i][\"TxEnd\"]\n",
    "            css_lst = css_lst_chr[i]\n",
    "            enh_by_loc_css_chr = []           \n",
    "            prev_gene_end = 0  # Initialize with 0 since there's no gene before the first one\n",
    "            for j in range(len(gene_start_lst)):\n",
    "                gene_start = gene_start_lst[j]\n",
    "                gene_end = gene_end_lst[j]\n",
    "#                 print(j)\n",
    "#                 print(\"[gene_start, gene_end]\",[gene_start, gene_end])\n",
    "                win_start = max(0, gene_start - num_1)  # use max to prevent negative index\n",
    "                win_end = min(len(css_lst), gene_start - num_2)  # use min to prevent index out of range\n",
    "                # Check if enhancer region overlaps with the body of the previous gene\n",
    "                if win_start < prev_gene_end:\n",
    "                    win_start = prev_gene_end+1\n",
    "                enh_by_loc_css = css_lst[win_start:win_end]\n",
    "#                 print(\"[win_start,win_end]\",[win_start,win_end])\n",
    "#                 print(\"length = \", win_end-win_start )\n",
    "                if len(enh_by_loc_css) >= 200:\n",
    "                    enh_by_loc_css_chr.append(enh_by_loc_css) \n",
    "                prev_gene_end = gene_end \n",
    "            enh_by_loc_css_all.append(enh_by_loc_css_chr)\n",
    "        enh_by_loc_css_unit_all=Convert2unitCSS_main_new(enh_by_loc_css_all, unit=unit)  \n",
    "        output_file_name=os.path.join(output_path,cell_num+\"_enhancer_up100k2k.pkl\")\n",
    "        with open(output_file_name,\"wb\") as g:\n",
    "            pickle.dump(enh_by_loc_css_unit_all,g)\n",
    "\n",
    "    return print(\"All done!\") #enh_by_loc_css_unit_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6837947b",
   "metadata": {},
   "source": [
    "### 3-8-2. Extract Enhancer regions from gene with various expression level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e106d1",
   "metadata": {},
   "source": [
    "#### Pipeline  (modified from those for promoter)\n",
    "\n",
    "(1) `ENH_expGene2css` : cut the enhancer regions of long css <br>\n",
    "(2) `extENH_wrt_g_exp` : transform css into unit length css <br>\n",
    "(3) `extNsaveENH_g_exp` : load the required file and process all, and save\n",
    "\n",
    "**Usage:** <br>\n",
    "`for rpkm_val in [0,10,20,30,50]:` <br>\n",
    "   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`extNsaveENH_g_exp(rpkm_val=rpkm_val)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "660f3031",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ENH_expGene2css(g_lst_chr_merged,df, num_1=100000, num_2=2000):   # df indicates css, created by bed2df_expanded\n",
    "    \"\"\"\n",
    "    modified from `compGene2css`\n",
    "    Input: Reference gene file trimmed for gene expresseion level, df (CSS)\n",
    "    Output: list of chromosome-wise list that contains the css at (expressed) genic area with prom only.\n",
    "    \"\"\"\n",
    "    g_lst_chr=g_lst_chr_merged\n",
    "    df = df[df['chromosome'] != 'chrM']\n",
    "    css_lst_chr=df2longcss(df) # list of long css per chromosome\n",
    "    \n",
    "    g_lst_chr = g_lst_chr[:len(css_lst_chr)]  # adjust the length of list according to length of df (might not have chrY)\n",
    "    total_chr=len(css_lst_chr)\n",
    "    \n",
    "    print(\"Matching to the chromatin state sequence data ...\")\n",
    "    css_enh_lst_all=[]\n",
    "    for i in tqdm_notebook(range(total_chr)):\n",
    "        css=css_lst_chr[i]   # long css of i-th chromosome\n",
    "        gene_df=g_lst_chr[i] # gene df of i-th chromosome\n",
    "        \n",
    "        css_enh_lst_chr=[]\n",
    "        prev_gene_end = 0  # Initialize with 0 since there's no gene before the first one\n",
    "        for j in range(len(gene_df)):\n",
    "            gene_start=gene_df[\"TxStart\"].iloc[j]\n",
    "            gene_end=gene_df[\"TxEnd\"].iloc[j]\n",
    "            \n",
    "            enh_start = max(0, gene_start - num_1)  # use max to prevent negative index\n",
    "            enh_end = min(len(css), gene_start - num_2)  # use min to prevent index out of range\n",
    "#             enh_start=gene_start-1-num_1  # python counts form 0\n",
    "#             enh_end=gene_start-num_2+1      # python excludes the end\n",
    "            if enh_start < prev_gene_end:\n",
    "                enh_start = prev_gene_end+1\n",
    "            css_enh = css[enh_start:enh_end]\n",
    "            if len(css_enh) >= 200:\n",
    "                css_enh_lst_chr.append(css_enh)\n",
    "            prev_gene_end = gene_end \n",
    "          \n",
    "        css_enh_lst_all.append(css_enh_lst_chr)  # list of list\n",
    "    \n",
    "    assert len(css_enh_lst_all)==total_chr\n",
    "    \n",
    "    # remove chromosome if it is empty (e.g. chrY for female)\n",
    "    css_enh_lst_all=[elm for elm in css_enh_lst_all if elm!=[]] \n",
    "    \n",
    "    print(\"Done!\")\n",
    "    return css_enh_lst_all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5721c414",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extENH_wrt_g_exp(exp_gene_file, df, num_1=100000, num_2=2000,unit=200):\n",
    "    \"\"\"\n",
    "    extract enhancer regions of genes according to gene expression level\n",
    "    \"\"\"\n",
    "    df = df[df['chromosome'] != 'chrM']\n",
    "    g_lst_chr=Gexp_Gene2GLChr(exp_gene_file)\n",
    "    g_lst_chr_merged=merge_intervals(g_lst_chr)\n",
    "    \n",
    "    css_enh_lst_all=ENH_expGene2css(g_lst_chr_merged,df, num_1=num_1, num_2=num_2)\n",
    "    css_enh_lst_unit_all=Convert2unitCSS_main_new(css_enh_lst_all, unit=unit)\n",
    "    return css_enh_lst_unit_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a71da0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extNsaveENH_g_exp(exp_gene_dir=\"../database/roadmap/gene_exp/refFlat_byCellType/\", df_pickle_dir=\"../database/roadmap/df_pickled/\",output_path=\"../database/roadmap/enhancer/up100k2k/gene_exp/\",rpkm_val=50, num_1=100000, num_2=2000,unit=200):\n",
    "    exp_gene_subdir=os.listdir(exp_gene_dir)\n",
    "    exp_gene_tardir=[os.path.join(exp_gene_dir, subdir) for subdir in exp_gene_subdir if str(rpkm_val) in subdir][0]    \n",
    "    if rpkm_val==0:\n",
    "        exp_gene_tardir=os.path.join(exp_gene_dir, \"rpkm0\")\n",
    "        \n",
    "    exp_gene_files=sorted([os.path.join(exp_gene_tardir,file) for file in os.listdir(exp_gene_tardir)])\n",
    "    \n",
    "    for exp_gene_file in exp_gene_files:\n",
    "        cell_id=exp_gene_file.split(\"/\")[-1][:4]\n",
    "#         if cell_id==\"E004\":break ## for test\n",
    "        df_name=[file for file in os.listdir(df_pickle_dir) if cell_id in file][0]\n",
    "        df_path=os.path.join(df_pickle_dir,df_name)\n",
    "        with open(df_path,\"rb\") as f:\n",
    "            df=pickle.load(f)\n",
    "        css_enh_lst_unit_all=extENH_wrt_g_exp(exp_gene_file, df, num_1=num_1, num_2=num_2, unit=unit)\n",
    "           \n",
    "        output_name=output_path+\"rpkm\"+str(rpkm_val)+\"/\"+cell_id+\"_enhancer_up100k2k.pkl\"\n",
    "        output_dir = os.path.dirname(output_name)\n",
    "        \n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "        with open(output_name, \"wb\") as g:\n",
    "            pickle.dump(css_enh_lst_unit_all,g)\n",
    "    return print(\"Saved at \",output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3483c8b7",
   "metadata": {},
   "source": [
    "### 3-8-3. Extract Enhancer regions from not expressed genes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08285368",
   "metadata": {},
   "source": [
    "Also similar to promoter case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d48170e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ENH_extNsaveNOTexp_by_compare(whole_gene_ref_path=\"../database/roadmap/gene_exp/chr.gene.refFlat\",\n",
    "                              exp_ref_path=\"../database/roadmap/gene_exp/refFlat_byCellType/rpkm0/\",\n",
    "                              df_pickle_dir=\"../database/roadmap/df_pickled/\",\n",
    "                              output_path_ref=\"../database/roadmap/gene_exp/refFlat_byCellType/not_exp/\",\n",
    "                              output_path_enhancer=\"../database/roadmap/enhancer/up100k2k/gene_exp/not_exp/\",\n",
    "                              num_1=100000,num_2=2000,unit=200):\n",
    "    \n",
    "    exp_ref_file_all=sorted([os.path.join(exp_ref_path,file) for file in os.listdir(exp_ref_path)])\n",
    "    \n",
    "    for exp_ref_file in exp_ref_file_all:\n",
    "        cell_id=exp_ref_file.split(\"/\")[-1][:4]\n",
    "#         if cell_id==\"E004\":break # for test\n",
    "        print(cell_id+\" is now processing...\")\n",
    "            \n",
    "        df_name=[file for file in os.listdir(df_pickle_dir) if cell_id in file][0]\n",
    "        df_path=os.path.join(df_pickle_dir,df_name)\n",
    "        with open(df_path,\"rb\") as f:\n",
    "            df=pickle.load(f)\n",
    "        \n",
    "        non_exp_gene_lst=extNOTexp_by_compare(whole_gene_ref_path, exp_ref_file) # a list of chromosome-wise df\n",
    "        #### refFlat for NOT expressed is pickled as a list of dataframe ####\n",
    "        not_exp_ref_path=output_path_ref+cell_id+\"_gene_not_expressed.pkl\"\n",
    "        with open(not_exp_ref_path,\"wb\") as g:\n",
    "            pickle.dump(non_exp_gene_lst,g)        \n",
    "#         css_prom_lst_all=prom_expGene2css(non_exp_gene_lst, df, up_num=up_num, down_num=down_num)\n",
    "#         css_prom_lst_unit_all=Convert2unitCSS_main_new(css_prom_lst_all, unit=unit)\n",
    "        css_enh_lst_all=ENH_expGene2css(non_exp_gene_lst, df, num_1=num_1, num_2=num_2)\n",
    "        css_enh_lst_unit_all=Convert2unitCSS_main_new(css_enh_lst_all, unit=unit)\n",
    "        \n",
    "        output_name=output_path_enhancer+cell_id+\"_not_exp_gene_enhancer_up100k2k.pkl\"\n",
    "        with open(output_name,\"wb\") as h:\n",
    "            pickle.dump(css_enh_lst_unit_all,h)\n",
    "    \n",
    "    return print(\"refFlat is saved at {} and prom is saved at {}.\".format(output_path_ref, output_path_enhancer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a144d5c2",
   "metadata": {},
   "source": [
    "### 3-8-4. Kmerize and save and merge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2eb5c1b",
   "metadata": {},
   "source": [
    "Also similar to promoter case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08f3d351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ENH_css_Kmer_by_cell(path=\"../database/roadmap/enhancer/up100k2k/all_genes/\", output_path=\"../database/pretrain/enhancer/up100k2k/all_genes/\",k=4):\n",
    "    output_dir=str(k)+\"mer/\"\n",
    "    output_path_fin=os.path.join(output_path, output_dir)\n",
    "    all_files=sorted([os.path.join(path, file) for file in os.listdir(path)]) \n",
    "    \n",
    "    for file in all_files:\n",
    "        enh_kmer_all=[]\n",
    "        cell_id=file.split(\"/\")[-1][:4]\n",
    "#         if cell_id==\"E004\": break # for test use\n",
    "        with open(file, \"rb\") as f:\n",
    "            enh=pickle.load(f)\n",
    "        enh_css=flatLst(enh)  # make a list from list of a list\n",
    "        enh_kmer=[seq2kmer(item,k) for item in enh_css]\n",
    "        enh_kmer_all.append(enh_kmer)\n",
    "        enh_kmer_all_flt=flatLst(enh_kmer_all)\n",
    "        enh_kmer_all_flt_not_zero=[item for item in enh_kmer_all_flt if item!=\"\"]\n",
    "        output_name=cell_id+\"_all_genes_enhancer_\"+str(k)+\"merized.txt\"\n",
    "        with open(output_path_fin+output_name, \"w\") as g:\n",
    "            g.write(\"\\n\".join(enh_kmer_all_flt_not_zero))\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be94907",
   "metadata": {},
   "source": [
    "### 3-8-5. Fine-tuning save byCellType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1b07c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FT_save_byCellType(input_path=\"../database/pretrain/enhancer/up100k2k/all_genes/\",\n",
    "                 output_path=\"../database/fine_tune/enhancer/up100k2k/byCellType/\",\n",
    "                 cl1=\"E033\",cl2=\"E115\", \n",
    "                 len_tr=20000, len_dev=1000,\n",
    "                 k=4):\n",
    "    \n",
    "    sub_path=os.path.join(input_path,str(k)+\"mer\")\n",
    "    tar_cl1=[file for file in os.listdir(sub_path) if cl1 in file][0]\n",
    "    cl1_path=os.path.join(sub_path,tar_cl1)\n",
    "    tar_cl2=[file for file in os.listdir(sub_path) if cl2 in file][0]\n",
    "    cl2_path=os.path.join(sub_path,tar_cl2)\n",
    "    \n",
    "    with open(cl1_path,\"r\") as f1:\n",
    "        cl1_lst=[line.strip() for line in f1]\n",
    "    with open(cl2_path, \"r\") as f2:\n",
    "        cl2_lst=[line.strip() for line in f2]\n",
    "   \n",
    "    # make it dataframe\n",
    "    df_cl1=pd.DataFrame(cl1_lst, columns=[\"sequence\"])  # contrast, e.g.) normal cell\n",
    "    df_cl1[\"label\"]=0\n",
    "    df_cl2=pd.DataFrame(cl2_lst, columns=[\"sequence\"])  # experiment, e.g.) cancer cell\n",
    "    df_cl2[\"label\"]=1\n",
    "\n",
    "    # make them have the same length\n",
    "    if len(df_cl1)>len(df_cl2):\n",
    "        df_cl1=df_cl1.sample(n=len(df_cl2), random_state=1) # use the same random state for reproducibility\n",
    "    elif len(df_cl1)<len(df_cl2):\n",
    "        df_cl2=df_cl2.sample(n=len(df_cl1), random_state=1) # use the same random state for reproducibility\n",
    "    assert len(df_cl1)==len(df_cl2), \"Check the data length.\"\n",
    "\n",
    "    df_all=pd.concat([df_cl1,df_cl2]).sample(frac=1).reset_index(drop=True) \n",
    "\n",
    "    # cutting into train and dev\n",
    "    assert len(df_all)> len_tr+len_dev, \"Not enough data length.\"\n",
    "    df_train=df_all[:len_tr]\n",
    "    df_dev=df_all[len_tr:len_tr+len_dev]    \n",
    "\n",
    "    # save at the fine tuning folder\n",
    "    data_type=cl1+\"_n_\"+cl2\n",
    "    \n",
    "    output_path_fin=os.path.join(output_path,str(k)+\"mer\",data_type)\n",
    "\n",
    "    # Check if the directory exists\n",
    "    if not os.path.exists(output_path_fin):\n",
    "        # If the directory does not exist, create it\n",
    "        os.makedirs(output_path_fin)\n",
    "    \n",
    "    train_name=os.path.join(output_path_fin,\"train.tsv\")\n",
    "    dev_name=os.path.join(output_path_fin,\"dev.tsv\")\n",
    "\n",
    "    df_train.to_csv(train_name, sep=\"\\t\", index=False)\n",
    "    df_dev.to_csv(dev_name, sep=\"\\t\", index=False)\n",
    "    print(\"Fine tuning files are saved at \", output_path_fin)\n",
    "    return df_train,df_dev\n",
    "\n",
    "###################################################################################################\n",
    "# kmers=[3,4,5,6]\n",
    "# exp_lst=[(\"E033\", \"E115\"),(\"E034\", \"E115\"),(\"E066\", \"E118\"),(\"E096\", \"E114\")]\n",
    "# for k in kmers:\n",
    "#     #if k==4:break # for test\n",
    "#     for i in range(len(exp_lst)):\n",
    "#         cl1=exp_lst[i][0]\n",
    "#         cl2=exp_lst[i][1]\n",
    "#         FT_save_byCellType(input_path=\"../database/pretrain/enhancer/up100k2k/all_genes/\",\n",
    "#                  output_path=\"../database/fine_tune/enhancer/up100k2k/byCellType/\",\n",
    "#                  cl1=cl1,cl2=cl2, \n",
    "#                  len_tr=20000, len_dev=1000,\n",
    "#                  k=k)\n",
    "###################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b37d5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45d9b63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bc3420",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc72630d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1d7e84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4154e248",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7d7e883",
   "metadata": {},
   "source": [
    "#### Funtion `cutKmerByCell`\n",
    "* Input: file path of a bed file like`\"../database/temp_files/whole_genome/byCellType/E001_whole_css_wo_telo.txt\"`)\n",
    "* Output: randomly cut from 5 to 510, without telomere, filtered to have longer than k, css list\n",
    "* Further work: save it as follows\n",
    "> `with open(output_path,\"w\") as save_file: `<br>\n",
    ">  <hspace> `save_file.write(\"\\n\".join(filtered_kmerized_unit_css))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c5153aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutKmerByCell(unzipped_bed_file_path,k=4):\n",
    "    df=bed2df_expanded(path)\n",
    "    unit_css=df2unitcss(df)\n",
    "    assert isinstance(unit_css[0], str) \n",
    "    if len(unit_css[0])>=50 and len(unit_css[-1])>50:\n",
    "        unit_css[0]=unit_css[0][50:] # cut the telomere\n",
    "        unit_css[-1]=unit_css[-1][:-50] # cut the telomere\n",
    "        \n",
    "    _, kmerized_unit_css=css_CUT_Kmer(unit_css, cut_thres=510, k=k)\n",
    "    \n",
    "    filtered_kmerized_unit_css=[item for item in kmerized_unit_css if len(item)>=k]\n",
    "    return filtered_kmerized_unit_css"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b10ad80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b98da3a7",
   "metadata": {},
   "source": [
    "# 4. CSS Pattern analysis\n",
    "**[back to index](#Index)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd9ff7c",
   "metadata": {},
   "source": [
    "## 4-1. For 15th-including data\n",
    "\n",
    "* Target data: CSS dataset with 15th state included\n",
    "* Starting data is acquired from `all_unit_css=df2unitcss(df)` [Jump](#Unit-length-css)\n",
    "* `all_unit_css` is a list, the element of which is chromosome-wise all-connected **unit-length** (per 200 bp) CSS\n",
    "> `len(all_unit_css)` = 24 <br>\n",
    "> `len(all_unit_css[0])` =1246253\n",
    "<!-- * Start from the process [3-2. Cut the telomere region on CSS and save the file](#3-2.-Cut-the-telomere-region-on-CSS-and-save-the-file) -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "536fc5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## but it must be a distribution where 15th states covers almost of the entire area. \n",
    "## So I stopped here, because basic statistics are known from 4-2. For 15th-less data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2002887f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5c1117",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "818f9291",
   "metadata": {},
   "source": [
    "## 4-2. For 15th-less data\n",
    "\n",
    "Now the dataframe has been transformed into a list of string all connected css, chromosome-wise.<br>\n",
    "The variable of the above list is now called chr_css_list.<br>\n",
    "Following functions will analyze the statistics of the each strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cd84237f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def css_list2count(df, chr_css_list):\n",
    "    \n",
    "    \"\"\"Input: chr_css_list acquired by df2css_chr_str(df), \n",
    "    which is a list of string all connected css, chromosome-wise.\n",
    "    Output: a dataframe (col: chromosome, row:letter)\"\"\"\n",
    "    \n",
    "    state_alphabets=list(state_dict.values())\n",
    "    chr_names=list(df[\"chromosome\"].unique())\n",
    "    count_all=pd.DataFrame(columns=chr_names, index=state_alphabets)  # create an empty dataframe \n",
    "    \n",
    "    for num, _ in enumerate(chr_css_list):   # for each chromosome..\n",
    "        chr_css=chr_css_list[num]\n",
    "        chr_name=chr_names[num]\n",
    "\n",
    "        for letter in state_alphabets:   # count the number of A, B, C, D ... in the string\n",
    "            count_all.loc[letter][chr_name]=chr_css.count(letter)\n",
    "    \n",
    "    return count_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5dbe712c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_count_barplot_incl15(count_all, chr_no):\n",
    "    \n",
    "    \"\"\" Draw a bar plot (chromatin state vs. count) per chromosome\n",
    "    input(1) table of 'count_all' which is created by the function css_list2count(df, chr_css_list) \n",
    "    input(2) chromosome name in string, e.g.) 'chr1', 'chr2', ... \n",
    "    output: bar plot of the all chromatin state count (including 15th state)\"\"\"\n",
    "\n",
    "    count_all_renamed=count_all.rename(index=css_dict)\n",
    "    color_dec=colors2color_dec(css_color_dict)\n",
    "    count_all_renamed.loc[:,chr_no].plot.bar(rot=45, color=color_dec)\n",
    "    ax0=ax0.set_ylabel(\"Counts\", fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "aecf17ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_count_barplot_wo15(count_all, chr_no):\n",
    "    \n",
    "    \"\"\" Draw a bar plot (chromatin state vs. count) per chromosome\n",
    "    input(1) table of 'count_all' which is created by the function css_list2count(df, chr_css_list) \n",
    "    input(2) chromosome name in string, e.g.) 'chr1', 'chr2', ... \n",
    "    output: bar plot of the all chromatin state count except for 15th state\"\"\"\n",
    "\n",
    "    count_all_renamed=count_all.rename(index=css_dict)\n",
    "    color_dec=colors2color_dec(css_color_dict)\n",
    "    ax0=count_all_renamed.loc[:,chr_no][:-1].plot.bar(rot=45, color=color_dec)\n",
    "    ax0.set_ylabel(\"Counts\", fontsize=14)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5bef3b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def colored_css_str(sub_str):\n",
    "    col_str=\"\"\n",
    "    for letter in sub_str:\n",
    "        for state in list(state_col_255_dict.keys()):\n",
    "            if letter==state:\n",
    "                r=state_col_255_dict[letter][0]\n",
    "                g=state_col_255_dict[letter][1]\n",
    "                b=state_col_255_dict[letter][2]\n",
    "                col_letter=\"\\033[38;2;{};{};{}m{}\\033[38;2;255;255;255m\".format(r,g,b,letter)\n",
    "                col_str+=col_letter\n",
    "    return print(\"\\033[1m\"+col_str+\"\\033[0;0m\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067f5b22",
   "metadata": {},
   "source": [
    "**Frequently used function!** <br>\n",
    "To convert any string into colored string according to the color palette for CSS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "aa9c144e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def colored_css_str_as_is(sub_str):   # convert space into space\n",
    "    col_str=\"\"\n",
    "    for letter in sub_str:\n",
    "        if letter==\" \":\n",
    "            col_str+=\" \"\n",
    "        else:                \n",
    "            for state in list(state_col_255_dict.keys()):\n",
    "                if letter==state:\n",
    "                    r=state_col_255_dict[letter][0]\n",
    "                    g=state_col_255_dict[letter][1]\n",
    "                    b=state_col_255_dict[letter][2]\n",
    "                    col_letter=\"\\033[38;2;{};{};{}m{}\\033[38;2;255;255;255m\".format(r,g,b,letter)\n",
    "                    col_str+=col_letter\n",
    "    return print(\"\\033[1m\"+col_str+\"\\033[0;0m\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fece48",
   "metadata": {},
   "source": [
    "#### css pattern analysis without 15th state (state **O**)\n",
    "\n",
    "1. create a list of a css without 15th state, the element of which is connected (df2inbetweeen_lst)\n",
    "2. create a whole list of css without 15th state, using a all-chromosome df (df2wo15list)\n",
    "3. calculate the length of each element of the generated list, and analyze the statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7b009962",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df2inbetweeen_lst(df):\n",
    "    lst=[]\n",
    "    df_wo_o=df[df[\"state\"]!=15]   #remove the 15th state from the css\n",
    "    css_df=df_wo_o[\"state_seq_full\"]\n",
    "    str_elm=css_df.iloc[0]  # the very first elm\n",
    "    for i in range(1, len(css_df)):\n",
    "        # check the index first\n",
    "        cid=css_df.index[i] #init=1\n",
    "        pid=css_df.index[i-1] # init=0\n",
    "        ssf=css_df\n",
    "        if (cid-pid)!=1: # if the index is separated (not a succeeding numbers)\n",
    "            lst.append(str_elm)\n",
    "            str_elm=ssf.iloc[i]\n",
    "        else:            # if encountered a consecutive index\n",
    "            str_elm+=ssf.iloc[i] # attach the next str to the previous str\n",
    "            if i==len(css_df)-1:   # treat the final line\n",
    "                lst.append(str_elm)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "086119b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df2wo15list(df):\n",
    "    total_lst=[]\n",
    "    df_chr_list=df2chr_df(df)   # a list, elm of which is the df of each chromosome\n",
    "    for df_chr in df_chr_list:   # for each chromosome, create a grand list by adding up the whole\n",
    "        lst_chr=df2inbetweeen_lst(df_chr)\n",
    "        total_lst+=lst_chr\n",
    "    return total_lst   # total_lst here consists of the connected-patterns betweeen 15th state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c2bd4a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def css_elm_stat(total_lst):# graph of the length distribution \n",
    "    len_lst=[]              # total_lst here consists of the connected-patterns betweeen 15th state\n",
    "    for elm in total_lst:\n",
    "        assert type(elm)==str, \"element type is not string\"\n",
    "        len_lst.append(len(elm))\n",
    "    print(\"total count: \", len(total_lst))\n",
    "    print(\"max length: \", max(len_lst))\n",
    "    print(\"min length: \", min(len_lst))\n",
    "    print(\"average length: \",np.mean(len_lst))\n",
    "    fig =plt.figure(figsize=(6,4))\n",
    "    plt.hist(len_lst, bins=20, log=True, color=\"teal\", edgecolor=\"white\")\n",
    "    plt.xlabel(\"length of chromatin state pattern\", fontsize=14)\n",
    "    plt.ylabel(\"Count\", fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e198cc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lst2let_compose(total_lst):# graph of the number of letter composed for a pattern\n",
    "    letter_cnt=[]              # total_lst here consists of the connected-patterns betweeen 15th state\n",
    "    for word in total_lst:\n",
    "        chk_let=word[0]\n",
    "        num_let=1\n",
    "        for let in word:\n",
    "            if let!=chk_let:\n",
    "                num_let+=1\n",
    "                chk_let=let\n",
    "        letter_cnt.append(num_let)\n",
    "    print(\"total count: \", len(letter_cnt))\n",
    "    print(\"max composition: \", max(letter_cnt))\n",
    "    print(\"min composition: \", min(letter_cnt))\n",
    "    print(\"average composition: \", np.mean(letter_cnt))\n",
    "    fig =plt.figure(figsize=(6,4))\n",
    "    plt.hist(letter_cnt, bins=20, log=True, color=\"orange\", edgecolor=\"white\")\n",
    "    plt.xlabel(\"number of state in a composition\", fontsize=14)\n",
    "    plt.ylabel(\"Count\", fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9269b02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_colorlist(data_dict):\n",
    "    \n",
    "    \"\"\" \n",
    "    INPUT: solo chromatin state data in dict such as \n",
    "           data_dict={'I': 114, 'A': 23, 'N': 119, 'G': 33, 'E': 131, 'H': 1}\n",
    "    OUTPUT: customized colormap according to ROADMAP (type=list)\n",
    "    \"\"\"\n",
    "    state_list=list(data_dict.keys())\n",
    "    colormap_list=[]\n",
    "    assert type(state_list[0])==str\n",
    "    for state in state_list:\n",
    "        if css_dict[state] in css_name_col_dict.keys():\n",
    "            color_rgb=css_name_col_dict[css_dict[state]]\n",
    "            colormap_list.append(color_rgb)\n",
    "    return colormap_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2327915a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lst2solo_compose(total_lst):# graph of a solo pattern frequency\n",
    "    \n",
    "    \"\"\"INPUT: the entire list of in-between pattern w.o. 15th state (total_lst)\n",
    "       OUTPUT: the most/least frequent solo pattern and the frequency graph\n",
    "    \"\"\"\n",
    "    \n",
    "    letter_cnt=[]\n",
    "    for word in total_lst:\n",
    "        chk_let=word[0]\n",
    "        num_let=1\n",
    "        for let in word:\n",
    "            if let!=chk_let:\n",
    "                num_let+=1\n",
    "                chk_let=let\n",
    "        letter_cnt.append(num_let)\n",
    "    css_lst_dict=dict(zip(total_lst, letter_cnt))\n",
    "    \n",
    "    lst_for_solo=[]                   # prepare to make a solo pattern list\n",
    "    for pattern, num in list(css_lst_dict.items()): # as a tuple element (key, val)\n",
    "        if num==1:\n",
    "            lst_for_solo.append(pattern[0])\n",
    "    solo_counter=collections.Counter(lst_for_solo)\n",
    "    solo_data_dict=dict(solo_counter) # ditionary of solo pattern and the frequency\n",
    "    solo_data_dict=dict(sorted(solo_data_dict.items(), reverse=True, key=lambda item: item[1]))\n",
    "    my_color=custom_colorlist(solo_data_dict)  # create a customized colormap using solo data\n",
    "    \n",
    "    for pattern, num in solo_data_dict.items():\n",
    "        if num is max(solo_data_dict.values()):\n",
    "            max_state=pattern\n",
    "            max_num=num\n",
    "        elif num is min(solo_data_dict.values()):\n",
    "            min_state=pattern\n",
    "            min_num=num\n",
    "\n",
    "    print(\"frequency of solo pattern: \", len(lst_for_solo))\n",
    "    print(\"the most frequent solo pattern: \", css_dict[max_state], \" for \", max_num, \" times appeared.\" )\n",
    "    print(\"the least frequent solo pattern: \", css_dict[min_state], \" for \", min_num, \" times appeared.\" )\n",
    "    \n",
    "    x=[css_dict[state] for state in solo_data_dict.keys()]\n",
    "    y=solo_data_dict.values()\n",
    "    \n",
    "    fig =plt.figure(figsize=(6,4))\n",
    "    plt.bar(x,y, color=my_color)\n",
    "    plt.xlabel(\"solo pattern\", fontsize=14)\n",
    "    plt.ylabel(\"Frequency\", fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56e48fe",
   "metadata": {},
   "source": [
    "#### make a kmer and save as a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7ff9bc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_lst2kmer(total_lst,k):\n",
    "    total_kmer_lst=[]\n",
    "    for elm in total_lst:\n",
    "        elm2kmer=seq2kmer(elm, k)\n",
    "        if len(elm2kmer) >0:   # remove the short pattern... will be fine?\n",
    "            total_kmer_lst.append(elm2kmer)\n",
    "    return total_kmer_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7100ccca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_kmer_lst=total_lst2kmer(total_lst,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "88b26d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name02=\"../database/test_data/6_tr01.txt\"\n",
    "# with open(file_name02,\"w\") as g:\n",
    "#     g.write(\"\\n\".join(total_kmer_lst))\n",
    "# g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e55f46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcba3c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11110dd0",
   "metadata": {},
   "source": [
    "# 5. Training result analysis\n",
    "**[back to index](#Index)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d7564d",
   "metadata": {},
   "source": [
    "## 5-1. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408a0e09",
   "metadata": {},
   "source": [
    "### 5-1-2. Pretrain evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "145de902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalDFconcat(df_lst, col_name, col_rename, colormap=\"Set1\"):\n",
    "    \"\"\"\n",
    "    Input\n",
    "    (1) df_lst: a list of target dataframes\n",
    "    (2) col_name: the columns of interest\n",
    "    (3) col_rename: a list of columns for the concatenated dataframes\n",
    "    \"\"\"\n",
    "    assert type(df_lst), \"Input should be a list of dataframes\"\n",
    "    assert type(col_rename), \"col_rename should be a list\"\n",
    "    assert len(df_lst)==len(col_rename), \"Check the length of input list\"\n",
    "    assert col_name in df_lst[0].columns, \"'{}' is not in the column list of dataframe\".format(col_name)\n",
    "    df_col_lst=[]\n",
    "    for num in range(len(df_lst)):       \n",
    "        df_col_lst.append(df_lst[num][col_name])\n",
    "    df_concat=pd.concat(df_col_lst, axis=1)\n",
    "    df_concat.columns=col_rename\n",
    "    \n",
    "    fig=plt.figure(figsize=(6,4))\n",
    "    p=sns.lineplot(data=df_concat, palette=colormap)\n",
    "    p.set_ylabel(col_name, fontsize=14)\n",
    "    p.set_xlabel(\"Iteration\", fontsize=14)\n",
    "#     p.set_ylim(1.0,2.8)\n",
    "    p.legend(fontsize=14)\n",
    "    \n",
    "    return df_concat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b28b0bb",
   "metadata": {},
   "source": [
    "#### Function: `evalPre_by_folder` \n",
    "\n",
    "* Usage: Create a dataframe and show the result plot of pretraining \n",
    "* Input: path of the pretraining result, basically under the folder `../database/pretrain/`\n",
    "* User input: `\"all\"` or a list of integer, such as `[0,1,2]`, as you can select from the list this function shows. \n",
    "* Output: Plot of perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1657291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalPre_by_folder(path,target='all',colormap=\"Set1\", ylim=6.5):\n",
    "    \"\"\"\n",
    "    path: the directory you have the pretrain result (eval_results.txt)\n",
    "          Multiple files can be processed.\n",
    "    target: if designated as \"all\", it considers all the files. \n",
    "            Otherwise, a list containing the numbers of the file you want to analyze should be given.\n",
    "    \"\"\"\n",
    "    file_list=[os.path.join(path, file) for file in sorted(os.listdir(path))]\n",
    "    print(\"\\n\".join(file_list))\n",
    "\n",
    "    target = input(\"Enter 'all' to process all files or a list of file numbers to process (ex. [1,2,3]): \")\n",
    "\n",
    "    if target == 'all':\n",
    "        target = 'all'\n",
    "    else:\n",
    "        try:\n",
    "            target = ast.literal_eval(target)\n",
    "            if not all(isinstance(i, int) for i in target):\n",
    "                raise ValueError(\"Invalid input, target should be 'all' or a list of integers.\")\n",
    "            for i in target:\n",
    "                if i > len(file_list):\n",
    "                    raise ValueError(\"Invalid file number\")\n",
    "        except (ValueError, SyntaxError):\n",
    "            raise ValueError(\"Invalid input, target should be 'all' or a list of integers in the format [1,2,3].\")\n",
    "\n",
    "    file_df_all=[]\n",
    "    if target=='all':        \n",
    "        for i, file in enumerate(file_list):\n",
    "            f_name=re.search(r'eval_results_(.*).txt', file).group(1)\n",
    "            file_df=pd.read_csv(file, header=None, names=[\"perplexity\"])\n",
    "            file_df.rename(columns={'perplexity': f_name}, inplace=True)\n",
    "            file_df_all.append(file_df)\n",
    "        result_df = pd.concat(file_df_all, axis=1)\n",
    "        \n",
    "    elif type(target)==list and type(target[0])==int:\n",
    "        for i in target:\n",
    "            f_name=re.search(r'eval_results_(.*).txt', file_list[i]).group(1)\n",
    "            file_df=pd.read_csv(file_list[i], header=None, names=[\"perplexity\"])\n",
    "            file_df.rename(columns={'perplexity': f_name}, inplace=True)\n",
    "            file_df_all.append(file_df)\n",
    "        result_df = pd.concat(file_df_all, axis=1)\n",
    "        \n",
    "    fig=plt.figure(figsize=(6,4))\n",
    "    p=sns.lineplot(data=result_df, palette=colormap)\n",
    "    p.set_xlabel(\"Iternation\", fontsize=13)\n",
    "    p.set_ylim([0.5, ylim])\n",
    "    \n",
    "    return result_df    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39ffef8",
   "metadata": {},
   "source": [
    "### 5-1-3. Fine tuning evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03d0ed4",
   "metadata": {},
   "source": [
    "The result of fine-tuning is provided by a `eval_result.txt` file by default, which contains acc (accuracy), auc (area under curve), mcc (Matthew's correlation coefficient), f1 score, precision, and recall. Those files can be saved with different names which contain the different experimental condition. \n",
    "\n",
    "The series of functions below are the unit functions for internal use, or simple use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95311d0",
   "metadata": {},
   "source": [
    " #### Function: `evalFT_df`\n",
    " * Create dataframe from the raw file `eval_result.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82aa8282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalFT_df(path):\n",
    "    \"\"\"\n",
    "    Unit function for eval_result.txt obtained after the fine tuning\n",
    "    \"\"\"\n",
    "    df=pd.read_csv(path, index_col=False, sep=\"\\s\", header=None, engine='python')\n",
    "    df.columns=[\"k\",\"acc\",\"auc\",\"f1\",\"mcc\",\"precision\",\"recall\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83de1135",
   "metadata": {},
   "source": [
    "#### Function `evalFT_fig`\n",
    "* Draw af figure for a single `eval_result.txt` file at the designated path. \n",
    "* Inputs\n",
    "    * `path` : path of the raw file\n",
    "    * `target` : any of `[acc\",\"auc\",\"f1\",\"mcc\",\"precision\",\"recall\"]` as a string, or a sub-list can be accepted\n",
    "    * `kwargs` : title can be added.\n",
    "* Output: a dataframe where the target is the column, row is the eval over iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e3856745",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalFT_fig(path, iteration=60, target=\"auc\", figsize=(4,2.5), colormap=\"Set1\", **kwargs):\n",
    "    \"\"\"\n",
    "    Unit function for drawing the figure only\n",
    "    \"target\" should be designated, either string or a list of strings\n",
    "    \"\"\"\n",
    "    df=evalFT_df(path)\n",
    "    fig=plt.figure(figsize=figsize)\n",
    "    plt.ylim([0,1])\n",
    "    plt.ylabel(\"metrics\")\n",
    "    plt.xlabel(\"iterations\")\n",
    "    color_lst=sns.color_palette(colormap)\n",
    "    line_lst=[\"-\",\"--\",\":\"]\n",
    "\n",
    "    if \"title\" in kwargs:\n",
    "        title=kwargs[\"title\"]\n",
    "        plt.title(title)\n",
    "    \n",
    "    df_target=pd.DataFrame()\n",
    "    \n",
    "    if not isinstance(target,list):\n",
    "        sns.lineplot(df[target][:iteration], label=target)\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        auc_avg_f10=np.mean(df[\"auc\"][:iteration].iloc[-10:])\n",
    "        df_target[target]=list(df[target][:iteration])\n",
    "        plt.text(2, 0.1, \"final 10 AUC avg. \"+str(round(auc_avg_f10,3)))\n",
    "    else:    \n",
    "        for i, tar in enumerate(target):\n",
    "            sns.lineplot(df[tar][:iteration], label=tar, linestyle=line_lst[i], color=color_lst[i])\n",
    "            plt.legend(loc=\"lower right\")\n",
    "            auc_avg_f10=np.mean(df[\"auc\"][:iteration].iloc[-10:])\n",
    "            plt.text(2, 0.1, \"final 10 AUC avg. \"+str(round(auc_avg_f10,3)))\n",
    "            \n",
    "            target_val_lst=list(df[tar][:iteration])\n",
    "            df_target[tar]=target_val_lst\n",
    "            \n",
    "    return  df_target "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561955a3",
   "metadata": {},
   "source": [
    "#### Function `evalFT_overview`\n",
    "* Show the result of evaluation in a figure\n",
    "* Input:\n",
    "    * `path_all` : either one or multiple paths\n",
    "    * `target`: any of `[acc\",\"auc\",\"f1\",\"mcc\",\"precision\",\"recall\"]` as a string, or a sub-list can be accepted\n",
    "* Output: a dictionary (key: different condition, value: dataframe of evaluation over time, for designated targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b1bd46f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalFT_overview(path_all,iteration, target,colormap=\"Set1\", show_depth=-2):\n",
    "    \n",
    "    if not isinstance(path_all,list):\n",
    "        df_target=evalFT_fig(path_all,iteration=iteration, target=target, figsize=(4,2.5), colormap=colormap)\n",
    "\n",
    "    else:\n",
    "        keys=[]\n",
    "        values=[]\n",
    "        for i, path in enumerate(path_all):\n",
    "            file_name_lst=os.path.splitext(path)[0].split(\"/\")[show_depth:]\n",
    "            title='   '.join(file_name_lst)\n",
    "            keys.append(file_name_lst[0])\n",
    "            df_target=evalFT_fig(path, iteration=iteration, target=target, colormap=colormap, title=title)\n",
    "            values.append(df_target)    \n",
    "        dict_df_target=dict(zip(keys,values))\n",
    "        \n",
    "    return dict_df_target "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65548bdc",
   "metadata": {},
   "source": [
    "#### Function `dict_df_target_2_bar_graph`\n",
    "\n",
    "* Create a bargraph set for different metrics\n",
    "* Run after the `evalFT_overview`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b1ce5bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_df_target_2_bar_graph(dict_df_target):\n",
    "    conds=dict_df_target.keys()\n",
    "    dfs=dict_df_target.values()\n",
    "    targets=list(list(dict_df_target.values())[0].columns) # produces a list like ['acc', 'auc', 'f1']\n",
    "    \n",
    "    all_mean_std={}\n",
    "    for target in targets:  # \"acc\", \"auc\", or \"f1\"       \n",
    "        dict_mean_std={}\n",
    "        for cond in conds: # for \"rpkm10_or_exp\" or \"rpkm30_or_not\"\n",
    "            target_val_lst=dict_df_target[cond][target]\n",
    "            mean_val=round(np.mean(target_val_lst),3)\n",
    "            std_val=round(np.std(target_val_lst),3)\n",
    "            mean_std=(mean_val, std_val)\n",
    "            dict_mean_std[cond]=mean_std\n",
    "         # dictionary of key \"acc\", \"auc\", or \"f1\" with the value of another dict 'rpkm10_or_exp':(mean,std)\n",
    "        all_mean_std[target]=dict_mean_std \n",
    "    \n",
    "    ### generate a bar graph\n",
    "    data=all_mean_std\n",
    "    color_map = {'acc': 'cornflowerblue', 'auc': 'teal', 'f1': 'tomato'}\n",
    "    for condition in data.keys():\n",
    "        # Get the data for this condition\n",
    "        condition_data = data[condition]\n",
    "\n",
    "        # Separate keys and values\n",
    "        keys = list(condition_data.keys())\n",
    "        mean_values, std_devs = zip(*condition_data.values())\n",
    "\n",
    "        # Define positions\n",
    "        x_pos = range(len(keys))\n",
    "\n",
    "        # Create a bar graph\n",
    "        plt.figure(figsize=(5,3.5))  # create a new figure for each condition\n",
    "        plt.bar(x_pos, mean_values, yerr=std_devs, align='center', alpha=0.6, \n",
    "                ecolor='gray', capsize=7, color=color_map[condition])\n",
    "\n",
    "        # Add labels and title\n",
    "        plt.ylabel(condition)\n",
    "        plt.xticks(x_pos, keys, rotation=45, ha='right')\n",
    "        plt.yticks(np.arange(0,1.2,0.2))\n",
    "        plt.title(f'Mean Values for {condition} with Error Bars (std)')\n",
    "\n",
    "        # Show the graph\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return all_mean_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3564a4eb",
   "metadata": {},
   "source": [
    "#### Function: `pred_prob_overall` \n",
    "\n",
    "* **updated** for showing the results for separated cases (for the visualization purpose)\n",
    "* Usage: Create a dataframe for prediction result and show the result plot (confusion matrix, violin plot)\n",
    "* Input: path of the prediction result file (`pred_results.npy`) and the labeled file (`dev.tsv`)\n",
    "    * `dev_path=\"../database/fine_tune/CompG_and_lessCompG/4mer/dev.tsv\"`\n",
    "    * `pred_path=\"../database/ft_result/pred/4_compless/pred_results.npy\"`\n",
    "* Output: Two dataframes (`high_pred`: label 1 and its prediction ,`low_pred`: label 0 and its prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7c08e52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pred_prob_overall(dev_path,pred_path, color1=\"Blues\",color2_lst=[\"yellowgreen\",\"skyblue\",\"teal\",\"royalblue\"]):\n",
    "#     pred=np.load(pred_path)\n",
    "#     dev=pd.read_csv(dev_path, sep=\"\\t\")\n",
    "#     dev[\"pred\"]=pred\n",
    "#     dev[\"pred_bool\"]=None\n",
    "#     df=dev\n",
    "    \n",
    "#     assert type(color2_lst) and len(color2_lst)==4, \"enter a list of 4 elements, as color names\"\n",
    "    \n",
    "#     # confusion matrix #\n",
    "#     for i in range(len(df)):\n",
    "#         if df[\"pred\"].at[i]>=0.5 :\n",
    "#             df[\"pred_bool\"].at[i]=1\n",
    "#         else:\n",
    "#             df[\"pred_bool\"].at[i]=0\n",
    "#     assert df[\"pred_bool\"].isnull().any()==False, \"Check the pred_bool\"\n",
    "#     cf_matrix=confusion_matrix(df[\"label\"],df[\"pred_bool\"].astype(bool))\n",
    "\n",
    "#     group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "#     group_counts = [\"{0:0.0f}\".format(value) for value in cf_matrix.flatten()]\n",
    "#     group_percentages = [\"({0:.2%})\".format(value) for value in cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "#     labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "#     labels = np.asarray(labels).reshape(2,2)\n",
    "    \n",
    "#     # confusion matrix visualization\n",
    "#     sns.heatmap(cf_matrix, annot=labels, annot_kws={'size': 16}, fmt='', cmap=color1)\n",
    "#     print(classification_report(df[\"label\"], df[\"pred_bool\"].astype(bool)))\n",
    "    \n",
    "#     high_prob, low_prob=[],[]\n",
    "#     label_1, label_0=[],[]\n",
    "#     high_1, high_0=[],[]\n",
    "#     low_1, low_0=[],[]\n",
    "\n",
    "#     for i in range(len(df)):\n",
    "#         # high_prob is defined as larger than 0.5       \n",
    "#         if df[\"pred\"].iloc[i]>=0.5:\n",
    "#             high_prob.append(df[\"pred\"].iloc[i])\n",
    "#             label_1.append(df[\"label\"].iloc[i])\n",
    "#             if df[\"label\"].iloc[i]==1:  # predition is higher than 0.5(=true), and label is 1 (=true): true positive\n",
    "#                 high_1.append(df[\"pred\"].iloc[i])\n",
    "#             else:\n",
    "#                 high_0.append(df[\"pred\"].iloc[i])    \n",
    "#         else:\n",
    "#             low_prob.append(df[\"pred\"].iloc[i])\n",
    "#             label_0.append(df[\"label\"].iloc[i])\n",
    "#             if df[\"label\"].iloc[i]==0: # predition is lower than 0.5(=false), and label is 0 (=false): true negative\n",
    "#                 low_0.append(df[\"pred\"].iloc[i])\n",
    "#             else:\n",
    "#                 low_1.append(df[\"pred\"].iloc[i])\n",
    "\n",
    "# #     print(\"false positive: {} |  false negative: {}\".format(false_positive,false_negative))\n",
    "#     high_pred=pd.DataFrame({'label': label_1, 'pred': high_prob})\n",
    "#     low_pred=pd.DataFrame({'label': label_0, 'pred': low_prob})\n",
    "\n",
    "#     fig=plt.figure(figsize=(8,8))\n",
    "#     plt.subplots_adjust(wspace=0.5, hspace=0.5)\n",
    "#     plt.subplot(2, 2, 1)\n",
    "#     sns.violinplot(data=high_prob, color=color2_lst[0])\n",
    "#     plt.title('High Probability', fontsize=13)\n",
    "#     plt.xticks([])\n",
    "#     plt.xlabel(\"predition >= 0.5\", fontsize=13)\n",
    "#     plt.ylabel(\"Prediction\", fontsize=13)\n",
    "\n",
    "#     plt.subplot(2, 2, 2)\n",
    "#     sns.violinplot(data=low_prob, color=color2_lst[1])\n",
    "#     plt.title('Low Probability', fontsize=13)\n",
    "#     plt.xticks([])\n",
    "#     plt.xlabel(\"predition < 0.5\", fontsize=13)\n",
    "#     plt.ylabel(\"Prediction\", fontsize=13)\n",
    "    \n",
    "#     plt.subplot(2, 2, 3)\n",
    "#     sns.violinplot(data=high_1, color=color2_lst[2])\n",
    "#     plt.title('True positive', fontsize=13)\n",
    "#     plt.xticks([])\n",
    "#     plt.xlabel(\"For label 1\", fontsize=13)\n",
    "#     plt.ylabel(\"Prediction\", fontsize=13)\n",
    "    \n",
    "#     plt.subplot(2, 2, 4)\n",
    "#     sns.violinplot(data=low_0, color=color2_lst[3])\n",
    "#     plt.title('True negative', fontsize=13)\n",
    "#     plt.xticks([])\n",
    "#     plt.xlabel(\"For label 0\", fontsize=13)\n",
    "#     plt.ylabel(\"Prediction\", fontsize=13)\n",
    "\n",
    "#     plt.show()\n",
    "\n",
    "#     return high_pred,low_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c30259e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_prob_overall(dev_path,pred_path, file_id, color1=\"Blues\",color2_lst=[\"yellowgreen\",\"skyblue\",\"teal\",\"royalblue\"]):\n",
    "    pred=np.load(pred_path)\n",
    "    dev=pd.read_csv(dev_path, sep=\"\\t\")\n",
    "    dev[\"pred\"]=pred\n",
    "    dev[\"pred_bool\"]=None\n",
    "    df=dev\n",
    "    \n",
    "    file_output_path=\"../database/figs/\"\n",
    "    \n",
    "    assert type(color2_lst) and len(color2_lst)==4, \"enter a list of 4 elements, as color names\"\n",
    "    \n",
    "    # confusion matrix #\n",
    "    for i in range(len(df)):\n",
    "        if df[\"pred\"].at[i]>=0.5 :\n",
    "            df[\"pred_bool\"].at[i]=1\n",
    "        else:\n",
    "            df[\"pred_bool\"].at[i]=0\n",
    "    assert df[\"pred_bool\"].isnull().any()==False, \"Check the pred_bool\"\n",
    "    cf_matrix=confusion_matrix(df[\"label\"],df[\"pred_bool\"].astype(bool))\n",
    "\n",
    "    group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in cf_matrix.flatten()]\n",
    "#     group_percentages = [\"({0:.2%})\".format(value) for value in cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "#     labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "#     labels = np.asarray(labels).reshape(2,2)\n",
    "########## for visualize with normalization per case####################\n",
    "    group_percentages = []\n",
    "    for i in range(cf_matrix.shape[0]):\n",
    "        for value in cf_matrix[i]:\n",
    "            group_percentages.append(\"({0:.2%})\".format(value / cf_matrix[i].sum()))\n",
    "\n",
    "    labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "######################################################################\n",
    "    \n",
    "    # confusion matrix visualization\n",
    "    sns.heatmap(cf_matrix, annot=labels, annot_kws={'size': 16}, fmt='', cmap=color1)\n",
    "    \n",
    "    ############### save the figure 1 ###############\n",
    "    file_name1=file_output_path+file_id+'_confusion_matrix.pdf'\n",
    "    plt.savefig(file_name1, format='pdf', bbox_inches='tight')\n",
    "    #################################################\n",
    "    print(classification_report(df[\"label\"], df[\"pred_bool\"].astype(bool)))\n",
    "    \n",
    "    high_prob, low_prob=[],[]\n",
    "    label_1, label_0=[],[]\n",
    "    high_1, high_0=[],[]\n",
    "    low_1, low_0=[],[]\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        # high_prob is defined as larger than 0.5       \n",
    "        if df[\"pred\"].iloc[i]>=0.5:\n",
    "            high_prob.append(df[\"pred\"].iloc[i])\n",
    "            label_1.append(df[\"label\"].iloc[i])\n",
    "            if df[\"label\"].iloc[i]==1:  # predition is higher than 0.5(=true), and label is 1 (=true): true positive\n",
    "                high_1.append(df[\"pred\"].iloc[i])\n",
    "            else:\n",
    "                high_0.append(df[\"pred\"].iloc[i])    \n",
    "        else:\n",
    "            low_prob.append(df[\"pred\"].iloc[i])\n",
    "            label_0.append(df[\"label\"].iloc[i])\n",
    "            if df[\"label\"].iloc[i]==0: # predition is lower than 0.5(=false), and label is 0 (=false): true negative\n",
    "                low_0.append(df[\"pred\"].iloc[i])\n",
    "            else:\n",
    "                low_1.append(df[\"pred\"].iloc[i])\n",
    "\n",
    "#     print(\"false positive: {} |  false negative: {}\".format(false_positive,false_negative))\n",
    "    high_pred=pd.DataFrame({'label': label_1, 'pred': high_prob})\n",
    "    low_pred=pd.DataFrame({'label': label_0, 'pred': low_prob})\n",
    "\n",
    "    fig=plt.figure(figsize=(8,8))\n",
    "    plt.subplots_adjust(wspace=0.5, hspace=0.5)\n",
    "    plt.subplot(2, 2, 1)\n",
    "    sns.violinplot(data=high_prob, color=color2_lst[0])\n",
    "    plt.title('High Probability', fontsize=13)\n",
    "    plt.xticks([])\n",
    "    plt.xlabel(\"predition >= 0.5\", fontsize=13)\n",
    "    plt.ylabel(\"Prediction\", fontsize=13)\n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "    sns.violinplot(data=low_prob, color=color2_lst[1])\n",
    "    plt.title('Low Probability', fontsize=13)\n",
    "    plt.xticks([])\n",
    "    plt.xlabel(\"predition < 0.5\", fontsize=13)\n",
    "    plt.ylabel(\"Prediction\", fontsize=13)\n",
    "    \n",
    "    plt.subplot(2, 2, 3)\n",
    "    sns.violinplot(data=high_1, color=color2_lst[2])\n",
    "    plt.title('True positive', fontsize=13)\n",
    "    plt.xticks([])\n",
    "    plt.xlabel(\"For label 1\", fontsize=13)\n",
    "    plt.ylabel(\"Prediction\", fontsize=13)\n",
    "    \n",
    "    plt.subplot(2, 2, 4)\n",
    "    sns.violinplot(data=low_0, color=color2_lst[3])\n",
    "    plt.title('True negative', fontsize=13)\n",
    "    plt.xticks([])\n",
    "    plt.xlabel(\"For label 0\", fontsize=13)\n",
    "    plt.ylabel(\"Prediction\", fontsize=13)\n",
    "    \n",
    "    ############### save the figure 2 ###############\n",
    "    file_name2=file_output_path+file_id+'_violinplot.pdf'\n",
    "    plt.savefig(file_name2, format='pdf', bbox_inches='tight')\n",
    "    #################################################\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return high_pred,low_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d8b80d",
   "metadata": {},
   "source": [
    "#### Function `dev_conv`\n",
    "\n",
    "* Auxiliary function for creating dataframe with original sequence from `dev.tsv`\n",
    "* Input: file path for `dev.tsv`\n",
    "* Output: dataframe that accommodates the original sequence, before the kmerization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cefe40af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dev_conv(dev_file_path):\n",
    "    dev_df=pd.read_csv(dev_file_path,sep=\"\\t\")\n",
    "    dev_df.fillna(\" \", inplace=True) # change the nan into empty string\n",
    "    assert dev_df[\"sequence\"].isnull().sum()==0, \"check the dev file for nan values\"\n",
    "    \n",
    "    def kmer2seq_or_space(seq):\n",
    "        if seq == \" \":\n",
    "            return \" \"\n",
    "        else:\n",
    "            return kmer2seq(seq)\n",
    "    \n",
    "    dev_df[\"ori_seq\"] = dev_df[\"sequence\"].apply(kmer2seq_or_space)\n",
    "\n",
    "    return dev_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23669ec",
   "metadata": {},
   "source": [
    "## 5-2. Motif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a59335a",
   "metadata": {},
   "source": [
    "#### Function `motif_df_initProcessing`\n",
    "\n",
    "* Usage: Initial processing for motif dataframe, created by `motif_utils.py`. Adding the columns like '\n",
    "* Input: motif dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c088599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def motif_df_initProcessing(motif_df=\"../database/motif/compNg_condw24min5ins3_df.csv\"):\n",
    "    fname=motif_df\n",
    "    hparam=r'cond(\\d+)?|w(\\d+)|min(\\d+)|ins(\\d+)'\n",
    "    matches=re.findall(hparam,fname)\n",
    "    numbers=[num for match in matches for num in match if num]\n",
    "    if not matches[0][0]: # if no number after cond (which is actually cond1 AND cond2)\n",
    "        cond='_'  # replace it with underscore\n",
    "        win=numbers[0]\n",
    "        min_len=numbers[1]\n",
    "        min_ins=numbers[2]\n",
    "    else:   \n",
    "        cond=numbers[0]\n",
    "        win=numbers[1]\n",
    "        min_len=numbers[2]\n",
    "        min_ins=numbers[3]\n",
    "    \n",
    "    print(\"condition: {}, windows: {}, min_length: {}, min_instance: {}\".format(cond,win,min_len,min_ins))\n",
    "    \n",
    "    # add columns \"pro_x\" and \"length\" to the dataframe\n",
    "    df=pd.read_csv(motif_df, engine='python')\n",
    "    df_sorted=df.sort_values(by=\"p\")   # sort by p-value, ascending order\n",
    "    df_sorted[\"pro_x\"]=df_sorted[\"x\"]/df_sorted[\"n\"] # add columns for proportional x over n\n",
    "    df_sorted[\"length\"]=[len(motif) for motif in df_sorted['motif'].tolist()] # and for length\n",
    "    \n",
    "    max_motif_len=max(df_sorted[\"length\"])\n",
    "    min_motif_len=min(df_sorted[\"length\"])\n",
    "    print(\"Total found motif number (p-val<0.05): {}\".format(len(df_sorted)))\n",
    "    print(\"max motif length: {}, min motif length: {}\".format(max_motif_len,min_motif_len))\n",
    "    \n",
    "    # list of colored motif\n",
    "    motif_lst=df_sorted[\"motif\"].tolist()\n",
    "    colored_motif=[colored_css_str_as_is(motif) for motif in motif_lst]\n",
    "    \n",
    "    return df_sorted, colored_motif   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01da361",
   "metadata": {},
   "source": [
    "### 5-2-1. Motif visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddda716",
   "metadata": {},
   "source": [
    "#### Function `create_motif_wordcloud`\n",
    "\n",
    "* Usage: create a word cloud using `wordcloud` package for representing the frequency of each motif\n",
    "* Input: path of the motif (where the file name is like `motif_AAAAA_3_txt`\n",
    "* Output: word cloud of the motif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1817794f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_motif_wordcloud(path, color_map=\"viridis\"):\n",
    "    target=[word for word in path.split(\"/\")[-2:] if word !=\"\"][0]\n",
    "    print(\"target\", target)\n",
    "    file_lst=[os.path.join(path,file) for file in os.listdir(path) if \".txt\" in file]\n",
    "    motifs={}\n",
    "    for file_name in file_lst:\n",
    "        motif, num_txt=file_name.split(\"/\")[-1].split(\"_\")[1:3]\n",
    "        freq=num_txt.split(\".\")[0]\n",
    "        motifs[motif]=int(freq)\n",
    "    print(\"motifs = \", motifs)\n",
    "    wc=WordCloud(width=800, height=400, background_color=\"white\", colormap=color_map)\n",
    "    wordcloud=wc.generate_from_frequencies(motifs)\n",
    "    plt.figure(figsize=(6,2), facecolor=None)\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout(pad=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac24ad7",
   "metadata": {},
   "source": [
    "#### Function `motif_vis`\n",
    "\n",
    "* Usage: create and save a motif on the attention matrix with colored text (for motif only)\n",
    "* Input: file_name (e.g. \"compNg\") and the path for dev.tsv and prediction attention matrix, motif, an instance include motif \n",
    "* Output: pdf file saved at \"../database/figs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d52a0267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def motif_vis(file_name, dev_path, atten_path, motif_str, motif_inst):\n",
    "    \"\"\"\n",
    "    input examples) \n",
    "     (1) dev_path = \"../database/fine_tune/CompG_and_intergenic/4mer/dev.tsv\"\n",
    "     (2) atten_path = \"../database/ft_result/pred/4_compNg/atten.npy\"\n",
    "    output: attention matrix segment which shows the motif on it\n",
    "    \"\"\"\n",
    "    dev_df=dev_conv(dev_path)\n",
    "    atten_mat=np.load(atten_path)\n",
    "    for i, seq in enumerate(dev_df[\"ori_seq\"].to_list()):\n",
    "        if motif_inst in seq and dev_df[\"label\"].iloc[i]==1:\n",
    "            if len(seq)>81:\n",
    "                seq=seq[:81]  # cut for visualization purpose\n",
    "            print(motif_str, i, len(seq), seq, \"\\n\")\n",
    "            \n",
    "            letters=seq\n",
    "            \n",
    "            figure=plt.figure(figsize=(35,2))\n",
    "            ax =sns.heatmap(data=atten_mat[i:i+1], cmap=\"viridis\")\n",
    "            sequence = motif_str\n",
    "            sequence_indices = [i for i in range(len(letters)) if letters.startswith(sequence, i)]\n",
    "            for j, letter in enumerate(letters):\n",
    "                if j in sequence_indices or j-1 in sequence_indices or j-2 in sequence_indices or j-3 in sequence_indices or j-4 in sequence_indices:\n",
    "                    ax.text(j + 0.5, -0.2, letter, ha='center', va='center', color=state_col_dict[letter], weight='bold', fontsize=30)\n",
    "                else:\n",
    "                    ax.text(j + 0.5, -0.2, letter, ha='center', va='center',fontsize=16)\n",
    "           \n",
    "            plt.tight_layout()\n",
    "            output_path=\"../database/figs/motif_vis_\"+file_name+\"_\"+motif_str+\"_in_\"+motif_inst+\".pdf\"\n",
    "            plt.savefig(output_path, format='pdf')\n",
    "            \n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78386492",
   "metadata": {},
   "source": [
    "### 5-2-1-1. Motif to Logo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce9f6c3",
   "metadata": {},
   "source": [
    "### Pipeline\n",
    "\n",
    "* Final function: `motif_logo` which creates logo only from paths (`mat_path`, `dev_path`) and motif.\n",
    "* Function list: `get_matWcss`,`get_motifWScore`,`score2logo`,`score2logo`\n",
    "* Usage \n",
    ">`score2logo(mat_path, dev_path, motif=\"GBBBG\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401e03b7",
   "metadata": {},
   "source": [
    "#### Function `get_matWcss`\n",
    "* Usage: convert the k-merized `dev.tsv` and attention matrix into original sequence and corresponding attention score vectors, divided into 1 and 0 labels\n",
    "* Input: `mat_path` is for `atten.npy` while `dev_path`is for `dev.tsv`\n",
    ">e.g.) `mat_path`=\"../database/ft_result/pred/4_gene_exp/test02_double_data/Ghexp_rpkm30_or_not/atten.npy\"\n",
    "`dev_path`=\"../database/fine_tune/gene_exp/4mer/Ghexp_rpkm30_or_not/tr_len_40k/dev.tsv\"\n",
    "* Output: Dictionary output for label 1 (`all_dict_1`) and label 0 (`all_dict_1`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d111589",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matWcss(mat_path,dev_path):\n",
    "    atten_raw=np.load(mat_path)\n",
    "    atten=pd.DataFrame(atten_raw)\n",
    "    dev_raw=dev_conv(dev_path) #dev_conv is a function in css_utility\n",
    "    dev=dev_raw[[\"ori_seq\",\"label\"]]\n",
    "    dev.reset_index(drop=True, inplace=True)  # remove the header\n",
    "    \n",
    "    dev_label_1=dev[dev[\"label\"]==1]\n",
    "    dev_label_0=dev[dev[\"label\"]==0]\n",
    "\n",
    "    atten[\"label\"] = dev[\"label\"].values\n",
    "    atten_label_1=atten[atten[\"label\"]==1]\n",
    "    dev_label_1.pop(\"label\") # remove the label column\n",
    "    atten_label_1.pop(\"label\") # remove the label column\n",
    "    atten_label_0=atten[atten[\"label\"]==0]\n",
    "    dev_label_0.pop(\"label\") # remove the label column\n",
    "    atten_label_0.pop(\"label\") # remove the label column\n",
    "    \n",
    "    assert len(dev_label_1)==len(atten_label_1)\n",
    "    assert len(dev_label_0)==len(atten_label_0)\n",
    "    \n",
    "    all_dict_1={i:(dev_label_1.loc[i], atten_label_1.loc[i]) for i in dev_label_1.index}\n",
    "    all_dict_0={i:(dev_label_0.loc[i], atten_label_0.loc[i]) for i in dev_label_0.index}\n",
    "\n",
    "    ### to use, apply following \n",
    "#     for index, (dev_entry, atten_entry) in list(atten_dict_1.items()):\n",
    "#         dev_tar=dev_entry['ori_seq']\n",
    "#         atten_tar=atten_entry.values\n",
    "    \n",
    "    return all_dict_1, all_dict_0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fb98fe",
   "metadata": {},
   "source": [
    "#### Function `draw_all_entry`\n",
    "* Usage: just to check all the entries using gradual colormap (viridis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f416b4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# JUST TO CHECK ALL THE ENTRIES IN GRADUAL COLORMAP\n",
    "def draw_all_entry(all_dict_1):\n",
    "    for index, (dev_entry, atten_entry) in list(all_dict_1.items()):\n",
    "        dev_tar = dev_entry['ori_seq']\n",
    "        atten_tar = atten_entry.values.reshape(-1, 1).T  # Reshape to 2D array for heatmap\n",
    "\n",
    "        # Get the lengths of the dev_tar and atten_tar\n",
    "        dev_length = len(dev_tar)\n",
    "        atten_length = atten_tar.shape[1]\n",
    "\n",
    "        # Only proceed if atten_length is not longer than dev_length\n",
    "        if atten_length <= dev_length:\n",
    "            plt.figure(figsize=(28, 1))  # Adjusted height to give space for text\n",
    "\n",
    "            # Add colored text for each letter in dev_tar above where the heatmap will be\n",
    "            for i, letter in enumerate(dev_tar[:atten_length]):\n",
    "                plt.text(i + 0.5, -0.2, letter, color=state_col_dict.get(letter, 'black'),\n",
    "                         ha='center', va='center', fontsize=32, family='monospace')\n",
    "\n",
    "            sns.heatmap(data=atten_tar, cmap=\"viridis\", yticklabels=False, cbar=False)\n",
    "\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fc2c24",
   "metadata": {},
   "source": [
    "#### Function `get_motifWScore`\n",
    "* Usage: Draw the designated part (motif part) only with gradual colormap (viridis)\n",
    "* Input: `all_dict_1` from the function `get_matWcss`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5229fb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### draw the designated entry only ######################\n",
    "def get_motifWScore(all_dict_1, motif=\"GBBBG\"):\n",
    "    # all_dict_1 is the dictionary (key:index, value=tuple of motif and )\n",
    "    motif_found_all=[]\n",
    "    score_found_all=[]\n",
    "    score_found_norm_all=[]\n",
    "\n",
    "    for index, (dev_entry, atten_entry) in list(all_dict_1.items()):\n",
    "        dev_tar = dev_entry['ori_seq']\n",
    "        atten = atten_entry.values.reshape(-1, 1).T  # Reshape to 2D array for heatmap\n",
    "        atten_tar = atten[0] # atten is a list of list, with one element\n",
    "\n",
    "        if motif in dev_tar:\n",
    "            start_index=dev_tar.find(motif)\n",
    "            end_index=start_index+len(motif)\n",
    "            if end_index <= len(atten_tar)+1:\n",
    "                print(\"index: \",index)\n",
    "                print(\"min-max: {} ~ {}\".format(round(min(atten_tar),3), round(max(atten_tar),3)))\n",
    "                motif_found=dev_tar[start_index:end_index]\n",
    "                score_found=atten_tar[start_index:end_index].tolist()\n",
    "                score_found_norm=[item/sum(atten_tar) for item in score_found]  # normalize\n",
    "                \n",
    "                motif_found_all.append(motif_found)\n",
    "                score_found_all.append(score_found)\n",
    "                score_found_norm_all.append(score_found_norm)\n",
    "\n",
    "                ### create the motif figures \n",
    "                fig_width=len(motif)*0.35\n",
    "                \n",
    "                ######## Data strip with colored scores\n",
    "                \n",
    "                plt.figure(figsize=(fig_width, 1))  # Adjusted height to give space for text\n",
    "                # Add colored text for each letter in dev_tar above the heatmap\n",
    "                for i, letter in enumerate(motif_found):                    \n",
    "                    plt.text(i + 0.5, -0.2, letter, color=state_col_dict.get(letter, 'black'),\n",
    "                             ha='center', va='center', fontsize=32, family='monospace')\n",
    "\n",
    "                sns.heatmap(data=[score_found], cmap=\"viridis\", yticklabels=False, cbar=False)\n",
    "                plt.show()\n",
    "    return motif_found_all, score_found_all, score_found_norm_all #list of list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d0776a",
   "metadata": {},
   "source": [
    "#### Function `score2logo`\n",
    "* Usage: Create a logo using score \n",
    "* Input: three lists of list acquired from the function `get_motifWScore`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0de7918a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score2logo(motif_found_all, score_found_all, score_found_norm_all, norm=False):\n",
    "    num_row=len(motif_found_all[0])\n",
    "    columns=[chr(i) for i in range(ord(\"A\"), ord(\"O\")+1)]\n",
    "    \n",
    "    # df for creating logo\n",
    "    df_logo_all=[]\n",
    "    df=pd.DataFrame(0.0, index=range(num_row), columns=columns)\n",
    "    for i, motif_found in enumerate(motif_found_all):\n",
    "        if norm:\n",
    "            for j, letter in enumerate(motif_found):\n",
    "                df.loc[j, letter]=round(score_found_norm_all[i][j],3)\n",
    "        elif not norm:\n",
    "            for j, letter in enumerate(motif_found):\n",
    "                df.loc[j, letter]=round(score_found_all[i][j],3)   \n",
    "        df_logo=df.copy()\n",
    "        df_logo_all.append(df_logo)\n",
    "\n",
    "        fig_width=num_row*0.5\n",
    "        logo=logomaker.Logo(df_logo,color_scheme=state_col_dict_num, figsize=(fig_width,0.8))\n",
    "        logo.style_spines(visible=False)\n",
    "        logo.style_spines(spines=[\"left\",\"bottom\"], visible=True)\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    # Calculate the average\n",
    "    total_df = pd.DataFrame()\n",
    "    for df_logo in df_logo_all:\n",
    "        total_df = total_df.add(df_logo, fill_value=0)\n",
    "    average_df = total_df / len(df_logo_all)\n",
    "    \n",
    "    extracted_values = average_df.max(axis=1).tolist()   # make the average score into a list\n",
    "    extracted_values = [round(item,3) for item in  extracted_values] \n",
    "    \n",
    "    df_logo_all.append(average_df)\n",
    "    \n",
    "    print(\"---------- Average Score Motif Logo ----------\")\n",
    "    logo2=logomaker.Logo(average_df,color_scheme=state_col_dict_num, figsize=(fig_width+1,1))\n",
    "    logo2.style_spines(visible=False)\n",
    "    logo2.style_spines(spines=[\"left\",\"bottom\"], visible=True)\n",
    "    plt.show()\n",
    "#     print(average_df)\n",
    "    logo_score = df_logo_all[-1].max(axis=1).tolist()\n",
    "    logo_score = [round(item,3) for item in  extracted_values] \n",
    "    print(\"Average logo score:\",logo_score)\n",
    "    \n",
    "    return logo_score "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f87564",
   "metadata": {},
   "source": [
    "#### Function `motif_logo`\n",
    "* Usage: final function connecting all the above functions, generating logo from the paths and motif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d773c45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def motif_logo(mat_path, dev_path, motif=\"GBBBG\"):\n",
    "    all_dict_1, all_dict_0=get_matWcss(mat_path,dev_path)\n",
    "    motif_found_all,score_found_all,score_found_norm_all=get_motifWScore(all_dict_1, motif=motif)\n",
    "    logo_score=score2logo(motif_found_all,score_found_all,score_found_norm_all)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fc91de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446900e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a7c523",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c545a36f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee139172",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cd3b73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2aa1f61a",
   "metadata": {},
   "source": [
    "### 5-2-2. Motif extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5969e8",
   "metadata": {},
   "source": [
    "1. Extracting the (1) motif sequence, (2) the attention scores, (3) mean, min, max of those attention scores from the two data frames generated by `motif_utilis.py`.\n",
    "2. Those two data frames are: \n",
    "    * The seq, N, k, n, x, p for the regions where p <0.05\n",
    "    * The seq, index (of validation samples), position, score list, for all high attention > condition\n",
    "3. The series of following functions contribute to the final pipeline function `filtered_motif_n_score`, which generates a merged data frame of the above. The most important information would be the \"**seq**\" and its corresponding \"**attention score**\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34f11478",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_numbers(s):\n",
    "    numbers = re.findall('\\d+', s)\n",
    "    numbers = [int(number) for number in numbers]\n",
    "    return numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5192e048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_array(s):\n",
    "    # Find all arrays in the string\n",
    "    arrays_str = re.findall(r'array\\(\\[.*?\\]\\)', s.replace('\\n', ''))\n",
    "\n",
    "    arrays = []\n",
    "    for arr_str in arrays_str:\n",
    "        # Remove 'array([' from the start and '])' from the end\n",
    "        s_trimmed = arr_str[7:-2]\n",
    "        # Convert string to array\n",
    "        array = np.fromstring(s_trimmed, sep=',')\n",
    "        arrays.append(array)\n",
    "    \n",
    "    return arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71a053d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_min_max(sampe_array_list):\n",
    "    if len(sampe_array_list) >1:\n",
    "        avg_val=np.mean([np.mean(item) for item in sampe_array_list])\n",
    "        min_val=min([min(item) for item in sampe_array_list])\n",
    "        max_val=max([max(item) for item in sampe_array_list])\n",
    "    else:\n",
    "        avg_val = np.mean(sampe_array_list[0])  # get the mean of the single array \n",
    "        min_val = min(sampe_array_list[0])  # get the min value of the single array\n",
    "        max_val = max(sampe_array_list[0])  # get the max value of the single array\n",
    "    return avg_val, min_val, max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3519b98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_motif_score_file(path):\n",
    "    df_raw=pd.read_csv(path, header=None)\n",
    "    df=df_raw.T\n",
    "    df=df.dropna()\n",
    "    df.columns=[\"seq\", \"index\", \"position\", \"score\"]\n",
    "    df=df[[\"index\", \"position\",\"seq\",\"score\"]]\n",
    "    df[\"index\"]=df[\"index\"].apply(extract_numbers)\n",
    "    df[\"position\"]=df[\"position\"].apply(ast.literal_eval)\n",
    "    df[\"score\"]=df[\"score\"].apply(convert_to_array)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0d21d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtered_motif_n_score(score_path,filter_path):\n",
    "    \"\"\"\n",
    "    score_path: the file for extracting motif and corresponding attention scores\n",
    "    filter_path: the file consists of \"motif\", \"N\", \"K\", \"n\", \"x\", \"p\"\n",
    "    \"\"\"\n",
    "    # motif scores are extracted for \"all high attention area\" meets the conditions\n",
    "    df=read_motif_score_file(score_path)\n",
    "    # filter is for p<0.05\n",
    "    fil_df=pd.read_csv(filter_path)\n",
    "    fil_df.rename(columns={'motif': 'seq'}, inplace=True)\n",
    "    df_merged=pd.merge(df, fil_df, on=\"seq\")\n",
    "    avg_all=[]\n",
    "    min_all=[]\n",
    "    max_all=[]\n",
    "    for lst_item in df_merged[\"score\"]:\n",
    "        avg_val, min_val, max_val=avg_min_max(lst_item)\n",
    "        avg_all.append(avg_val)\n",
    "        min_all.append(min_val)\n",
    "        max_all.append(max_val)\n",
    "    df_merged[\"score_mean\"]=avg_all\n",
    "    df_merged[\"score_min\"]=min_all\n",
    "    df_merged[\"score_max\"]=max_all\n",
    "    df_merged.rename(columns={'x': 'appeared'}, inplace=True)\n",
    "    df_merged=df_merged[[\"seq\",\"p\",\"score_mean\",\"score_max\",\"score_min\",\"score\",\"appeared\",\"index\", \"position\"]]\n",
    "    return df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a665eba",
   "metadata": {},
   "source": [
    "### 5-2-3. Motif embedding: one-hot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785d111a",
   "metadata": {},
   "source": [
    "Hmm, not sure whether one-hot encoding is useful here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e3267d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(df_merged):\n",
    "    import string\n",
    "    char_to_int = {char: index for index, char in enumerate(string.ascii_uppercase[:15])}\n",
    "    sequences=df_merged[\"seq\"].to_list()\n",
    "    # One-hot encode the sequences\n",
    "    encoded_sequences = []\n",
    "    for sequence in sequences:\n",
    "        encoded_sequence = []\n",
    "        for char in sequence:\n",
    "            one_hot = np.zeros(15)\n",
    "            one_hot[char_to_int[char]] = 1\n",
    "            encoded_sequence.append(one_hot)\n",
    "        encoded_sequences.append(np.array(encoded_sequence))\n",
    "    return encoded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c206f95f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bae0fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56288012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7eec3e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8b85ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
