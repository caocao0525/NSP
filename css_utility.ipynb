{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76c36b48",
   "metadata": {},
   "source": [
    "# Utilities\n",
    "Various functions to process the initial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "706ee542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### To convert the file into .py\n",
    "# !jupyter nbconvert --to script css_utility.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "caaf2acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from motif_utils import seq2kmer\n",
    "from motif_utils import kmer2seq\n",
    "from scipy.stats import norm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import random\n",
    "import collections\n",
    "import operator\n",
    "import itertools\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "import glob\n",
    "from wordcloud import WordCloud\n",
    "import stylecloud\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2290a7",
   "metadata": {},
   "source": [
    "## Index\n",
    "\n",
    "* **[1. Gene and Genome file preprocessing](#1.-Gene-and-Genome-file-preprocessing)**\n",
    "    * [1-1. Gene file separation by chromosome](#1-1.-Gene-file-separation-by-chromosome)\n",
    "    * [1-2. Genome statistics](#1-2.-Genome-statistics)\n",
    "* **[2. Chromatin state preprocessing](#2.-Chromatin-state-preprocessing)**\n",
    "    * [2-1. Chromatin state file info](#2-1.-Chromatin-state-file-info)\n",
    "    * [2-2. Prerequisite dictionaries](#2-2.-Prerequisite-dictionaries)\n",
    "        * [2-2-1. Function to convert RGB into decimal RGB](#2-2-1.-Function-to-convert-RGB-into-decimal-RGB)\n",
    "    * [2-3. Generate CSS .bed to dataframe](#2-3.-Generate-CSS-.bed-to-dataframe)\n",
    "        * [2-3-1. Individual dataframe analysis](#2-3-1.-Individual-dataframe-analysis)\n",
    "    * [2-4. CSS string generation from dataframe](#2-4.-CSS-string-generation-from-dataframe)\n",
    "        * [2-4-1. Real length CSS](#2-4-1.-Real-length-CSS)\n",
    "        * [2-4-2. Unit-length CSS](#2-4-2.-Unit-length-CSS)\n",
    "    * [2-5. Chromatin State Statistics](#2-5.-Chromatin-State-Statistics)\n",
    "* **[3. Cutting the chromatin state (Dataset Preparation)](#3.-Cutting-the-chromatin-state-(Dataset-Preparation))**\n",
    "    * [3-1. Quiescent state distribution](#3-1.-Quiescent-state-distribution)\n",
    "    * [3-2. Cut the telomere region on CSS and save the file](#3-2.-Cut-the-telomere-region-on-CSS-and-save-the-file) <font color=\"royalblue\">-> **pretrain data are saved**</font>\n",
    "    * [3-3. Cut the chromatin states : genic/non-genic area](#3-3.-Cut-the-chromatin-states-:-genic-or-non-genic-area)\n",
    "        * [3-3-1. Genic area](#3-3-1.-Genic-area)\n",
    "        * [3-3-2. Non-genic area (intergenic region)](#3-3-2.-Non-genic-area-(intergenic-region))\n",
    "        * [3-3-3. Genic or Non-genic raw-length CSS to unit-length CSS](#3-3-3.-Genic-or-Non-genic-raw-length-CSS-to-unit-length-CSS)\n",
    "            * [3-3-3-1. CSS for 57 Epigenomes Genic regions are saved.](#3-3-3-1.-CSS-for-57-Epigenomes-Genic-regions-are-saved.)\n",
    "        * [3-3-4. Cut the unit-length css into trainable size and kmerize it](#3-3-4.-Cut-the-unit-length-css-into-trainable-size-and-kmerize-it) <font color=\"royalblue\">-> **pretrain data are saved**</font>\n",
    "        * [3-3-5. Fine-tuning data: Dataframe version](#3-3-5.-Fine-tuning-data:-Dataframe-version)\n",
    "        * [3-3-6. Fine-tuning data: save files as .tsv](#3-3-6.-Fine-tuning-data:-save-files-as-.tsv) <font color=\"orange\"> -> **fine-tuning data are saved** </font>\n",
    "    * [3-4. Count the number of 15th states in genic and non-genic region](#3-4.-Count-the-number-of-15th-states-in-genic-and-non-genic-region)         \n",
    "    * [3-5. Complexity of CSS in genic area](#3-5.-Complexity-of-CSS-in-genic-area)\n",
    "        * [3-5-1. Create a matrix to show the statistics](#3-5-1.-Create-a-matrix-to-show-the-statistics)\n",
    "        * [3-5-2. Extract the complex and less complex css on gene](#3-5-2.-Extract-the-complex-and-less-complex-css-on-gene)\n",
    "            * [3-5-2-1. CSS for 57 Epigenomes Complex and Less Complex Genic regions are saved.](#3-5-2-1.-CSS-for-57-Epigenomes-Complex-and-Less-Complex-Genic-regions-are-saved.)\n",
    "        * [3-5-3. Cut into Kmer and save](#3-5-3.-Cut-into-Kmer-and-save) <font color=\"royalblue\">-> **pretrain data are saved**</font>\n",
    "        * [3-5-4. Show the composition for each case](#3-5-4.-Show-the-composition-for-each-case)\n",
    "        * [3-5-5. Prepare and save Fine-tuning for Complex gene CSS and others](#3-5-5.-Prepare-and-save-Fine-tuning-for-Complex-gene-CSS-and-others) <font color=\"orange\"> -> **fine-tuning data are saved**</font>\n",
    "    * [3-6. Gene expression classification](#3-6.-Gene-expression-classification)\n",
    "        * [3-6-1. Gene expression file into the list of dataframe](#3-6-1.-Gene-expression-file-into-the-list-of-dataframe)\n",
    "        * [3-6-2. Matching to CSS](#3-6-2.-Matching-to-CSS)\n",
    "            * [3-6-2-1. CSS for various gene expression cases are saved.](#3-6-2-1.-CSS-for-various-gene-expression-cases-are-saved.)\n",
    "        * [3-6-3. Cut into Kmer and save](#3-6-3.-Cut-into-Kmer-and-save)<font color=\"royalblue\">-> **pretrain data are saved**</font>\n",
    "        * [3-6-4. Fine-tuning data](#3-6-4.-Fine-tuning-data) <font color=\"orange\"> -> **fine-tuning data are saved** </font>\n",
    "* **[4. CSS Pattern analysis](#4.-CSS-Pattern-analysis)**\n",
    "* **[5. Training result analysis](#5.-Training-result-analysis)**\n",
    "    * [5-1. Evaluation](#5-1.-Evaluation)\n",
    "        * [5-1-2. Pretrain evaluation](#5-1-2.-Pretrain-evaluation)\n",
    "        * [5-1-3. Fine tuning evaluation](#5-1-3.-Fine-tuning-evaluation)\n",
    "    * [5-2. Motif](#5-2.-Motif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4421a5",
   "metadata": {},
   "source": [
    "**Frequently used functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2143a0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatLst(lst):\n",
    "    flatten_lst=[elm for sublst in lst for elm in sublst]\n",
    "    return flatten_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b765864",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_list_maker(path, files):\n",
    "    all_files=[]\n",
    "    for file in files:\n",
    "        file_path=os.path.join(path,file)\n",
    "        all_files.append(file_path)\n",
    "    return all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7297205d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def colored_css_str_as_is(sub_str):   # convert space into space\n",
    "    col_str=\"\"\n",
    "    for letter in sub_str:\n",
    "        if letter==\" \":\n",
    "            col_str+=\" \"\n",
    "        else:                \n",
    "            for state in list(state_col_255_dict.keys()):\n",
    "                if letter==state:\n",
    "                    r=state_col_255_dict[letter][0]\n",
    "                    g=state_col_255_dict[letter][1]\n",
    "                    b=state_col_255_dict[letter][2]\n",
    "                    col_letter=\"\\033[38;2;{};{};{}m{}\\033[38;2;255;255;255m\".format(r,g,b,letter)\n",
    "                    col_str+=col_letter\n",
    "    return print(\"\\033[1m\"+col_str+\"\\033[0;0m\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb94779a",
   "metadata": {},
   "source": [
    "## 1. Gene and Genome file preprocessing\n",
    "Handling the human gene location file and the reference human genome file *hg19*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd3b1bc",
   "metadata": {},
   "source": [
    "**Gene file info**\n",
    "* This file includes the information of the location of genes on the human genome.\n",
    "* Name: `RefSeq.WholeGene.bed`\n",
    "* Location: (local linux DLBOX2 ->) `../database/RefSeq/` (server ->) `euphonium:/work/Database/UCSC/hg19/` \n",
    "* Structure: \n",
    "    * tab-delimited\n",
    "    * columns: `{0:\"chromosome\",1:\"TxStart\",2:\"TxEnd\",3:\"name\",4:\"unk0\",5:'strand', 6:'cdsStart', 7:'cdsEnd',8:\"unk1\",9:\"exonCount\",10:\"unk2\",11:\"unk3\"}`\n",
    "<br>\n",
    "\n",
    "**Genome file info**\n",
    "\n",
    "* This file is the human reference genome file.\n",
    "* Name: `genome.fa`\n",
    "* Location: (local linux DLBOX2, macpro ->) `../database/hg19/` (server ->) `/work/Database/UCSC/hg19/`\n",
    "* Chromosome-wise file location: (local linux DLBOX2, macpro ->) `../database/hg19/genome_per_chr/`\n",
    "* Structure:\n",
    "    * `>` delimiter per chromosome (e.g. `>chr1`)\n",
    "    * The file is separated chromosome-wise, using following command lines\n",
    "        > (1) `sed 's/>//g' genome.fa > genome_mod.fa` : find `>` and remove it then save as `genome.fa`<br>\n",
    "        > (2) `awk '$1 ~/^chr/{close(name);name=$1;next}{print $1>name}' genome_mod.fa` : find string starting `chr` form `genome_mod.fa` and save the 1st field (=the base string) as reading the file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "456028d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the file from local\n",
    "whole_gene_file='../database/RefSeq/RefSeq.WholeGene.bed'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72ebb3c",
   "metadata": {},
   "source": [
    "### 1-1. Gene file separation by chromosome\n",
    "#### Function: `WhGene2GLChr`\n",
    "* **Description**: Generate the chromosome-wise list of dataframe of gene location\n",
    "<br>\n",
    "* **Input**: `whole_gene_file`\n",
    "* **Output**: `g_df_chr_lst` A list of chromosome-wise Dataframes, each of which contains `chromosome` (chromosome number), `TxStart`, `TxEnd`, and `name` (gene name). Note that `chrM` is removed in the process. \n",
    "\n",
    "* This fuction is used in the function `compGene2css` [jump](#compGene2css) which generates **`css_gene_lst_all`**, the list of list that contains the chromatin states for genic region per chromosome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f555c512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for preprocess the whole gene data and produce chromosome-wise gene lists\n",
    "# each element is dataframe\n",
    "\n",
    "def whGene2GLChr(whole_gene_file='../database/RefSeq/RefSeq.WholeGene.bed'):\n",
    "    print(\"Extracting the gene file ...\")\n",
    "    g_fn=whole_gene_file\n",
    "    g_df_raw=pd.read_csv(g_fn, sep='\\t', lineterminator='\\n', header=None, low_memory=False)\n",
    "    g_df_int=g_df_raw.rename(columns={0:\"chromosome\",1:\"TxStart\",2:\"TxEnd\",3:\"name\",4:\"unk0\",\n",
    "                                  5:'strand', 6:'cdsStart', 7:'cdsEnd',8:\"unk1\",9:\"exonCount\",\n",
    "                                  10:\"unk2\",11:\"unk3\"})\n",
    "    g_df=g_df_int[[\"chromosome\",\"TxStart\",\"TxEnd\",\"name\"]]\n",
    "    \n",
    "    # Remove other than regular chromosomes\n",
    "    chr_lst=['chr1','chr2','chr3','chr4','chr5','chr6','chr7','chr8','chr9','chr10',\n",
    "             'chr11','chr12','chr13','chr14','chr15','chr16','chr17','chr18','chr19',\n",
    "             'chr20','chr21','chr22','chrX','chrY']\n",
    "    g_df=g_df.loc[g_df[\"chromosome\"].isin(chr_lst)]\n",
    "    \n",
    "    # Create a list of chromosome-wise dataframe \n",
    "    g_df_chr_lst=[]\n",
    "    for num in range(len(chr_lst)):\n",
    "        chr_num=chr_lst[num]\n",
    "        g_chr_df='g_'+chr_num\n",
    "        locals()[g_chr_df]=g_df[g_df[\"chromosome\"]==chr_num]\n",
    "        g_chr_df=locals()[g_chr_df]\n",
    "        g_chr_df=g_chr_df.sort_values(\"TxStart\")\n",
    "        g_df_chr_lst.append(g_chr_df)\n",
    "    print(\"Done!\")\n",
    "    \n",
    "    return g_df_chr_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdd499f",
   "metadata": {},
   "source": [
    "### 1-2. Genome statistics\n",
    "\n",
    "* Prerequisite file: chromosome-wise separated reference genome file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a90c573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prerequisite file load\n",
    "chr_path='../database/hg19/genome_per_chr/'\n",
    "chr_list=[os.path.join(chr_path, file) for file in sorted(os.listdir(chr_path))]\n",
    "chr1=chr_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eab8960",
   "metadata": {},
   "source": [
    "#### Function `chrNdist`\n",
    "\n",
    "* **Description**: Generate the index list and dataframe ('start' and 'end' location) of 'N' base in genome file. <br> 'N' indicates that it can be *any* base (See [reference](https://iubmb.qmul.ac.uk/misc/naseq.html))\n",
    "* **Input**: Chromosome-wise separated genome\n",
    "* **Output**: Two elements (`all_n_index` (list) and  `n_dist_df`(dataframe)). <br> `all_n_index` is just a list of all the indices where 'N's are located, while `n_dist_df` accomodates 'start', 'end', and 'count' as columns.\n",
    "* **Note** that the 'N' here stands for 50 bases. (resolution=50 bases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a983d85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chrNdist(chr_file=chr1):\n",
    "    \"\"\"\n",
    "    input: divided genome by chromosome (without any index, only genome)\n",
    "    output: dataframe of [start, end] position of \"N\" in the genome sequence\n",
    "    \"\"\"\n",
    "    with open(chr_file) as infile:\n",
    "        all_n_line=\"N\"*50    # python reads text line by 50 characters\n",
    "        all_n_index=[]\n",
    "        all_n_start=[1]\n",
    "        all_n_end=[]\n",
    "\n",
    "        for i, line in enumerate(infile):\n",
    "            if all_n_line in line:\n",
    "                all_n_index.append(i)    # all_n_index is a list of N\n",
    "\n",
    "        for i, num in enumerate(all_n_index):   \n",
    "            if i==0:        \n",
    "                pre_num=num\n",
    "            elif num !=pre_num+1:\n",
    "                all_n_start.append(num)\n",
    "            pre_num=num   \n",
    "        for i, num in enumerate(all_n_index):   \n",
    "            if i==0:        \n",
    "                pre_num=num\n",
    "            elif num !=pre_num+1:\n",
    "                all_n_end.append(pre_num+1)\n",
    "            pre_num=num\n",
    "        all_n_end.append(all_n_index[-1]+1)\n",
    "\n",
    "        assert len(all_n_start)==len(all_n_end)\n",
    "        \n",
    "        n_dist_df=pd.DataFrame({\"start\":all_n_start,\"end\":all_n_end, \n",
    "                                \"count\":[e-s+1 for s,e in zip(all_n_start,all_n_end)]},\n",
    "                               columns=[\"start\",\"end\",\"count\"])\n",
    "        ######## uncomment this block if you want to draw the histogram!\n",
    "#         fig=plt.figure(figsize=(8,4))\n",
    "#         plt.hist(all_n_index, 50, facecolor='teal', alpha=0.75)\n",
    "#         plt.xlabel(\"Position\")\n",
    "#         plt.ylabel(\"number of 'N' lines\")\n",
    "#         plt.show()    \n",
    "        return all_n_index, n_dist_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec03aaf8",
   "metadata": {},
   "source": [
    "#### Function: `all_chr_Ndist `\n",
    "\n",
    "* **Description**\n",
    "    * Draw a histogram of 'N' distiribution chromosome-wise.\n",
    "    * Generate a list of chromosome-wise list of the index for 'N' location (still, resolution = 50 bases)\n",
    "* **Input**: The reference genome file path `'../database/hg19/genome_per_chr/'`\n",
    "* **Option**: Normalization (default=`True`)\n",
    "\n",
    "* **Output**\n",
    "    * A list of chromosome-wise list of 'N' location on genome.\n",
    "    * `all_chr_n_index_norm` (if normalization ON) \n",
    "    * `all_chr_n_index` (if normalization OFF)\n",
    "<!-- ![](./desc_img/all_chr_Ndist.png) -->\n",
    "\n",
    "<img src=\"./desc_img/all_chr_Ndist.png\" width=\"500\" height=\"250\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0b1b453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_chr_Ndist(ref_genome_path='../database/hg19/genome_per_chr/', normalization=True):\n",
    "    \n",
    "    \"\"\"\n",
    "    input: ref_genome_path='../database/hg19/genome_per_chr/'\n",
    "    output: all_chr_n_index_norm (normalization ON) / all_chr_n_index (normalization OFF)\n",
    "    option: normalization (all chromosome length= 0 to 1 for drawing a dist. graph)\n",
    "    \"\"\"\n",
    "    \n",
    "    path=ref_genome_path\n",
    "    chr_list=[(file, os.path.join(path, file)) for file in sorted(os.listdir(path)) if \"chrM\" not in file] # remove chrM\n",
    "    \n",
    "    fig=plt.figure(figsize=(12,6))\n",
    "    ax = plt.subplot(111)\n",
    "    \n",
    "    all_chr_n_index=[] # list of list (raw data)\n",
    "    all_chr_n_index_norm=[] # list of list (normalized data)\n",
    "    \n",
    "    for i, (chr_no, chr_path) in enumerate(chr_list):\n",
    "        all_n_index, n_dist_df=chrNdist(chr_path)\n",
    "        # save the raw data\n",
    "        all_chr_n_index.append(all_n_index)\n",
    "        \n",
    "        ########### normalization here ###########\n",
    "        all_n_index_norm=[elm/all_n_index[-1] for elm in all_n_index]\n",
    "        ##########################################\n",
    "        \n",
    "        grad_color=plt.cm.terrain(i*10)\n",
    "        ax.hist(all_n_index_norm, 50, color=grad_color, histtype=\"step\", label=chr_no)\n",
    "        all_chr_n_index_norm.append(all_n_index_norm)\n",
    "        \n",
    "    ### show only the normalized disribution\n",
    "    box = ax.get_position()\n",
    "    ax.set_position([box.x0, box.y0, box.width * 0.8, box.height]) # Shrink current axis's height by 20% on the bottom\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.xlabel(\"Normalized Position\")\n",
    "    plt.ylabel(\"number of 'N' lines\")\n",
    "    plt.grid(b=None)\n",
    "\n",
    "    plt.show()  \n",
    "    \n",
    "    if normalization:\n",
    "        return all_chr_n_index_norm \n",
    "    else:\n",
    "        return all_chr_n_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13309e5",
   "metadata": {},
   "source": [
    "# 2. Chromatin state preprocessing\n",
    "**[back to index](#Index)**\n",
    "\n",
    "Chromatin state file (`.bed` file) preprocessing to further analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df78600",
   "metadata": {},
   "source": [
    "## 2-1. Chromatin state file info\n",
    "\n",
    "* This files are the chromatin state-annotated (15 different states, per 200 bps) genomes of 127 different cells.\n",
    "* Location: (local linux DLBOX2, macpro ->) `/database/bed/unzipped`  (server ->) `euph:/work/ChIP-seq/ROADMAP/byFileType/chromhmmSegmentations/ChmmModels/coreMarks/jointModel/final/*_15_coreMarks_dense.bed`\n",
    "* Structure: tab-delimited, 4 columns (chromosome numner, start, end, and state number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce6b1d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pickle for a cell-wise dataframe\n",
    "def total_df2pickle(total_df_list):\n",
    "    for num, df_cell in enumerate(tqdm.notebook.tqdm(total_df_list)):\n",
    "        path=\"../database/cell_pickle/\"\n",
    "        if num+1 < 10:\n",
    "            file_name=path+\"df_cell\"+\"00\"+str(num+1)+\".pkl\"\n",
    "            df_cell_pickled=df_cell.to_pickle(file_name)\n",
    "        elif num+1 < 100:\n",
    "            file_name=path+\"df_cell\"+\"0\"+str(num+1)+\".pkl\"\n",
    "            df_cell_pickled=df_cell.to_pickle(file_name)\n",
    "        else:\n",
    "            file_name=path+\"df_cell\"+str(num+1)+\".pkl\"\n",
    "            df_cell_pickled=df_cell.to_pickle(file_name)\n",
    "\n",
    "path='../database/bed/unzipped/'\n",
    "bed_files=os.listdir(path)\n",
    "\n",
    "pickle_path='../database/cell_pickle'\n",
    "pickle_files=os.listdir(pickle_path)\n",
    "            \n",
    "all_files=file_list_maker(path, bed_files)\n",
    "all_cell_pickles=file_list_maker(pickle_path, pickle_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95d9bfbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../database/bed/unzipped/E119_15_coreMarks_stateno.bed'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e85da4e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../database/cell_pickle/df_cell022.pkl'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cell_pickles[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6330ba71",
   "metadata": {},
   "source": [
    "## 2-2. Prerequisite dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ed5aad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict={1:\"A\", 2:\"B\", 3:\"C\", 4:\"D\", 5:\"E\",6:\"F\",7:\"G\",8:\"H\" ,\n",
    "                9:\"I\" ,10:\"J\",11:\"K\", 12:\"L\", 13:\"M\", 14:\"N\", 15:\"O\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbe7fa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "css_name=['TssA','TssAFlnk','TxFlnk','Tx','TxWk','EnhG','Enh','ZNF/Rpts',\n",
    "          'Het','TssBiv','BivFlnk','EnhBiv','ReprPC','ReprPcWk','Quies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6196a9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "css_dict=dict(zip(list(state_dict.values()), css_name))  # css_dict={\"A\":\"TssA\", \"B\":\"TssAFlnk\", ... }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a03cc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# color dict update using the info from https://egg2.wustl.edu/roadmap/web_portal/chr_state_learning.html\n",
    "# 18th May 2022\n",
    "css_color_dict={'TssA':(255,0,0), # Red\n",
    "                'TssAFlnk': (255,69,0), # OrangeRed\n",
    "                'TxFlnk': (50,205,50), # LimeGreen\n",
    "                'Tx': (0,128,0), # Green\n",
    "                'TxWk': (0,100,0), # DarkGreen\n",
    "                'EnhG': (194,225,5), # GreenYellow \n",
    "                'Enh': (255,255,0),# Yellow\n",
    "                'ZNF/Rpts': (102,205,170), # Medium Aquamarine\n",
    "                'Het': (138,145,208), # PaleTurquoise\n",
    "                'TssBiv': (205,92,92), # IndianRed\n",
    "                'BivFlnk': (233,150,122), # DarkSalmon\n",
    "                'EnhBiv': (189,183,107), # DarkKhaki\n",
    "                'ReprPC': (128,128,128), # Silver\n",
    "                'ReprPCWk': (192,192,192), # Gainsboro\n",
    "                'Quies': (240, 240, 240)}  # White -> bright gray "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c13341b",
   "metadata": {},
   "source": [
    "### 2-2-1. Function to convert RGB into decimal RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfa51178",
   "metadata": {},
   "outputs": [],
   "source": [
    "def colors2color_dec(css_color_dict):\n",
    "    colors=list(css_color_dict.values())\n",
    "    color_dec_list=[]\n",
    "    for color in colors:\n",
    "        color_dec=tuple(rgb_elm/255 for rgb_elm in color)\n",
    "        color_dec_list.append(color_dec)        \n",
    "    return color_dec_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429deff0",
   "metadata": {},
   "source": [
    "**scale 0 to 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e4be49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_col_dict=dict(zip(list(state_dict.values()),colors2color_dec(css_color_dict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e336c717",
   "metadata": {},
   "source": [
    "**scale 0 to 255**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0819c597",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_col_255_dict=dict(zip(list(state_dict.values()),list(css_color_dict.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951c6bfb",
   "metadata": {},
   "source": [
    "**hexacode**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50252bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "hexa_state_col_dict={letter: \"#{:02x}{:02x}{:02x}\".format(*rgb) for letter,rgb in state_col_255_dict.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c45f0c",
   "metadata": {},
   "source": [
    "**name instead of alphabets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13cfe7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "css_name_col_dict=dict(zip(css_name,state_col_dict.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ef3909",
   "metadata": {},
   "source": [
    "## 2-3. Generate CSS .bed to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f92a5e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe from bed file\n",
    "# bed file here means: EXXX_15_coreMarks_stateno.bed\n",
    "\n",
    "def bed2df_as_is(filename):    \n",
    "    \n",
    "    \"\"\"Create dataframe from the .bed file, as is.\n",
    "    Dataframe contains following columns:\n",
    "    chromosome |  start |  end  | state \"\"\"\n",
    "    \n",
    "    df_raw=pd.read_csv(filename, sep='\\t', lineterminator='\\n', header=None, low_memory=False)\n",
    "    df=df_raw.rename(columns={0:\"chromosome\",1:\"start\",2:\"end\",3:\"state\"})\n",
    "    df=df[:-1]\n",
    "    df[\"start\"]=pd.to_numeric(df[\"start\"])\n",
    "    df[\"end\"]=pd.to_numeric(df[\"end\"])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa9c3da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bed2df_expanded(filename):\n",
    "    \n",
    "    \"\"\"Create an expanded dataframe from the .bed file.\n",
    "    Dataframe contains following columns:\n",
    "    chromosome |  start |  end  | state | length | unit | state_seq | state_seq_full\"\"\"\n",
    "   \n",
    "    df_raw=pd.read_csv(filename, sep='\\t', lineterminator='\\n', header=None, low_memory=False)\n",
    "    df=df_raw.rename(columns={0:\"chromosome\",1:\"start\",2:\"end\",3:\"state\"})\n",
    "    df=df[:-1]\n",
    "    df[\"start\"]=pd.to_numeric(df[\"start\"])\n",
    "    df[\"end\"]=pd.to_numeric(df[\"end\"])\n",
    "    df[\"state\"]=pd.to_numeric(df[\"state\"])\n",
    "    df[\"length\"]=df[\"end\"]-df[\"start\"]\n",
    "    df[\"unit\"]=(df[\"length\"]/200).astype(int)  # chromatin state is annotated every 200 bp (18th May 2022)\n",
    "               \n",
    "    df[\"state_seq\"]=df[\"state\"].map(state_dict)\n",
    "    df[\"state_seq_full\"]=df[\"unit\"]*df[\"state_seq\"]\n",
    "    \n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf755bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_df_maker(all_files):\n",
    "    \n",
    "    \"\"\"Create a list of dataframe from a list of bed files.\n",
    "    This function utilizes the function named 'bed2df_expanded.'\"\"\"\n",
    "    \n",
    "    total_df=[]\n",
    "    for filename in all_files:\n",
    "        df=bed2df_expanded(filename)\n",
    "        total_df.append(df)\n",
    "    return total_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c5da4e",
   "metadata": {},
   "source": [
    "### 2-3-1. Individual dataframe analysis\n",
    "\n",
    "* Functions for analyzing an individual dataframe\n",
    "* CSS here refers Chromatin state sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b1b4d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numchr(df):\n",
    "    assert \"chromosome\" in df.columns, \"Check your df has the column named 'chromosome'\"\n",
    "    return df[\"chromosome\"].nunique()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9266675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a large piece of string of the whole state_seq_full \n",
    "# CSS: chromatin-state sequence\n",
    "\n",
    "def df2css_allchr(df):\n",
    "    \n",
    "    \"\"\"Create a large piece of string of the whole state_seq_full \n",
    "    This function generates a string from the entire chromosomes\"\"\"\n",
    "    \n",
    "    state_seq_full_list=df[\"state_seq_full\"].tolist()\n",
    "    state_seq_full_to_str=''.join([elm for elm in state_seq_full_list ])\n",
    "    return state_seq_full_to_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1ee94a",
   "metadata": {},
   "source": [
    "#### Create CSS chromosome-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d05d43a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, learn where one chromosome ends in the df\n",
    "# this is just a prerequisite function for df2css_chr\n",
    "\n",
    "def df2chr_index(df):\n",
    "    \n",
    "    \"\"\"Create a list of smaller piece of string of the state_seq_full per chromosome\n",
    "    This function generates a list of chromatin state sequence strings chromosome-wise\"\"\"\n",
    "    \n",
    "    total_row=len(df)\n",
    "    chr_len=[]\n",
    "    chr_check=[]\n",
    "    chr_index=[]\n",
    "\n",
    "    for i in range(total_row):\n",
    "        if (df[\"start\"].iloc[i]==0) & (i >0):\n",
    "            chr_len.append(df[\"end\"].iloc[i-1]) # chr_len stores the end position of each chromosome\n",
    "            chr_check.append(df[\"start\"].iloc[i]) # for assertion : later check chr_check are all zero\n",
    "            chr_index.append(i-1) # the index (row number)\n",
    "\n",
    "    end_len=df[\"end\"].iloc[-1] # add the final end position\n",
    "    end_index=total_row-1 # add the final end index (row number)\n",
    " \n",
    "    chr_len.append(end_len)\n",
    "    chr_index.append(end_index)\n",
    "\n",
    "    assert len(chr_len)==df[\"chromosome\"].nunique() #assert the length of the list corresponds to no. of chromosome\n",
    "    assert len(chr_index)==df[\"chromosome\"].nunique()\n",
    "    \n",
    "    return chr_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c84dab",
   "metadata": {},
   "source": [
    "#### Create df cut by each chromosome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "86e3b8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df2chr_df(df):\n",
    "   \n",
    "    \"\"\"Create a list of dataframes, each of which containing \n",
    "    the the whole expanded type of dataframe per chromosome\"\"\"\n",
    "    \n",
    "    start=0\n",
    "    df_chr_list=[]\n",
    "    chr_index=df2chr_index(df)\n",
    "    \n",
    "    for index in chr_index:\n",
    "        df_chr=df[start:index+1] # note that python [i:j] means from i to j-1\n",
    "        chr_name=df[\"chromosome\"].iloc[start] # string, such as chr1, chr2, ...\n",
    "        df_name='df_'+chr_name  # the chromosome-wise data stored like df_chr1, df_chr2, ...\n",
    "        locals()[df_name]=df_chr # make a string into a variable name\n",
    "        df_chr_list.append(df_chr)\n",
    "        start=index+1\n",
    "    \n",
    "    return df_chr_list   # elm is the df of each chromosome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebc9494",
   "metadata": {},
   "source": [
    "#### Create CSS chromosome-wise, string only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a4e82dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of dataframes, each of which contains the name of chromosome and chromosome-wise string of state_seq_full\n",
    "# This is prerequisite function for df2css_chr_string\n",
    "\n",
    "def df2css_chr(df):\n",
    "   \n",
    "    \"\"\"Create a list of dataframes, each of which containing \n",
    "    the chromosome name and the state_seq_full per chromosome (2 columns)\"\"\"\n",
    "    \n",
    "    start=0\n",
    "    df2col_chr_list=[]\n",
    "    chr_index=df2chr_index(df)\n",
    "    \n",
    "    for index in chr_index:\n",
    "        df_chr=df[[\"chromosome\",\"state_seq_full\"]][start:index+1] # note that python [i:j] means from i to j-1\n",
    "        chr_name=df[\"chromosome\"].iloc[start] # string, such as chr1, chr2, ...\n",
    "        df2col_name='df2col_'+chr_name  # the chromosome-wise data stored like df2col_chr1, df2col_chr2, ...\n",
    "        locals()[df2col_name]=df_chr # make a string into a variable name\n",
    "        df2col_chr_list.append(df_chr)\n",
    "        start=index+1\n",
    "    \n",
    "    return df2col_chr_list    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b631c09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df2css_chr_str(df):\n",
    "    \n",
    "    \"\"\"Create a list of strings which is the state_seq_full, all-connected per chromosome\"\"\"\n",
    "    \n",
    "    chr_index=df2chr_index(df)  \n",
    "    chr_index_num=len(chr_index) \n",
    "\n",
    "    df2col_chr_list=df2css_chr(df)  # contains a list of df: chromosome name, state_seq_full (2-column datafame)\n",
    "    chr_css_list=[]\n",
    "\n",
    "    for num in range(chr_index_num): \n",
    "        css_full_list=df2col_chr_list[num][\"state_seq_full\"].tolist()  # extract the state_seq_full only and make it a list\n",
    "        css_full_to_str=''.join([elm for elm in css_full_list]) # make it a long string of all-connected state_seq_full (chromosome-wise)\n",
    "        chr_css_list.append(css_full_to_str)\n",
    "    return chr_css_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926d5326",
   "metadata": {},
   "source": [
    "## 2-4. CSS string generation from dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9baebf5",
   "metadata": {},
   "source": [
    "### 2-4-1. Real length CSS\n",
    "\n",
    "#### Function: `df2longcss`\n",
    "* make a long string of the css (not using unit, but the **real** length)\n",
    "* ChrM is removed\n",
    "* chromosome-wise list\n",
    "* real length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "34358ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a long string of the css (not using unit, but the real length)\n",
    "\n",
    "def df2longcss(df):\n",
    "    df_lst_chr=df2chr_df(df)\n",
    "    # remove the microchondria DNA from df_lst_chr\n",
    "    if df_lst_chr[-3][\"chromosome\"].iloc[0]==\"chrM\":\n",
    "        del df_lst_chr[-3]\n",
    "        assert df_lst_chr[-3][\"chromosome\"].iloc[0]==\"chr22\"\n",
    "    else:   \n",
    "        assert df_lst_chr[-3][\"chromosome\"].iloc[0]==\"chr22\"\n",
    "    \n",
    "    all_css=[]\n",
    "    for i in range(len(df_lst_chr)):\n",
    "        df_chr=df_lst_chr[i]\n",
    "        css_chr=''\n",
    "        for j in range(len(df_chr)):\n",
    "            css_chr+=df_chr[\"length\"].iloc[j]*df_chr[\"state_seq\"].iloc[j]\n",
    "        all_css.append(css_chr)  \n",
    "    return all_css"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37700d4d",
   "metadata": {},
   "source": [
    "### 2-4-2. Unit-length CSS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6864ea",
   "metadata": {},
   "source": [
    "#### Function: `df2unitcss`\n",
    "\n",
    "* make a unit-length string of the css (not the real length, but **200-bp resolution unit**)\n",
    "* ChrM is removed\n",
    "* chromosome-wise list\n",
    "* unit length (chromatin is annotated per 200 bp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d57de8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a long string of the css (unit length, not the real length)\n",
    "\n",
    "def df2unitcss(df):\n",
    "    df_lst_chr=df2chr_df(df)\n",
    "    # remove the microchondria DNA from df_lst_chr\n",
    "    if df_lst_chr[-3][\"chromosome\"].iloc[0]==\"chrM\":\n",
    "        del df_lst_chr[-3]\n",
    "        assert df_lst_chr[-3][\"chromosome\"].iloc[0]==\"chr22\"\n",
    "    else:   \n",
    "        assert df_lst_chr[-3][\"chromosome\"].iloc[0]==\"chr22\"\n",
    "    \n",
    "    all_unit_css=[]\n",
    "    for i in range(len(df_lst_chr)):\n",
    "        df_chr=df_lst_chr[i]\n",
    "        css_chr=''\n",
    "        for j in range(len(df_chr)):\n",
    "            css_chr+=df_chr[\"unit\"].iloc[j]*df_chr[\"state_seq\"].iloc[j]\n",
    "        all_unit_css.append(css_chr)  \n",
    "    return all_unit_css"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ca72a1",
   "metadata": {},
   "source": [
    "## 2-5. Chromatin State Statistics\n",
    "\n",
    "\n",
    "#### Function: `prop_data2df`\n",
    "\n",
    "* With 15th state (including 15ths state)\n",
    "* `'../database/conserv_overlap/'` contains the emission of the state (occupation of the state on the genome) \n",
    "* State distribution on genome across all the cell types\n",
    "* Mostly for visualization\n",
    "    <img src=\"./desc_img/prop_data2df.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0a3e3a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prop_data2df(path='../database/conserv_overlap/'):\n",
    "    file_list=[os.path.join(path, file) for file in os.listdir(path)]\n",
    "    \n",
    "    temp_df=pd.read_csv(file_list[0],sep='\\t', lineterminator='\\n')\n",
    "    init_col=pd.DataFrame(temp_df[\"state (Emission order)\"])\n",
    "    init_col=init_col.rename(columns={\"state (Emission order)\":\"state\"})\n",
    "    for file in file_list:\n",
    "        file_name=file.split('/')[3]\n",
    "        sample_name=file_name.split('_')[0]\n",
    "\n",
    "        prop_data=pd.read_csv(file, sep='\\t', lineterminator='\\n')\n",
    "        prop=prop_data[\"Genome %\"]\n",
    "        temp_df=pd.concat([init_col,prop], axis=1)\n",
    "        temp_df=temp_df.rename(columns={\"Genome %\":str(sample_name)})\n",
    "        init_col=temp_dfx\n",
    "    \n",
    "    # show the result df (first col=state, other col=samples)\n",
    "    temp_df.drop(temp_df.tail(1).index, inplace=True) # remove the last row (100%)\n",
    "    \n",
    "    # transposed and trimmed df (col+1=state no. row=samples)\n",
    "    trans_df=temp_df.T\n",
    "    trans_df.drop(trans_df.head(1).index, inplace=True)\n",
    "    trans_df.columns=temp_df[\"state\"].to_list()\n",
    "    \n",
    "    state_list=temp_df[\"state\"].to_list()\n",
    "    \n",
    "    ################### create a plot for genome proportion across cell types\n",
    "    fig=plt.figure(figsize=(9,5))\n",
    "    ax=fig.add_subplot(111)\n",
    "    for i in range(len(state_list)):\n",
    "        state=list(css_color_dict.keys())[i]\n",
    "        state_as_colname=list(trans_df.columns)[i]\n",
    "\n",
    "        color=tuple([elm/255 for elm in css_color_dict[state]])\n",
    "\n",
    "        bp=ax.boxplot(trans_df.iloc[:,i],widths=0.65,positions = [i+1], notch=True,patch_artist=True, \n",
    "                     boxprops=dict(facecolor=color, color=\"gray\"),whiskerprops=dict(color=\"gray\", linewidth=2),\n",
    "                     medianprops=dict(color=color, linewidth=2),\n",
    "                     capprops=dict(color=\"gray\", linewidth=2),\n",
    "                     flierprops=dict(markeredgecolor=color, markeredgewidth=1.5))\n",
    "    plt.xticks(list(range(1,16)),list(trans_df.columns))\n",
    "    plt.xlabel(\"Chromatin state\")\n",
    "    plt.ylabel(\"Genome [%]\\n across Different Cell Types\")\n",
    "    fig.autofmt_xdate(rotation=45)\n",
    "    plt.show()\n",
    "    ###################\n",
    "    \n",
    "    return temp_df, trans_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "de44156b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_df, trans_df=prop_data2df(path='../database/conserv_overlap/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20ab882",
   "metadata": {},
   "source": [
    "# 3. Cutting the chromatin state (Dataset Preparation)\n",
    "**[back to index](#Index)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe0bf89",
   "metadata": {},
   "source": [
    "## 3-1. Quiescent state distribution\n",
    "How Quiescent states are distributed on the whole genome?\n",
    "\n",
    "#### Function: `UnitCSS_Q_Dist`\n",
    "\n",
    "* Input: df, chromosome number\n",
    "* Output: `q_index` index of genome (not normalized) where Quiescent states are found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1c60ce67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index list for O state in unit-length css sequence:\n",
    "def UnitCSS_Q_Dist(df, chr_no=1):\n",
    "    all_unit_css=df2unitcss(df)\n",
    "    chr_unit_css=all_unit_css[chr_no]\n",
    "    q_index=[]\n",
    "    for i,state in enumerate(chr_unit_css):\n",
    "        if state==\"O\":\n",
    "            q_index.append(i)\n",
    "    ######## uncomment this block if you want to draw the histogram!\n",
    "#     fig=plt.figure(figsize=(8,4))\n",
    "#     plt.hist(q_index, 30, histtype=\"step\", color='orange')\n",
    "# #     sns.histplot(q_index, kde=False, color='orange', bins=30, element=\"step\", fill=False)\n",
    "\n",
    "#     plt.xlabel(\"Position\")\n",
    "#     plt.ylabel(\"number of 'O' state\")\n",
    "#     plt.show()\n",
    "    return q_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2175e482",
   "metadata": {},
   "source": [
    "#### Function: `all_chr_UnitCSS_Q_Dist(df, normalization=True)`\n",
    "\n",
    "* Input: df, normalization (T/F, default=T)\n",
    "* Output: list of list, the element of which is a list contains the position index of the Q state in a chromosome\n",
    "    * Normalization True: `all_chr_q_index_norm`\n",
    "    * Normalization False: `all_chr_q_index`\n",
    "* Graph (distribution histogram)\n",
    "<img src=\"./desc_img/all_chr_UnitCSS_Q_Dist.png\" width=\"400\" height=\"150\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "327e6cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_chr_UnitCSS_Q_Dist(df,normalization=True):\n",
    "    \n",
    "    \"\"\"\n",
    "    input: df (the dataframe acquired by bed2df_expanded function for a chromatin state bed file)\n",
    "    output: all_chr_q_index_norm (normalization ON) / all_chr_q_index (normalization OFF)\n",
    "    option: normalization (all chromosome length= 0 to 1 for drawing a dist. graph)\n",
    "    \"\"\"\n",
    "    \n",
    "    all_unit_css=df2unitcss(df)  # a list of unit-css of df sample, chromosome wise\n",
    "       \n",
    "    fig=plt.figure(figsize=(12,6))\n",
    "    ax = plt.subplot(111)\n",
    "    all_chr_q_index=[] # list of list (raw data)\n",
    "    all_chr_q_index_norm=[] # list of list (normalized data)\n",
    "    \n",
    "    for i in range(len(all_unit_css)):\n",
    "        q_index=UnitCSS_Q_Dist(df, chr_no=i)\n",
    "        all_chr_q_index.append(q_index)\n",
    "        \n",
    "        ########### normalization here ###########\n",
    "        q_index_norm=[elm/q_index[-1] for elm in q_index]\n",
    "        ##########################################\n",
    "        all_chr_q_index_norm.append(q_index_norm)\n",
    "        if i <=21:\n",
    "            chr_name=\"chr\"+str(i+1)\n",
    "        elif i==23:\n",
    "            chr_name=\"chrX\"\n",
    "        else:\n",
    "            chr_name=\"chrY\"\n",
    "\n",
    "        grad_color=plt.cm.coolwarm(i*10)\n",
    "#         ax.hist(q_index_norm, 100, color=grad_color, ec='white', alpha=0.5, label=chr_no)\n",
    "        ax.hist(q_index_norm, 50, color=grad_color, histtype=\"step\", label=chr_name)\n",
    "\n",
    "    ### show only the normalized disribution\n",
    "    box = ax.get_position()\n",
    "    ax.set_position([box.x0, box.y0, box.width * 0.8, box.height]) # Shrink current axis's height by 20% on the bottom\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.xlabel(\"Normalized Position\")\n",
    "    plt.ylabel(\"number of 'O' state\")\n",
    "    plt.grid(b=None)\n",
    "    \n",
    "    if normalization:\n",
    "        return all_chr_q_index_norm\n",
    "    else:\n",
    "        return all_chr_q_index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57854437",
   "metadata": {},
   "source": [
    "## 3-2. Cut the telomere region on CSS and save the file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bcb39c",
   "metadata": {},
   "source": [
    "### 3-2-1. Random cut\n",
    "**Pretrain data was generated by this function, and chromosome-wise data are saved at `database/wo_telo`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13a2023",
   "metadata": {},
   "source": [
    "#### Function: `chr_cssWOtelo_ranCUT_Kmer`\n",
    "\n",
    "* Cut the list of CSS into trainable size and save after trimming the telometer region \n",
    "    >1. Cut the telomere (50 units=10000 bp)\n",
    "    >2. Select the sample `df` and chromosome number `chr_no` to take\n",
    "    >3. Determine the range of random cut of the string (e.g. `100` to `2000`)\n",
    "    >4. Determine the `k` for making kmer\n",
    "    \n",
    "* Input: df,chr_no,num1=5,num2=510, k=3, weight_rn=False, v_name=\"v1.01\"\n",
    "> weight_rn `True`: 50% cut into 510, 50% cut randomly between 5 and 510 <br>\n",
    "> weight_rn `False` : 100% cut randomly between 5 and 510\n",
    "* Output file name: `k_wo_telo_v1.01.txt`, v1 stands for version 1 (considering telomere length) \n",
    "* Usage: `chr_cssWOtelo_ranCUT_Kmer(df,1,100,200,6)`\n",
    "\n",
    "* Version control (e.g. v1.01)\n",
    "     * v1: version 1, telomere length set at 50 units.\n",
    "     * .01: not weighted random, from 5 to 510 \n",
    "\n",
    ">*Output message* <br>\n",
    ">unit-length css of chr1 cut randomly(weighted range:5-510) for 3mer was saved at '../database/wo_telo/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c41e45c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "#    Chromosome-wise save     #\n",
    "###############################\n",
    "\n",
    "# randomly cut the string \n",
    "\n",
    "def chr_cssWOtelo_ranCUT_Kmer(df,chr_no,num1=5,num2=510, k=3, weight_rn=False, v_name=\"v1.01\"):\n",
    "    \"\"\"\n",
    "    Usage: chr_cssWOtelo_ranCUT_Kmer(df,chr_no,num1,num2, weight_rn, k, v_name)\n",
    "    \n",
    "    - df: expanded version of 1 sample bed file\n",
    "    - chr_no: no. of chromosome\n",
    "    - num1: cut range start\n",
    "    - num2: cut range end\n",
    "    - weight_rn: \n",
    "      if True: random with weighted, 50% of chance to be num2, 50% random between num1 and num2\n",
    "      if False: random between num1 and num2\n",
    "    - k: kmer\n",
    "    - v_name: version name to be used as a file name \n",
    "      (Conventionally, 01 was used for weighted_rn False, 02 for True\n",
    "       v1 just stands for telomere is set to be 50 unit)\n",
    "    \n",
    "    output: randomly cut w15 css for one chromosome unit-length css\n",
    "    \"\"\"\n",
    "    all_unit_css=df2unitcss(df)\n",
    "    ch1_unit_css=all_unit_css[chr_no]\n",
    "    ch1_unit_css_wotelo=ch1_unit_css[50:-50] #cut the telomere\n",
    "\n",
    "    splitted=[]\n",
    "    prev=0\n",
    "\n",
    "    ori_lst=[elm for elm in range(num1,num2+1)]   # list of num between num1 and num2\n",
    "    sin_lst=[num2]*len(ori_lst)   # list of all num2 (length is the same of ori_lst)\n",
    "    tot_lst=ori_lst+sin_lst\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        if weight_rn:\n",
    "            n=random.choice(tot_lst)\n",
    "\n",
    "        else:\n",
    "            n=random.randint(num1,num2)\n",
    "        \n",
    "        splitted.append(ch1_unit_css_wotelo[prev:prev+n])\n",
    "        prev=prev+n\n",
    "        if prev >= len(ch1_unit_css_wotelo)-1:\n",
    "            break\n",
    "   \n",
    "    ch1_unit_css_wotelo_kmer=[seq2kmer(item, k) for item in splitted]\n",
    "    \n",
    "      \n",
    "    path='../database/wo_telo/'\n",
    "    fn_base=\"chr\"+str(chr_no)+\"_\"+str(k)+\"_wo_telo_\"+v_name   # version 1.01_pre (Oct. 2022) : telo 50 unit, rn 200-1000\n",
    "                                                              # version 1.01 (Oct. 2022) : telo 50, rn 5 - 510\n",
    "    ext=\".txt\"\n",
    "          \n",
    "    fn=path+fn_base+ext  # file name\n",
    "\n",
    "    with open(fn,\"w\") as save_file:\n",
    "        save_file.write(\"\\n\".join(ch1_unit_css_wotelo_kmer))\n",
    "          \n",
    "    return print(\"unit-length css of chr{} cut randomly(weighted range:{}-{}) for {}mer was saved at {}\".format(chr_no, num1, num2, k,fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f96033a",
   "metadata": {},
   "source": [
    "#### Function: `cell_cssWOtelo_ranCUT_Kmer`\n",
    "\n",
    "* Conduct the same work but now cell-wise, not chromosome-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfe4b0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "#    Cell-wise save     #\n",
    "###############################\n",
    "\n",
    "# randomly cut the string \n",
    "\n",
    "def cell_cssWOtelo_ranCUT_Kmer(all_file_path=all_files, cell_num=0, num1=5,num2=510, k=4, weight_rn=False, v_name=\"v1.01\"):\n",
    "    \"\"\"\n",
    "    Usage: chr_cssWOtelo_ranCUT_Kmer(df,chr_no,num1,num2, weight_rn, k, v_name)\n",
    "    \n",
    "    - all_file_path: the list of all_files (see css_utility)\n",
    "    - cell_num: the number of cell in the list of all_files\n",
    "    - num1: cut range start\n",
    "    - num2: cut range end\n",
    "    - weight_rn: \n",
    "      if True: random with weighted, 50% of chance to be num2, 50% random between num1 and num2\n",
    "      if False: random between num1 and num2\n",
    "    - k: kmer\n",
    "    \n",
    "    output: randomly cut w15 css for one chromosome unit-length css\n",
    "    \"\"\"\n",
    "    target_cell=all_file_path[cell_num]\n",
    "    cell_id=target_cell.split(\"/\")[-1].split(\"_\")[1]\n",
    "    assert type(cell_id)==str,\"Check the all_file path\"\n",
    "    \n",
    "    df=bed2df_expanded(target_cell)    \n",
    "    all_unit_css=df2unitcss(df)\n",
    "    all_chr=len(all_unit_css)\n",
    "    \n",
    "    all_chr_unit_css_wotelo_kmer=[]\n",
    "    \n",
    "    for chr_no in range(all_chr):        \n",
    "    \n",
    "        chr_unit_css=all_unit_css[chr_no]\n",
    "        chr_unit_css_wotelo=chr_unit_css[50:-50] #cut the telomere\n",
    "\n",
    "        splitted=[]\n",
    "        prev=0\n",
    "\n",
    "        ori_lst=[elm for elm in range(num1,num2+1)]   # list of num between num1 and num2\n",
    "        sin_lst=[num2]*len(ori_lst)   # list of all num2 (length is the same of ori_lst)\n",
    "        tot_lst=ori_lst+sin_lst\n",
    "\n",
    "        while True:\n",
    "\n",
    "            if weight_rn:\n",
    "                n=random.choice(tot_lst)\n",
    "\n",
    "            else:\n",
    "                n=random.randint(num1,num2)\n",
    "\n",
    "            splitted.append(chr_unit_css_wotelo[prev:prev+n])\n",
    "            prev=prev+n\n",
    "            if prev >= len(chr_unit_css_wotelo)-1:\n",
    "                break\n",
    "\n",
    "        chr_unit_css_wotelo_kmer=[seq2kmer(item, k) for item in splitted]\n",
    "        all_chr_unit_css_wotelo_kmer.append(chr_unit_css_wotelo_kmer)\n",
    "        \n",
    "    all_unit_css_wotelo_kmer=flatLst(all_chr_unit_css_wotelo_kmer)\n",
    "    \n",
    "    path='../database/wo_telo/'\n",
    "    fn_base=\"cell\"+cell_id+\"_\"+str(k)+\"_wo_telo_\"+v_name   # version 1.01_pre (Oct. 2022) : telo 50 unit, rn 200-1000\n",
    "                                                              # version 1.01 (Oct. 2022) : telo 50, rn 5 - 510\n",
    "    ext=\".txt\"\n",
    "          \n",
    "    fn=path+fn_base+ext  # file name\n",
    "\n",
    "    with open(fn,\"w\") as save_file:\n",
    "        save_file.write(\"\\n\".join(all_unit_css_wotelo_kmer))\n",
    "    \n",
    "    \n",
    "    return print(\"unit-length css of cell ID {} cut randomly(weighted range:{}-{}) for {}mer was saved at {}\".format(cell_id, num1, num2, k,fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69d81ad",
   "metadata": {},
   "source": [
    "### 3-2-1. Kmerized data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f965c7",
   "metadata": {},
   "source": [
    "#### Function: `dataLengCompo`\n",
    "* Input: data path, k (of kmer), color, bins, dna or not (default=false)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bd4010a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataLengCompo(path, k, color=\"teal\", bins=15, dna=False):\n",
    "    \"\"\"\n",
    "    Create a histogram of data length (elements before k-merization in the training dataset list)\n",
    "    \"\"\"\n",
    "    file_name=path\n",
    "    with open(file_name) as f:\n",
    "        len_lst=[]\n",
    "        for line_no, line in enumerate(f):\n",
    "            if dna:\n",
    "                line_len=int((len(line)-1)/k)+(k-1)  # -1 comes from the space only between DNA sequence kmer\n",
    "                if line_len!=0:\n",
    "                    len_lst.append(line_len)               \n",
    "            else:\n",
    "                line_len=int(len(line)/(k+1))+(k-1)  # reduced \n",
    "#                 line_len=int(len(line)/(k+1))*k # +1 comes from the space after the kmers\n",
    "                len_lst.append(line_len)\n",
    "                \n",
    "    fig=plt.figure(figsize=(6,4))\n",
    "    \n",
    "    s=sns.histplot(len_lst, kde=False, color=color, log_scale=True, bins=bins, element=\"step\", fill=False)\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.xlabel(\"Length of each element in training dataset\", fontsize=12)\n",
    "    plt.xlim([1,10000])\n",
    "    plt.show()\n",
    "    return  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd68457",
   "metadata": {},
   "source": [
    "## 3-3. Cut the chromatin states : genic or non-genic area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb0de6d",
   "metadata": {},
   "source": [
    "### 3-3-1. Genic area\n",
    "#### Function: `compGene2css`\n",
    "\n",
    "* Input: whole_gene_file, df\n",
    "* Output: `css_gene_lst_all` list of list that css for genic region per chromosome (which can be utilized very frequently after this)\n",
    "* The output is pickled as `\"../database/temp_files/css_gene_lst_all\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "499a7618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compGene2css(whole_gene_file,df):   # note that the result is also overlapped css... \n",
    "    \"\"\"\n",
    "    Input: Reference gene file, df (CSS)\n",
    "    Output: list of chromosome-wise list that contains the css at genic area only.\n",
    "    \"\"\"\n",
    "    g_lst_chr=whGene2GLChr(whole_gene_file) # list of gene table df per chromosome\n",
    "    css_lst_chr=df2longcss(df) # list of long css per chromosome\n",
    "    total_chr=len(g_lst_chr)\n",
    "    \n",
    "    css_gene_lst_all=[]\n",
    "    for i in tqdm_notebook(range(total_chr)):\n",
    "        css=css_lst_chr[i]   # long css of i-th chromosome\n",
    "        gene_df=g_lst_chr[i] # gene df of i-th chromosome\n",
    "        \n",
    "        css_gene_lst_chr=[]\n",
    "        for j in range(len(gene_df)):\n",
    "            g_start=gene_df[\"TxStart\"].iloc[j]-1  # python counts form 0\n",
    "            g_end=gene_df[\"TxEnd\"].iloc[j]+1      # python excludes the end\n",
    "            \n",
    "            css_gene=css[g_start:g_end]           # cut the gene area only\n",
    "            css_gene_lst_chr.append(css_gene)     # store in the list\n",
    "          \n",
    "        css_gene_lst_all.append(css_gene_lst_chr)  # list of list\n",
    "    \n",
    "    assert len(css_gene_lst_all)==total_chr\n",
    "    return css_gene_lst_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41196d56",
   "metadata": {},
   "source": [
    "#### Function: `countGeneCss`\n",
    "* How many css data strips are in the Non-genic (intergenic) region?\n",
    "* How long each css data strips are in the Non-genic (intergenic) region?\n",
    "* Input: `css_gene_lst_all`, the result list from `compGene2css(whole_gene_file,df)`. (Also pickled at `\"../database/temp_files/css_gene_lst_all\"`\n",
    "* Output: Two lists (`g_css_cnt_all` and `g_css_len_all`) and their distribution histogram\n",
    "\n",
    "<img src=\"./desc_img/countGeneCss.png\" width=\"600\" height=\"300\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b607cc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def countGeneCss(css_gene_lst_all):\n",
    "    g_css_cnt_all=[]\n",
    "    g_css_len_all=[]\n",
    "    tot_chr=len(css_gene_lst_all)\n",
    "    for chr_no in range(tot_chr):\n",
    "        g_chr_lst=css_gene_lst_all[chr_no]\n",
    "        g_css_cnt_all.append(len(g_chr_lst))\n",
    "        g_css_len_chr=[]\n",
    "        for i in range(len(g_chr_lst)):\n",
    "            g_css_len=len(g_chr_lst[i])\n",
    "            g_css_len_chr.append(g_css_len)  # to let it iterate for chr!\n",
    "        g_css_len_all.append(g_css_len_chr)\n",
    "    g_css_len_all=flatLst(g_css_len_all) \n",
    "    \n",
    "    g_css_len_all=list(filter(lambda elm: elm!=0, g_css_len_all))  # remove 0s\n",
    "        \n",
    "    # visualization for ng_css_cnt_all (no. of data strips per chromosome)\n",
    "    fig,(ax1, ax2)=plt.subplots(1,2,figsize=(12,4), sharey=False)\n",
    "    ax1=sns.histplot(g_css_cnt_all, bins=12, color=\"cadetblue\", element=\"step\", fill=False, ax=ax1)\n",
    "    ax1.set_xlabel(\"Count of data strip on Genic region\", fontsize=13)\n",
    "    ax1.set_ylabel(\"Count\", fontsize=13)\n",
    "    ax1.grid(b=None)\n",
    "    ax1.xaxis.grid(None)\n",
    "    ax1.yaxis.grid()\n",
    "    \n",
    "    # visualization for ng_css_cnt_all (no. of data strips per chromosome)\n",
    "    ax2=sns.histplot(g_css_len_all, bins=15, log_scale=True, color=\"crimson\", element=\"step\", fill=False, ax=ax2)\n",
    "    ax2.set_xlabel(\"Length of CSS on Genic region\", fontsize=13)\n",
    "    ax2.set_ylabel(\"Count\", fontsize=13)\n",
    "    ax2.grid(b=None)\n",
    "    plt.grid(False)\n",
    "            \n",
    "    return g_css_cnt_all,g_css_len_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69027e1",
   "metadata": {},
   "source": [
    "### 3-3-2. Non-genic area (intergenic region)\n",
    "\n",
    "* The problem in evaluating the intergenic region is that the positions of genes are frequently duplicated. Therefore, the gene table shares lots of same start and end position.\n",
    "    1. First, we need to take a look how many genes are duplicated at the start and end position.\n",
    "    2. Second, gene table has been collapsed to remove the overlaps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81495f86",
   "metadata": {},
   "source": [
    "#### Function: `count_samePos` (To take a look how many genes are overlapped)\n",
    "* Input: `whole_gene_file='../database/RefSeq/RefSeq.WholeGene.bed'`\n",
    "* Output: 2 dataframes (`df_cnt` and `df_pro`) and visualization for them in violin plot\n",
    "    * `df_cnt` : Chromosome-wise list of the count of the duplicated gene Start and End position on genome\n",
    "    * `df_pro` : Chromosome-wise list of the proportion of the duplicated gene Start and End position on genome (per gene)    \n",
    "    \n",
    "<img src=\"./desc_img/gene_dup_start_end_vis.png\" width=\"500\" height=\"200\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "82db0a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to visualize how many genes are sharing the start and end position on genome\n",
    "\n",
    "def count_samePos(whole_gene_file='../database/RefSeq/RefSeq.WholeGene.bed'):\n",
    "    g_df_chr_lst=whGene2GLChr(whole_gene_file)\n",
    "    cnt_same_start_all=[]\n",
    "    pro_same_start_all=[]\n",
    "    cnt_same_end_all=[]\n",
    "    pro_same_end_all=[]\n",
    "    tot_chr_no=len(g_df_chr_lst)\n",
    "    \n",
    "    ########### count the same start position ###########\n",
    "    def count_sameStart(g_df_chr_lst,chr_no):\n",
    "        cnt_same_start=0\n",
    "        tot_start=len(g_df_chr_lst[chr_no])\n",
    "        for i in range(len(g_df_chr_lst[chr_no])):\n",
    "            chr1=g_df_chr_lst[chr_no][\"TxStart\"]\n",
    "            if i==0:\n",
    "                continue\n",
    "            elif chr1.iloc[i]==chr1.iloc[i-1]:\n",
    "                cnt_same_start+=1  # how many same start in rows\n",
    "            else:\n",
    "                continue\n",
    "        prop_same_start=cnt_same_start/tot_start\n",
    "        return cnt_same_start, prop_same_start\n",
    "    \n",
    "    ########### count the same end position ############\n",
    "    def count_sameEnd(g_df_chr_lst,chr_no):\n",
    "        cnt_same_end=0\n",
    "        tot_end=len(g_df_chr_lst[chr_no])\n",
    "        for i in range(len(g_df_chr_lst[chr_no])):\n",
    "            chr1=g_df_chr_lst[chr_no][\"TxEnd\"]       \n",
    "            if i==0:\n",
    "                continue\n",
    "            elif chr1.iloc[i]==chr1.iloc[i-1]:\n",
    "                cnt_same_end+=1  # how many same start in rows\n",
    "            else:\n",
    "                continue\n",
    "        prop_same_end=cnt_same_end/tot_end\n",
    "        return cnt_same_end, prop_same_end\n",
    "    ####################################################\n",
    "    \n",
    "    for chr_no in tqdm_notebook(range(tot_chr_no)):\n",
    "        cnt_same_start, prop_same_start = count_sameStart(g_df_chr_lst,chr_no)\n",
    "        cnt_same_end, prop_same_end = count_sameEnd(g_df_chr_lst,chr_no)\n",
    "        \n",
    "        cnt_same_start_all.append(cnt_same_start)\n",
    "        pro_same_start_all.append(prop_same_start)\n",
    "        cnt_same_end_all.append(cnt_same_end)\n",
    "        pro_same_end_all.append(prop_same_end)\n",
    "        \n",
    "    dict_cnt={\"cnt_same_start\":cnt_same_start_all, \"cnt_same_end\":cnt_same_end_all}\n",
    "    dict_pro={\"pro_same_start\":pro_same_start_all, \"pro_same_end\":pro_same_end_all}\n",
    "    df_cnt=pd.DataFrame(dict_cnt)\n",
    "    df_pro=pd.DataFrame(dict_pro)\n",
    "    \n",
    "    ###### Visualization ######\n",
    "    fig, (ax1,ax2) = plt.subplots(1,2,figsize=(10,5), sharey=False)\n",
    "    ax1=sns.violinplot(data=df_cnt, palette=\"pastel\", linewidth=0.7, saturation=0.5, ax=ax1)\n",
    "    ax1.set_ylabel(\"Count\", fontsize=15)\n",
    "    ax2=sns.violinplot(data=df_pro, palette=\"husl\", linewidth=0.7, saturation=0.5, ax=ax2)\n",
    "    ax2.set_ylim([0.2,0.8])\n",
    "    ax2.set_ylabel(\"Proportion\", fontsize=15)\n",
    "    plt.show()\n",
    "\n",
    "    return df_cnt, df_pro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09167c5",
   "metadata": {},
   "source": [
    "#### Function: `removeOverlapDF` and `gene_removeDupl`\n",
    "\n",
    "* Main function: `gene_removeDupl`\n",
    "* `removeOverlapDF`: function used inside the main function.\n",
    "* To acquire final collapsed gene table, run `gene_removeDupl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "148fd1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeOverlapDF(test_df):    \n",
    "    new_lst=[]\n",
    "    for i in range(len(test_df)):\n",
    "        start=test_df[\"TxStart\"].iloc[i]\n",
    "        end=test_df[\"TxEnd\"].iloc[i]\n",
    "\n",
    "        exist_pair=(start,end)\n",
    "\n",
    "        if i==0:\n",
    "            new_pair=exist_pair\n",
    "            new_lst.append(new_pair)        \n",
    "        else:\n",
    "            start_pre=test_df[\"TxStart\"].iloc[i-1]\n",
    "            end_pre=test_df[\"TxEnd\"].iloc[i-1]\n",
    "\n",
    "            # first, concatenate all the shared start\n",
    "            if start==start_pre:\n",
    "                new_end=max(end, end_pre)\n",
    "                new_pair=(start, new_end)\n",
    "            # second, concatenate all the shared end\n",
    "            elif end==end_pre:\n",
    "                new_start=min(start, start_pre)\n",
    "                new_pair=(new_start, end)\n",
    "            else:    \n",
    "                new_pair=exist_pair\n",
    "\n",
    "        new_lst.append(new_pair) \n",
    "    new_lst=list(dict.fromkeys(new_lst))\n",
    "    \n",
    "    mod_lst=[[start, end] for (start, end) in new_lst] # as a list element\n",
    "\n",
    "    for j, elm in enumerate(mod_lst):\n",
    "        start, end = elm[0], elm[1]\n",
    "\n",
    "        if j==0:\n",
    "            continue\n",
    "        else:\n",
    "            start_pre=mod_lst[j-1][0]\n",
    "            end_pre=mod_lst[j-1][1]\n",
    "\n",
    "            if end_pre>=end:\n",
    "                mod_lst[j][0]=mod_lst[j-1][0]  # if end_pre is larger than end, replace start as start_pre\n",
    "                mod_lst[j][1]=mod_lst[j-1][1]  # if end_pre is larger than end, replace end as end_pre\n",
    "\n",
    "            elif start <=end_pre:\n",
    "                mod_lst[j][0]=mod_lst[j-1][0]  # current start=start_pre\n",
    "                mod_lst[j-1][1]=max(mod_lst[j][1],mod_lst[j-1][1])  # end_pre = end\n",
    "\n",
    "            else:\n",
    "                continue\n",
    "           \n",
    "    mod_lst=[tuple(elm) for elm in mod_lst]\n",
    "    fin_lst=list(dict.fromkeys(mod_lst))\n",
    "    gene_collapsed_df=pd.DataFrame(fin_lst, columns=[\"TxStart\", \"TxEnd\"])\n",
    " \n",
    "    return gene_collapsed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3ce0120f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gene_removeDupl(whole_gene_file='../database/RefSeq/RefSeq.WholeGene.bed'):\n",
    "    g_df_chr_lst=whGene2GLChr(whole_gene_file)\n",
    "    new_gene_lst_all=[]\n",
    "    for chr_no in range(len(g_df_chr_lst)):\n",
    "        gene_df=g_df_chr_lst[chr_no]\n",
    "        gene_collapsed_df=removeOverlapDF(gene_df)\n",
    "        new_gene_lst_all.append(gene_collapsed_df)\n",
    "    return new_gene_lst_all # list of chromosome-wise dataframe for collapsed gene table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6eeed7e",
   "metadata": {},
   "source": [
    "#### Function: `compNonGene2css`\n",
    "* This function extracts the css on the non-genic (intergenic) area of the genome.\n",
    "* The function `gene_removeDupl` was used here, for extracting the non-genic region index.\n",
    "* Input: `whole_gene_file` and `df` (from the css bed file)\n",
    "* Output: `css_Ngene_lst_all` The CSS on the non-genic region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "30387822",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compNonGene2css(whole_gene_file,df):\n",
    "    \"\"\"\n",
    "    Input: Reference gene file, df (CSS)\n",
    "    Output: list of chromosome-wise list that contains the css at \"non-genic\" area only.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Extracting the CSS on the intergenic region ...\")\n",
    "\n",
    "    ########### new fancy gene table without overlap ###########\n",
    "    new_gene_lst_all=gene_removeDupl(whole_gene_file)\n",
    "    ############################################################\n",
    "    \n",
    "    css_lst_chr=df2longcss(df) # list of long css per chromosome\n",
    "    total_chr=len(new_gene_lst_all)\n",
    "    \n",
    "    css_Ngene_lst_all=[]\n",
    "        \n",
    "    for i in tqdm_notebook(range(total_chr)):\n",
    "        css=css_lst_chr[i]   # long css of i-th chromosome\n",
    "        gene_df=new_gene_lst_all[i] # gene df of i-th chromosome\n",
    "        \n",
    "        assert gene_df[\"TxStart\"].iloc[0]>=1, \"Gene starts from the very first location at {}-th chromosome.\".format(i)\n",
    "        assert gene_df[\"TxEnd\"].iloc[-1]<=len(css), \"Gene ends at the very last location at {}-th chromosome.\".format(i)  \n",
    "                \n",
    "        css_Ngene_lst_chr=[]        \n",
    "        for j in range(len(gene_df)):\n",
    "            if j==0:\n",
    "                ng_start=1 # to avoid any \"zero\" causing problem \n",
    "                ng_end=gene_df[\"TxStart\"].iloc[j]\n",
    "#                 print(\"j: {} | ng_start: {} - ng_end: {} \".format(j, ng_start, ng_end)) # for checking\n",
    "            elif j==len(gene_df)-1: \n",
    "                ng_start=gene_df[\"TxEnd\"].iloc[j]\n",
    "                ng_end=len(css)\n",
    "#                 print(\"j: {} | ng_start: {} - ng_end: {} \".format(j, ng_start, ng_end)) # for checking\n",
    "            else:\n",
    "                ng_start=gene_df[\"TxEnd\"].iloc[j-1]\n",
    "                ng_end=gene_df[\"TxStart\"].iloc[j]\n",
    "#                 print(\"j: {} | ng_start: {} - ng_end: {} \".format(j, ng_start, ng_end)) # for checking \n",
    "        \n",
    "            css_Ngene=css[ng_start:ng_end]\n",
    "            css_Ngene_lst_chr.append(css_Ngene)\n",
    "        \n",
    "        css_Ngene_lst_all.append(css_Ngene_lst_chr) \n",
    "        \n",
    "    assert len(css_Ngene_lst_all)==total_chr\n",
    "    print(\"Done!\")\n",
    "    \n",
    "    return css_Ngene_lst_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12918d70",
   "metadata": {},
   "source": [
    "#### Function: `countNgeneCss`\n",
    "* How many css data strips are in the Non-genic (intergenic) region?\n",
    "* How long each css data strips are in the Non-genic (intergenic) region?\n",
    "* Input: `css_Ngene_lst_all`, the result list from `compNonGene2css(whole_gene_file,df)`. (Also pickled at `\"../database/temp_files/css_Ngene_lst_all\"`\n",
    "* Output: Two lists (`ng_css_cnt_all` and `ng_css_len_all`) and their distribution histogram\n",
    "\n",
    "<img src=\"./desc_img/countNgeneCss.png\" width=\"600\" height=\"300\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "99f2a2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def countNgeneCss(css_Ngene_lst_all):\n",
    "    ng_css_cnt_all=[]\n",
    "    ng_css_len_all=[]\n",
    "    tot_chr=len(css_Ngene_lst_all)\n",
    "    for chr_no in range(tot_chr):\n",
    "        ng_chr_lst=css_Ngene_lst_all[chr_no]\n",
    "        ng_css_cnt_all.append(len(ng_chr_lst))\n",
    "        ng_css_len_chr=[]\n",
    "        for i in range(len(ng_chr_lst)):\n",
    "            ng_css_len=len(ng_chr_lst[i])\n",
    "            ng_css_len_chr.append(ng_css_len)  # to let it iterate for chr!\n",
    "        ng_css_len_all.append(ng_css_len_chr)\n",
    "    ng_css_len_all=flatLst(ng_css_len_all) \n",
    "    \n",
    "    ng_css_len_all=list(filter(lambda elm: elm!=0, ng_css_len_all))  # remove 0s\n",
    "        \n",
    "    # visualization for ng_css_cnt_all (no. of data strips per chromosome)\n",
    "    fig,(ax1, ax2)=plt.subplots(1,2,figsize=(12,4), sharey=False)\n",
    "    ax1=sns.histplot(ng_css_cnt_all, bins=12, color=\"navy\", element=\"step\", fill=False, ax=ax1)\n",
    "    ax1.set_xlabel(\"Count of data strip on Intergenic region\", fontsize=13)\n",
    "    ax1.set_ylabel(\"Count\", fontsize=13)\n",
    "    ax1.grid(b=None)\n",
    "    ax1.xaxis.grid(None)\n",
    "    ax1.yaxis.grid()\n",
    "    \n",
    "    # visualization for ng_css_cnt_all (no. of data strips per chromosome)\n",
    "    ax2=sns.histplot(ng_css_len_all, bins=15, log_scale=True, color=\"maroon\", element=\"step\", fill=False, ax=ax2)\n",
    "    ax2.set_xlabel(\"Length of CSS on Intergenic region\", fontsize=13)\n",
    "    ax2.set_ylabel(\"Count\", fontsize=13)\n",
    "    ax2.grid(b=None)\n",
    "    plt.grid(False)\n",
    "            \n",
    "    return ng_css_cnt_all,ng_css_len_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edd56eb",
   "metadata": {},
   "source": [
    "### 3-3-3. Genic or Non-genic raw-length CSS to unit-length CSS\n",
    "\n",
    "* For the genic and intergenic region, the css is the raw length, not the unit length. To keep the same training data condition, the data should be formed as unit length (200-bp).\n",
    "* So, the purpose is to convert `css_Ngene_lst_all` and `css_gene_lst_all` into the unit-length version of them.\n",
    "* To do this job, 2 functions are required : `long2unitCSS` and `Convert2unitCSS_main`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f9f16f",
   "metadata": {},
   "source": [
    "#### Function (preliminary) : `long2unitCSS` (included in the main function)\n",
    "\n",
    "* As the **preliminary** function, `long2unitCSS`, investigates \n",
    "    1. The sequence of the state (letter) appears -> as a list of string\n",
    "    2. How many times the state appears -> as a list of list (numbers)   \n",
    "\n",
    "* Input: `long_css_lst` which is a list of string.\n",
    "\n",
    "* Output\n",
    "    1. `let_str_lst_all`: The list of string that only shows the sequence of the css \n",
    "    2. `unit_cnt_lst_all`: The list of list of unit-length of each state in the list `let_str_lst_all`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3e649ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the idea is to separate, count, combine\n",
    "def long2unitCSS(long_css_lst, unit=200):\n",
    "    \"\"\"\n",
    "    * description *\n",
    "    long_css is the result of the function \"df2longcss\" (real length css), \n",
    "    and this function aims to convert it into the result of the function \"df2unitcss\",\n",
    "    which is shortest possible version of the css.\n",
    "    Why? because pre-train data for ChromBERT is done by unit-length, \n",
    "    and the genic/intergenic css is acquired as a long-css\n",
    "    \n",
    "    Input: long_css_lst (type=list) acquired by df2longcss(df) and the unit length bp (default=200 bp)\n",
    "    Output: let_str_lst_all (list of unit state) and unit_cnt_lst_all (list of list)\n",
    "    \"\"\"\n",
    "    assert type(long_css_lst)==list, \"Check the input type: it should be a list, but now it's {}\".format(type(long_css_lst))\n",
    "    assert type(long_css_lst[0])==str, \"Check the type of input element: it should be a string, but it's {}\".format(type(long_css_lst[0]))\n",
    "    let_str_lst_all=[]\n",
    "    unit_cnt_lst_all=[]\n",
    "    for elm in long_css_lst:\n",
    "        unit_str=''\n",
    "        unit_cnt_lst=[]\n",
    "        unit_cnt=0\n",
    "        for i, let_str in enumerate(elm):\n",
    "            if i==0:     # handling the first letter\n",
    "                unit_str+=let_str\n",
    "                unit_cnt=1\n",
    "            elif i==len(elm)-1:    # handling the final letter\n",
    "                unit_cnt+=1\n",
    "                unit_cnt_lst.append(int(unit_cnt/unit)) \n",
    "            elif let_str==elm[i-1]:\n",
    "                unit_cnt+=1      \n",
    "            elif (let_str!=elm[i-1] and i!=len(elm)-1):\n",
    "                unit_str+=let_str            \n",
    "                unit_cnt+=1\n",
    "                unit_cnt_lst.append(int(unit_cnt/unit))  \n",
    "                unit_cnt=1\n",
    "            else:\n",
    "                continue\n",
    "        let_str_lst_all.append(unit_str)\n",
    "        unit_cnt_lst_all.append(unit_cnt_lst)\n",
    "    return let_str_lst_all, unit_cnt_lst_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd9dab2",
   "metadata": {},
   "source": [
    "#### Function (main): `Convert2unitCSS_main`\n",
    "* Input: `css_gene_lst_all` or `css_Ngene_lst_all`, the raw-length css on genic and non-genic regions, and the unit (default=200, as the css are annotated per )\n",
    "* Output: `css_unit_lst_all`, the list of chromosome-wise list of unit-length css."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d3697fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Convert2unitCSS_main(css_lst_all, unit=200): # should be either css_gene_lst_all or css_Ngene_lst_all\n",
    "    \"\"\"\n",
    "    Input: css_gene_lst_all or css_Ngene_lst_all, the list of chromosome-wise list of the css in genic, intergenic regions.\n",
    "    Output: css_gene_unit_lst_all or css_Ngene_unit_lst_all\n",
    "    \"\"\"\n",
    "    print(\"Converting css from the raw length into unit-length ... \")\n",
    "    css_unit_lst_all=[]\n",
    "    for chr_no in tqdm_notebook(range(len(css_lst_all))):\n",
    "        css_chr_lst=css_lst_all[chr_no]\n",
    "        css_chr_unit_lst=[]\n",
    "        let_str_lst_all, unit_cnt_lst_all=long2unitCSS(css_chr_lst, unit=unit)\n",
    "        unit_css_lst=['']*len(let_str_lst_all)\n",
    "        for i, let_str in enumerate(let_str_lst_all):\n",
    "            for j in range(len(let_str)-1):\n",
    "                unit_css_lst[i]+=let_str[j]*unit_cnt_lst_all[i][j] # only unit will be multiplied!\n",
    "        unit_css_lst=[css for css in unit_css_lst if css!='']  # remove the empty element\n",
    "        css_unit_lst_all.append(unit_css_lst)\n",
    "    print(\"Done!\")\n",
    "    return css_unit_lst_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1216e0",
   "metadata": {},
   "source": [
    "Now following files are saved at : `../database/temp_files/` \n",
    "* `css_gene_unit_lst_all` : The unit-length css on the genic area\n",
    "* `css_Ngene_unit_lst_all`: The unit-length css on the intergenic area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3781b83",
   "metadata": {},
   "source": [
    "### 3-3-3-1. CSS for 57 Epigenomes Genic regions are saved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95587ce5",
   "metadata": {},
   "source": [
    "#### Function:` extGenic_byCell`\n",
    "* Input: output path\n",
    "* This function cut CSS of each cell type by Genic area, and reduce it as unit length\n",
    "* Output: function has been already executed, and pickled at `../database/temp_files/whole_gene_unit/`\n",
    "    * The saved file names are like `E003_css_gene_unit_lst_all.pkl`\n",
    "* **Note** that it takes up to 10 hours to complete if you use macbook pro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb451f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the whole gene area of the 57 epigenomes, in CSS unit sequences (total no. 56, because no E000 for CSS)\n",
    "# Following function has been already executed, and pickled at \"../database/temp_files/whole_gene_unit/\"\n",
    "\n",
    "def extGenic_byCell(output_path=\"../database/temp_files/whole_gene_unit/\", verbose=True):\n",
    "    \"\"\"\n",
    "    Extract the genic area CSS from the designated 57 epigenome in EG.name.txt\n",
    "    and save them at \"../database/temp_files/whole_gene_unit/\"\n",
    "    \"\"\"\n",
    "    # note that EG.name.txt contains E000 (which is not in CSS bed file)\n",
    "    bed_file_path=\"../database/bed/unzipped/\"\n",
    "    epi_name_path=\"../database/bed/gene_expression/EG.name.txt\"\n",
    "\n",
    "    epi_name_df=pd.read_csv(epi_name_path, names=[\"epi_num\",\"epi_name\"], sep=\"\\t\", header=None, index_col=False)\n",
    "    epi_name_df=epi_name_df.dropna()\n",
    "    epi_num=epi_name_df[\"epi_num\"].dropna().to_list() # number, 0th field\n",
    "    epi_name=epi_name_df[\"epi_name\"].dropna().to_list() # name, 1st field\n",
    "    bed_file_lst=sorted(os.listdir(bed_file_path))\n",
    "    \n",
    "    # list comprehension for extract the bed files that corresponds to the target epigenome\n",
    "    epi_target_tuple=[(num, bed_file) for num in epi_num for bed_file in bed_file_lst if num in bed_file]\n",
    "    epi_target=[tup[1] for tup in epi_target_tuple]\n",
    "    path=\"../database/bed/unzipped/\"\n",
    "    \n",
    "#     print(epi_name_df)\n",
    "    for epi in epi_target:\n",
    "        cell_type=epi_name_df.loc[epi_name_df[\"epi_num\"]==epi[:4],\"epi_name\"].values[0]\n",
    "        if verbose: \n",
    "            print(\"{}: {} is now processed ...\".format(epi, cell_type))\n",
    "        \n",
    "        df_epi=bed2df_expanded(path+epi)  # create df of the css for the cell\n",
    "        css_epi_gene_lst_all=compGene2css(whole_gene_file,df_epi) # list of the css on the genic region\n",
    "        css_epi_gene_unit_lst_all=Convert2unitCSS_main(css_epi_gene_lst_all,unit=200) # make css to unit length \n",
    "        # note that the above list is chromosome-wise list\n",
    "        \n",
    "        # total number of genes        \n",
    "        print(\"Total number of genes: {}\".format(len(flatLst(css_epi_gene_unit_lst_all))))\n",
    "        \n",
    "        # pickle it!\n",
    "        epi_gene_css_name=output_path+epi[:4]+\"_css_gene_unit_lst_all.pkl\"\n",
    "        with open(epi_gene_css_name, \"wb\") as f:\n",
    "            pickle.dump(css_epi_gene_unit_lst_all,f)\n",
    "\n",
    "    return print(\"Files are pickled at {}.\".format(output_path))   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a637573c",
   "metadata": {},
   "source": [
    "### 3-3-4. Cut the unit-length css into trainable size and kmerize it\n",
    "\n",
    "#### Function: `chr_css_CUT_Kmer`\n",
    "* Input: Unit-length css list of chromosome-wise list (e.g. `css_gene_unit_lst_all` or `css_Ngene_unit_lst_all`)\n",
    "* Output: \n",
    "    1. `splitted` : List of strings before kmerization (to visualize later)\n",
    "    2. `kmerized_unit_css` :  List of strings after kmerization (to use as a trinable data)\n",
    " \n",
    "* Usage (e.g. Generate a 3-mer traning data from 2nd chromosome in intergenic area)\n",
    "> `splitted, kmerized_unit_css=chr_css_CUT_Kmer(css_Ngene_unit_lst_all, 2, 510, 3)`\n",
    "* And the data can be stored like \n",
    "> `with open(\"../database/fine_tune/genic_and_intergenic/3mer/chr2_Ngene.txt\", \"w\") as f:         f.write(\"\\n\".join(kmerized_unit_css))`\n",
    "       \n",
    "* The reason why the above code for saving is not included is because it takes too much time.. dunno why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9ccd5df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut the unit-length string (input: unit-css, not df)\n",
    "def chr_css_CUT_Kmer(unit_css, chr_no, cut_thres, k):\n",
    "    \"\"\"    \n",
    "    Prepare kmer dataset for unit_css, as is if length<=510, else cut it to be length>510   \n",
    "    Usage: chr_css_CUT_Kmer(unit_css, chr_no, cut_thres, k)\n",
    "    \n",
    "    - unit_css: list of chromosome-wise list of unit-length css (e.g. css_gene_unit_lst_all)\n",
    "    - chr_no: no. of chromosome\n",
    "    - cut_thres: length of split, default=510\n",
    "    - k: kmer\n",
    "    \n",
    "    Output: 1. splitted (before kmerization) 2. kmerized_unit_css (after kmerization) \n",
    "    \"\"\"    \n",
    "    chr_unit_css=unit_css[chr_no]   # designated chromosome no.    \n",
    "    splitted=[] # bucket for the all the splitted strings   \n",
    "    cnt_short, cnt_long=0,0\n",
    "    for css_elm in chr_unit_css:\n",
    "        if len(css_elm) <=cut_thres:\n",
    "            splitted.append(css_elm)\n",
    "            cnt_short+=1\n",
    "        else:\n",
    "            cnt_long+=1\n",
    "            prev=0\n",
    "            while True:\n",
    "                splitted.append(css_elm[prev:prev+cut_thres])\n",
    "                prev+=cut_thres\n",
    "                if prev>=len(css_elm)-1:\n",
    "                    break                   \n",
    "    kmerized_unit_css=[seq2kmer(item, k) for item in splitted]\n",
    "    long_pro=cnt_long/(cnt_long+cnt_short)\n",
    "    \n",
    "    return splitted, kmerized_unit_css"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259161eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "afa94a39",
   "metadata": {},
   "source": [
    "#### Function: `saveCUTs_all`\n",
    "\n",
    "* Simply save the file created from the above fucntion: k-merized genic and intergenic unit-length css\n",
    "* 3mer, 4mer files are already stored at `../database/fine_tune/genic_and_intergenic/`\n",
    "* Usage\n",
    "> `saveCUTs_all(css_gene_unit_lst_all, 510, 3, gene=True)`\n",
    "> saves the css on the genic region after 3-merization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "699c464e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveCUTs_all(unit_css, cut_thres, k, gene=True):\n",
    "    for chr_no in range(len(unit_css)):        \n",
    "        _, kmerized=chr_css_CUT_Kmer(unit_css, chr_no, cut_thres, k)\n",
    "        chr_num=str(chr_no+1)\n",
    "        if gene:\n",
    "            g='gene'\n",
    "        else:\n",
    "            g='Ngene'\n",
    "   \n",
    "        path=\"../database/fine_tune/genic_and_intergenic/\"\n",
    "        kmer=str(k)+'mer/'\n",
    "        folder=g+\"/\"\n",
    "        name=\"chr\"+chr_num+\"_\"+g+\".txt\"\n",
    "        f_name=path+kmer+folder+name\n",
    "        \n",
    "        with open(f_name, \"w\") as f:\n",
    "            f.write(\"\\n\".join(kmerized))\n",
    "    return print(\"{}merized files for {} are saved at {}.\".format(k,unit_css,path+kmer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca5711d",
   "metadata": {},
   "source": [
    "### 3-3-5. Fine-tuning data: Dataframe version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412271f3",
   "metadata": {},
   "source": [
    "#### Function: `prepFT_gNg`\n",
    "* Create a dataframe version of dataset, accommodating the same number of genic and non-genic region unit css.\n",
    "* Input: `path` (for the specific task), `k`, `sampling_no` (number of chromosome you want to pick as a random no.)\n",
    "* Output: `df_g_ng_all` the dataframe containing same amount of genic/non-genic css strips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9dca7216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing the dataframe-version for generating train and dev dataset\n",
    "def prepFT_gNg(path=\"../database/fine_tune/genic_and_intergenic/\", k=4, sampling_no=10):\n",
    "    dir_k=path+str(k)+\"mer/\"\n",
    "    \n",
    "    dir_g=dir_k+\"gene/\"\n",
    "    dir_ng=dir_k+\"Ngene/\"\n",
    "    g_files=os.listdir(dir_g)\n",
    "    ng_files=os.listdir(dir_ng)\n",
    "    all_g_files=file_list_maker(dir_g,g_files)\n",
    "    all_ng_files=file_list_maker(dir_ng,ng_files)\n",
    "    \n",
    "    g_len_all,ng_len_all=[],[]\n",
    "    df_ng_all,df_g_all=[],[]\n",
    "    \n",
    "    ### for Ngene data\n",
    "    for chr_ng in all_ng_files:\n",
    "        df_ng=pd.read_csv(chr_ng, header=None, names=[\"sequence\"], sep=\"\\n\")\n",
    "        df_ng[\"label\"]=0        \n",
    "        ng_len=len(df_ng)  # only for checking length\n",
    "        ng_len_all.append(ng_len)  # only for checking length\n",
    "        \n",
    "        df_ng_all.append(df_ng) \n",
    "    df_ng_concat=pd.concat(df_ng_all)  # for ng, concatenate all the list\n",
    "    \n",
    "    ### for gene data\n",
    "    sample=random.sample([i for i, elm in enumerate(all_g_files)], sampling_no)\n",
    "    print(\"Sampled chromosome for genic region: {}\".format(sample))\n",
    "    for i, chr_g in enumerate(all_g_files):\n",
    "        df_g=pd.read_csv(chr_g, header=None, names=[\"sequence\"], sep=\"\\n\")\n",
    "        df_g[\"label\"]=1\n",
    "        g_len=len(df_g)  # only for checking length\n",
    "        g_len_all.append(g_len)  # only for checking length\n",
    "        \n",
    "        if i in sample:   # sampling \n",
    "            df_g_all.append(df_g)\n",
    "        else:\n",
    "            continue\n",
    "    df_g_concat=pd.concat(df_g_all)\n",
    "    \n",
    "    ### for the length adjustment ###\n",
    "    if len(df_g_concat)>len(df_ng_concat):\n",
    "        df_g_concat=df_g_concat[:len(df_ng_concat)] \n",
    "    elif len(df_g_concat)<len(df_ng_concat):\n",
    "        df_ng_concat=df_ng_concat[:len(df_g_concat)]\n",
    "    assert len(df_g_concat)==len(df_ng_concat)\n",
    "    \n",
    "    df_g_ng_all=pd.concat([df_ng_concat,df_g_concat]).sample(frac=1).reset_index(drop=True)  # shuffling    \n",
    "    \n",
    "    ### for visualization purpose ###\n",
    "#     fig, ax = plt.subplots(1,1,figsize=(6,4))\n",
    "#     ax=sns.histplot(g_len_all, color=\"teal\", element=\"step\", bins=10, fill=False) #cumulative=True\n",
    "#     ax=sns.histplot(ng_len_all, color=\"orange\", element=\"step\", bins=4, fill=False)\n",
    "#     plt.title(\"Cumulative plot of genic/intergenic data size\", fontsize=13)\n",
    "#     ax.set_xlabel(\"Length of data\", fontsize=13)\n",
    "#     ax.legend([\"genic\",\"intergenic\"])\n",
    "#     plt.show()   \n",
    "        \n",
    "    return df_g_ng_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e52dbe5",
   "metadata": {},
   "source": [
    "### 3-3-6. Fine-tuning data: save files as .tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa3488c",
   "metadata": {},
   "source": [
    "#### Function: `saveTF_gNg`\n",
    "* Fine-tuning files for classifying genic and intergenic area already are saved at `\"../database/fine_tune/genic_and_intergenic/\"` (4mer only)\n",
    "* Input: `df_g_ng_all` (Result from the function `prepFT_gNg`), `path`, `k`, `len_train`, `len_dev`\n",
    "* Output: Files are saved at \"`path/kmer/`\" folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8184f04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveTF_gNg(df_g_ng_all, path=\"../database/fine_tune/genic_and_intergenic/\",k=4,len_train=30000,len_dev=1000):\n",
    "    dir_k=path+str(k)+\"mer/\"\n",
    "    df_g_ng_train=df_g_ng_all[:len_train]\n",
    "    df_g_ng_dev=df_g_ng_all[len_train:len_train+len_dev]    \n",
    "    \n",
    "    train_name=dir_k+\"train.tsv\"\n",
    "    dev_name=dir_k+\"dev.tsv\"\n",
    "    \n",
    "    df_g_ng_train.to_csv(train_name, sep=\"\\t\", index=False)\n",
    "    df_g_ng_dev.to_csv(dev_name, sep=\"\\t\", index=False)\n",
    "    \n",
    "    return print(\"train.tsv and dev.tsv Files are saved at '{}'.\". format(dir_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082bb889",
   "metadata": {},
   "source": [
    "## 3-4. Count the number of 15th states in genic and non-genic region"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5117b2",
   "metadata": {},
   "source": [
    "#### Function: `QnonQforCell`\n",
    "\n",
    "* Calculate the numbers of genes that contain/ not contain 15th state (Quiescent) for all 127 cells\n",
    "* Caution: it takes tremendous of time. Just use pickled output at `\"../database/temp_files/\"`\n",
    "* Input: cell file list, whole gene file\n",
    "* Output: `q_cnt_lst` (The number of gene that contains 15th state) / `not_q_cnt_lst` (genes do not have 15th state)\n",
    "* Note that you need to flatten it when use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "df3b6bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for cell-wise count : how many 15th-including genes are there per cell\n",
    "\n",
    "# caution: takes tremendous of time!\n",
    "# better make it for a single cell?\n",
    "# No, it was required, and the result files are pickled at ./temp_files\n",
    "\n",
    "def QnonQforCell(all_files=all_files,whole_gene_file=whole_gene_file):\n",
    "    total_cells=len(all_files)\n",
    "    \n",
    "    q_cnt_lst=[]\n",
    "    not_q_cnt_lst=[]\n",
    "#     for i in range(total_cells):\n",
    "    for i in tqdm_notebook(range(total_cells)):\n",
    "        cell_path=all_files[i]\n",
    "        df=bed2df_expanded(cell_path)\n",
    "        css_gene_lst_all=compGene2css(whole_gene_file,df)\n",
    "        \n",
    "        q_cnt=0\n",
    "        not_q_cnt=0\n",
    "        for j in range(len(css_gene_lst_all)):\n",
    "            css_gene_lst=css_gene_lst_all[j]\n",
    "            for k in range(len(css_gene_lst)):\n",
    "                css_gene=css_gene_lst[k]\n",
    "                if \"O\" in css_gene:\n",
    "                    q_cnt+=1\n",
    "                else:\n",
    "                    not_q_cnt+=1\n",
    "        q_cnt_lst.append(q_cnt)\n",
    "        not_q_cnt_lst.append(not_q_cnt)\n",
    "    return q_cnt_lst, not_q_cnt_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a836e0",
   "metadata": {},
   "source": [
    "#### Function: `QnonQforChr`\n",
    "* Similar to `QnonQforCell`, but it is a flatten version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "688cff7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for chromosome-wise list of list -> flatten list\n",
    "\n",
    "def QnonQforChr(all_files=all_files,whole_gene_file=whole_gene_file):\n",
    "#     import itertools\n",
    "    total_cells=len(all_files)\n",
    "    \n",
    "    q_cnt_lst_all=[]\n",
    "    not_q_cnt_lst_all=[]\n",
    "#     for i in range(total_cells):\n",
    "    for i in tqdm_notebook(range(total_cells)):\n",
    "        cell_path=all_files[i]\n",
    "        df=bed2df_expanded(cell_path)\n",
    "        css_gene_lst_all=compGene2css(whole_gene_file,df)\n",
    "        \n",
    "        q_cnt_lst=[]\n",
    "        not_q_cnt_lst=[]\n",
    "        for j in range(len(css_gene_lst_all)):\n",
    "            css_gene_lst=css_gene_lst_all[j]\n",
    "            \n",
    "            q_cnt=0\n",
    "            not_q_cnt=0\n",
    "            for k in range(len(css_gene_lst)):\n",
    "                css_gene=css_gene_lst[k]\n",
    "                if \"O\" in css_gene:\n",
    "                    q_cnt+=1\n",
    "                else:\n",
    "                    not_q_cnt+=1\n",
    "                    \n",
    "            q_cnt_lst.append(q_cnt)\n",
    "            not_q_cnt_lst.append(not_q_cnt)        \n",
    "        q_cnt_lst_all.append(q_cnt_lst)\n",
    "        not_q_cnt_lst_all.append(not_q_cnt_lst)\n",
    "\n",
    "#     flatten the list of list and make it into list\n",
    "    q_cnt_lst_all=list(itertools.chain.from_iterable(q_cnt_lst_all))\n",
    "    not_q_cnt_lst_all=list(itertools.chain.from_iterable(not_q_cnt_lst))\n",
    "        \n",
    "    return q_cnt_lst_all, not_q_cnt_lst_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f301f779",
   "metadata": {},
   "source": [
    "#### Function: `QnonQforCellHistT1`\n",
    "\n",
    "* Input: `q_cnt_lst`, `not_q_cnt_lst` (they are pickled at `\"../database/temp_files/\"`)\n",
    "* How to load the pickled data\n",
    "    > `with open(\"path\", \"rb\") as f:`  <br>\n",
    "    > `data=pickle.load(f)`\n",
    "* Output: Histogram of the numbers of gene per cell that contains/ don't contain 15th state in the all cell types\n",
    "<br><br>\n",
    "\n",
    "<img src=\"./desc_img/qnonq_hist1.png\" width=\"400\" height=\"150\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ad5fc2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw a histogram type1 (group by data)\n",
    "def QnonQforCellHistT1(q_cnt_lst, not_q_cnt_lst, bin_size=20):\n",
    "    \"\"\"Run this after executing QnonQforCell\"\"\"\n",
    "    data_w=q_cnt_lst\n",
    "    data_wo=not_q_cnt_lst\n",
    "\n",
    "    mu_w, std_w=norm.fit(data_w)\n",
    "    mu_wo, std_wo=norm.fit(data_wo)\n",
    "\n",
    "    fig=plt.figure(figsize=(8,4))\n",
    "    ax=fig.add_subplot(1,1,1)\n",
    "    ax.hist(data_w, bins=bin_size, alpha=0.3, color=\"k\")\n",
    "    ax.hist(data_wo, bins=bin_size, alpha=0.5, color=\"r\")\n",
    "\n",
    "    title='Number of Genic region with/without Quiescent state'\n",
    "    \n",
    "    ax.set_title(title, fontsize=15)\n",
    "    ax.set_xlabel(\"No. of Genes\", fontsize=15)\n",
    "    plt.xticks(fontsize=12)\n",
    "    ax.set_ylabel(\"Counts\", fontsize=15)\n",
    "    ax.legend([\"With Q\", \"Without Q\"])\n",
    "    plt.yticks(fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e0a824",
   "metadata": {},
   "source": [
    "#### Function: `QnonQforCellHistT2`\n",
    "\n",
    "* Input: `q_cnt_lst`, `not_q_cnt_lst` and `bin_size` (they are pickled at `\"../database/temp_files/\"`)\n",
    "* How to load the pickled data\n",
    "    > `with open(\"path\", \"rb\") as f:`  <br>\n",
    "    > `data=pickle.load(f)`\n",
    "* Output: Histogram of the numbers of gene per cell that contains/ don't contain 15th state in the all cell types that is grouped by bin (Well, I don't know why I wrote this code..)\n",
    "<br><br>\n",
    "\n",
    "<img src=\"./desc_img/qnonq_hist2.png\" width=\"400\" height=\"150\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a5cd9203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw a histogram type2 (group by bin)\n",
    "def QnonQforCellHistT2(q_cnt_lst, not_q_cnt_lst,bin_size):\n",
    "    \"\"\"Run this after executing QnonQforCell\"\"\"\n",
    "    data_w=q_cnt_lst\n",
    "    data_wo=not_q_cnt_lst\n",
    "\n",
    "    mu_w, std_w=norm.fit(data_w)\n",
    "    mu_wo, std_wo=norm.fit(data_wo)\n",
    "\n",
    "    fig=plt.figure(figsize=(8,4))\n",
    "    ax=fig.add_subplot(1,1,1)\n",
    "    ax.hist([data_w,data_wo], bins=bin_size, alpha=0.5, color=[\"teal\",\"orange\"], label=[\"with Quiescent state\",\"without Quiescent state\"])\n",
    "    \n",
    "    ax.legend(loc=\"upper left\")\n",
    "\n",
    "    title='Number of Genic region with/without Quiescent state'\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"No. of Genes\")\n",
    "    plt.ylabel(\"Counts\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e784b4ca",
   "metadata": {},
   "source": [
    "#### Fuction: `QnonQforCellSwarmp`\n",
    "* Create a dataframe of two lists (below) and draw a dual swarmp graph in a single figure.\n",
    "* Input: `q_cnt_lst` and `not_q_cnt_lst` (find them pickled at `\"../database/temp_files/\"`)\n",
    "* Output: `q_cnt_data` (dataframe of the two lists) and the graph\n",
    "\n",
    "<img src=\"./desc_img/qnonq_swarmp.png\" width=\"400\" height=\"150\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "29aaa812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def QnonQforCellSwarmp(q_cnt_lst, not_q_cnt_lst):\n",
    "    q_cnt_data=pd.DataFrame({\"q_cnt\":q_cnt_lst, \"not_q_cnt\":not_q_cnt_lst}) # create a dataframe\n",
    "    fig=plt.figure(figsize=(6,4))\n",
    "    sns.swarmplot(data=q_cnt_data, palette=\"bone\")\n",
    "    plt.grid(b=None)\n",
    "    plt.ylabel(\"Counts\", fontsize=12)\n",
    "    plt.show()\n",
    "    return q_cnt_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84043e2",
   "metadata": {},
   "source": [
    "#### Function: `cntQinGene`\n",
    "* This function generates three lists\n",
    "    1. 15th state-including gene count\n",
    "    2. 15th state-including gene length\n",
    "    3. Proportion of 15th state in the 15th state-including gene\n",
    "* Input: `css_gene_lst_all` (pickled at `\"../database/temp_files/\"`, note that it's 2.8Gb)\n",
    "* Output: \n",
    "    1. `cnt_o_lst`: 15th state-including gene count\n",
    "    2. `gene_len_lst`: 15th state-including gene length\n",
    "    3. `pro_o_lst`: Proportion of 15th state in the 15th state-including gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d4ae54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate three lists: 15th state-including gene count, gene length, proportion of 15th state per gene\n",
    "def cntQinGene(css_gene_lst_all):\n",
    "    \"\"\"run this after executing compGene2css(whole_gene_file,df)\n",
    "       [Input]\n",
    "       css_gene_lst_all : list of css list of each chromosome\n",
    "       [Output]\n",
    "       cnt_o_lst : list of Quiescent state counts list per chromosome\n",
    "       gene_len_lst : list of gene length (in terms of chromatin state Anno.200bps) list per chromosome\n",
    "       pro_o_lst : list of proportion of Quiescent state per gene list per chromosome\n",
    "    \"\"\"\n",
    "    cnt_o_lst=[]\n",
    "    gene_len_lst=[]\n",
    "    pro_o_lst=[]\n",
    "    for i in range(len(css_gene_lst_all)):\n",
    "        css_gene_lst=css_gene_lst_all[i]\n",
    "        \n",
    "        cnt_o_chr=[]\n",
    "        gene_len_chr=[]\n",
    "        pro_o_chr=[]\n",
    "        for j in range(len(css_gene_lst)):\n",
    "            css_gene=css_gene_lst[j]\n",
    "            cnt_o=css_gene.count(\"O\")\n",
    "            gene_len=len(css_gene)\n",
    "            pro_o=cnt_o/gene_len\n",
    "            \n",
    "            cnt_o_chr.append(cnt_o)\n",
    "            gene_len_chr.append(gene_len)\n",
    "            pro_o_chr.append(pro_o)\n",
    "            \n",
    "        cnt_o_lst.append(cnt_o_chr)\n",
    "        gene_len_lst.append(gene_len_chr)\n",
    "        pro_o_lst.append(pro_o_chr)\n",
    "        \n",
    "    return cnt_o_lst, gene_len_lst, pro_o_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1b6bf5",
   "metadata": {},
   "source": [
    "#### Function: `cntQinGeneVis1`\n",
    "* For visualization of the result of the function `cntQinGene`.\n",
    "* Input: `cnt_o_lst`, `gene_len_lst`, and `pro_o_lst` (result of `cntQinGene`), for more info, see that function.\n",
    "* Output: Letter-value histogram of `cnt_o_lst` and `gene_len_lst`, and violin plot for `pro_o_lst`\n",
    "<img src=\"./desc_img/cntQinGeneVis1.png\" width=\"500\" height=\"150\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "591d42aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cntQinGeneVis1(cnt_o_lst, gene_len_lst, pro_o_lst):\n",
    "    \"\"\"\n",
    "    Input: cnt_o_lst, gene_len_lst, pro_o_lst (the result lists of cntQinGene(css_gene_lst_all). To load the css_gene_lst_all, find the file at \"../database/temp_files/\")\n",
    "    Output: Dataframe of those 3 lists, and the visualization of the above lists using histogram\n",
    "    \"\"\"\n",
    "    def flatLst(lst):\n",
    "        flatten_lst=[elm for sublst in lst for elm in sublst]\n",
    "        return flatten_lst\n",
    "\n",
    "    cnt_o_lst_flat=flatLst(cnt_o_lst)\n",
    "    gene_len_lst_flat=flatLst(gene_len_lst)\n",
    "    pro_o_lst_flat=flatLst(pro_o_lst)\n",
    "    \n",
    "    three_df=pd.DataFrame({\"gene_len\":gene_len_lst_flat, \"cnt_o\":cnt_o_lst_flat, \"o_proportion\":pro_o_lst_flat})\n",
    "    \n",
    "    fig, (ax1,ax2) = plt.subplots(1,2,figsize=(10,5), sharey=False)\n",
    "    ax1=sns.boxenplot(data=three_df[[\"gene_len\",\"cnt_o\"]],palette=\"viridis\", width=0.6, linewidth=0.01, scale=\"linear\", ax=ax1)\n",
    "    ax1.set_ylabel(\"Count\", fontsize=15)\n",
    "    \n",
    "    ax2=sns.violinplot(data=three_df[[\"o_proportion\"]], linewidth=0.6, inner=\"box\", width=0.6, color=\"lightgray\", ax=ax2)  \n",
    "    ax2.set_ylabel(\"Proportion\", fontsize=15)\n",
    "    ax2.grid()\n",
    "    plt.grid(b=None)\n",
    "    \n",
    "    return three_df   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee0837f",
   "metadata": {},
   "source": [
    "## 3-5. Complexity of CSS in genic area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82de6f2",
   "metadata": {},
   "source": [
    "**[back to index](#Index)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941ed854",
   "metadata": {},
   "source": [
    "### 3-5-1. Create a matrix to show the statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae4d733",
   "metadata": {},
   "source": [
    "#### Function: `complexity_overview_mat`\n",
    "\n",
    "* Usage: Produce a dataframe describing the complexity of the CSS pattern\n",
    "* Input: list of css (Here, `gene_css_all` which is pickled at `\"../database/temp_files/\"`)\n",
    "* Columns: `[\"length\",\"uniq\",\"switch\",\"uniq_pro\",\"switch_pro\"]`\n",
    "* `length`: gene length\n",
    "* `uniq`: How many unique states are \n",
    "* `switch`: How many times the states changed\n",
    "* `uniq_pro`: Proportion of `uniq` per gene length\n",
    "* `switch_pro`: Proportion of `switch` per gene length\n",
    "* Output: dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc7db6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complexity_overview_mat(chr_gene_css):\n",
    "    abs_uniq_all=[]\n",
    "    abs_switch_all=[]\n",
    "    gene_len_all=[]\n",
    "    compl_uniq_all=[]\n",
    "    compl_swit_all=[]\n",
    "    for num in range(len(chr_gene_css)):\n",
    "        gene_css=chr_gene_css[num]\n",
    "        gene_css_len=len(gene_css)\n",
    "        css_uniq=len(set(gene_css)) # only the unique css (min=1, max=gene_css_len)\n",
    "        \n",
    "        tot_char=\"\"\n",
    "        for i, char in enumerate(gene_css):\n",
    "            if i==0 or char!=gene_css[i-1]:\n",
    "                tot_char+=char\n",
    "            css_switch=len(tot_char) # num. of swtiching in css (min=1, max=gene_css_len)\n",
    "            complexity_uniq=css_uniq/gene_css_len\n",
    "            complexity_swit=css_switch/gene_css_len\n",
    "        \n",
    "        gene_len_all.append(gene_css_len)\n",
    "        abs_uniq_all.append(css_uniq)\n",
    "        abs_switch_all.append(css_switch)\n",
    "        compl_uniq_all.append(complexity_uniq)\n",
    "        compl_swit_all.append(complexity_swit)\n",
    "        \n",
    "    data=list(zip(gene_len_all,abs_uniq_all, abs_switch_all,compl_uniq_all,compl_swit_all))\n",
    "    df=pd.DataFrame(data,columns=[\"length\",\"uniq\",\"switch\",\"uniq_pro\",\"switch_pro\"])\n",
    "    df=df[df[\"length\"]>=2]  # remove when the length = 1 unit (=200 bps)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d90957e",
   "metadata": {},
   "source": [
    "### 3-5-2. Extract the complex and less complex css on gene"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564e0090",
   "metadata": {},
   "source": [
    "#### Function: `extract_complex_css`\n",
    "\n",
    "* Usage: Return two lists (css on complex gene / less complex gene) \n",
    "* Input: list of css (Here, `gene_css_all` which is pickled as `\"../database/temp_files/css_gene_unit_lst_all\"`)\n",
    "* Output: `comp_gene_css_all`,`less_comp_gene_css_all`\n",
    "* Above output files are stored as pickle, at `\"../database/temp_files/complexity` using following commands:\n",
    "\n",
    "`with open(\"../database/temp_files/complexity/thres_mean/comp\", \"wb\") as f:\n",
    "    pickle.dump(comp_gene_css_all,f)`\n",
    "    \n",
    "`with open(\"../database/temp_files/complexity/thres_mean/less_comp\", \"wb\") as g:\n",
    "    pickle.dump(less_comp_gene_css_all,g)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1abea07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract according to the complexity\n",
    "\n",
    "def extract_complex_css(gene_css_all, thres=\"mean\"):\n",
    "    '''\n",
    "    Load the file first by `pickle.load(open(\"../database/temp_files/css_gene_unit_lst_all\",\"rb\"))`\n",
    "    This function will extract the css of gene which is defined as complex in css pattern.\n",
    "    '''\n",
    "    tot_gene_css=flatLst(gene_css_all) # flatten it from 24 chromosomes\n",
    "    tot_gene_css=[gene_css for gene_css in tot_gene_css if len(gene_css)>=2] # length<2 removed\n",
    "    \n",
    "    df=complexity_overview_mat(tot_gene_css) # from the process, length<2 was removed\n",
    "    # df columns=[\"length\",\"uniq\",\"switch\",\"uniq_pro\",\"switch_pro\"]     \n",
    "    assert len(tot_gene_css)==len(df), \"length of tot_gene_css and df do not match\"\n",
    "    \n",
    "    df[\"css\"]=tot_gene_css # add new column with css (per gene)\n",
    "        \n",
    "    comp_gene_css_all=[]\n",
    "    less_comp_gene_css_all=[]\n",
    "    \n",
    "    if thres==\"mean\":\n",
    "        thres_val=np.mean(df[\"switch_pro\"])\n",
    "    \n",
    "    for i, css in enumerate(tot_gene_css):\n",
    "        if df[\"switch_pro\"].iloc[i]>=thres_val:\n",
    "            comp_gene_css_all.append(df[\"css\"].iloc[i])\n",
    "        else:\n",
    "            less_comp_gene_css_all.append(df[\"css\"].iloc[i])\n",
    "        \n",
    "    return comp_gene_css_all,less_comp_gene_css_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ed9ac8",
   "metadata": {},
   "source": [
    "### 3-5-2-1. CSS for 57 Epigenomes Complex and Less Complex Genic regions are saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8266c402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the complex and less complex genic area of the 57 epigenomes, in CSS unit sequences\n",
    "# Following function has been already executed, and pickled at \"../database/temp_files/complexity/thres_mean/byCellType/\"\n",
    "\n",
    "def extCompGenic_byCell(output_path=\"../database/temp_files/complexity/\", thres=\"mean\", all_file=True, verbose=True, **kwargs):\n",
    "    \"\"\"\n",
    "    This function extract CSS complex and less-complex genic region, according to the threshold.\n",
    "    (1) To process all the .pkl file in ../database/temp_files/whole_gene_unit/, set 'all_file=True'.\n",
    "        If you want to process only one file at a time, set e.g.) 'file=E003_css_gene_unit_lst_all.pkl'\n",
    "    \"\"\"\n",
    "    \n",
    "    css_gene_path=\"../database/temp_files/whole_gene_unit/\"\n",
    "    if thres==\"mean\":\n",
    "        output_path_mod=output_path+\"thres_\"+thres+\"/byCellType/\"\n",
    "    else:\n",
    "        print(\"No threshold other than 'mean'.\")\n",
    "    \n",
    "    # File list of CSS on genic region for all cell types\n",
    "    files_under_folder=sorted(os.listdir(css_gene_path))\n",
    "    cell_gene_css_all=[file for file in files_under_folder if file.startswith('E') and file.endswith('.pkl')]\n",
    "    \n",
    "    if all_file:\n",
    "        if verbose: print(\"processing all files ...\")\n",
    "        for epi_css in tqdm_notebook(cell_gene_css_all):             \n",
    "            epi_num=epi_css[:4] # e.g.) E003\n",
    "            if verbose: print(\"{} is now processed ...\".format(epi_num))\n",
    "            file_path=css_gene_path+epi_css\n",
    "            with open(file_path,\"rb\") as f:\n",
    "                cell_gene_css=pickle.load(f)\n",
    "            comp_gene_css,less_comp_gene_css=extract_complex_css(cell_gene_css, thres=thres)\n",
    "            comp_name=output_path_mod+epi_num+\"_comp_gene_css.pkl\"\n",
    "            less_name=output_path_mod+epi_num+\"_less_comp_gene_css.pkl\"\n",
    "            with open(comp_name,\"wb\") as g:\n",
    "                pickle.dump(comp_gene_css, g)\n",
    "            with open(less_name,\"wb\") as h:\n",
    "                pickle.dump(less_comp_gene_css, h)  \n",
    "                           \n",
    "    elif len(kwargs)>0:\n",
    "        for file_key, file_name in kwargs.items():            \n",
    "            epi_num=file_name[:4]\n",
    "            file_path=css_gene_path+file_name\n",
    "            if verbose: print(\"all_file=False, processing single case for {}.\".format(epi_num))\n",
    "            with open(file_path,\"rb\") as f:\n",
    "                cell_gene_css=pickle.load(f)\n",
    "            comp_gene_css,less_comp_gene_css=extract_complex_css(cell_gene_css, thres=thres)\n",
    "            comp_name=output_path_mod+epi_num+\"_comp_gene_css.pkl\"\n",
    "            less_name=output_path_mod+epi_num+\"_less_comp_gene_css.pkl\"\n",
    "            with open(comp_name,\"wb\") as g:\n",
    "                pickle.dump(comp_gene_css, g)\n",
    "            with open(less_name,\"wb\") as h:\n",
    "                pickle.dump(less_comp_gene_css, h)               \n",
    "    else:\n",
    "        raise ValueError(\"Set all_file=True, or desginate any file name to proceed!\")\n",
    "    \n",
    "    return print(\"Results are stored at {}\".format(output_path_mod))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebc161c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4b3f3dc",
   "metadata": {},
   "source": [
    "### 3-5-3. Cut into Kmer and save"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17143094",
   "metadata": {},
   "source": [
    "#### Function: `css_CUT_Kmer` (general form of `chr_css_CUT_Kmer`)\n",
    "\n",
    "* Usage: For any list of CSS, cut them when it is longer than `cut_thres`, and make it `k`-mer\n",
    "* Input: list of css (Here, `comp_gene_css_all` which is generated from the above fnt `extract_complex_css`)\n",
    "* Output: `splitted` (raw splitted list),`kmerized_unit_css` (k-merized form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2e95380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut if it is longer than 510\n",
    "def css_CUT_Kmer(css, cut_thres=510, k=5):\n",
    "    \"\"\" \n",
    "    A GENERAL version of `chr_css_CUT_Kmer` and updated to remove any nan in sequence\n",
    "    Prepare kmer dataset for unit_css, as is if length<=510, else cut it to be length>510   \n",
    "    Usage: css_CUT_Kmer(css, cut_thres, k)\n",
    "    \n",
    "    - css: unit-length css (e.g. comp_gene_css_all)\n",
    "    - cut_thres: length of split, default=510\n",
    "    - k: kmer\n",
    "    \n",
    "    Output: 1. splitted (before kmerization) 2. kmerized_unit_css (after kmerization) \n",
    "    \"\"\"    \n",
    "    splitted=[] # bucket for the all the splitted strings   \n",
    "    for css_elm in css:\n",
    "        if len(css_elm) <k:  # if the length of css_elm is shorter than k (cannot create k-mer)\n",
    "            continue\n",
    "        elif len(css_elm) <=cut_thres:\n",
    "            splitted.append(css_elm)\n",
    "        else:  \n",
    "            prev=0\n",
    "            while True:\n",
    "                splitted.append(css_elm[prev:prev+cut_thres])\n",
    "                prev+=cut_thres\n",
    "                if prev>=len(css_elm)-1:\n",
    "                    break      \n",
    "\n",
    "    kmerized_unit_css_raw=[seq2kmer(item, k) for item in splitted] # k-merize here\n",
    "    \n",
    "    ### this part is updated to prevent any empty string to be generated ###\n",
    "    kmerized_unit_css=[item for item in kmerized_unit_css_raw if item!=\"\"]\n",
    "    ########################################################################\n",
    "    \n",
    "    return splitted, kmerized_unit_css"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a03ddb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cut if it is longer than 510\n",
    "# def css_CUT_Kmer(css, cut_thres=510, k=5):\n",
    "#     \"\"\" \n",
    "#     A GENERAL version of `chr_css_CUT_Kmer`\n",
    "#     Prepare kmer dataset for unit_css, as is if length<=510, else cut it to be length>510   \n",
    "#     Usage: css_CUT_Kmer(css, cut_thres, k)\n",
    "    \n",
    "#     - css: unit-length css (e.g. comp_gene_css_all)\n",
    "#     - cut_thres: length of split, default=510\n",
    "#     - k: kmer\n",
    "    \n",
    "#     Output: 1. splitted (before kmerization) 2. kmerized_unit_css (after kmerization) \n",
    "#     \"\"\"    \n",
    "#     splitted=[] # bucket for the all the splitted strings   \n",
    "#     for css_elm in css:\n",
    "#         if len(css_elm) <k:  # if the length of css_elm is shorter than k (cannot create k-mer)\n",
    "#             continue\n",
    "#         elif len(css_elm) <=cut_thres:\n",
    "#             splitted.append(css_elm)\n",
    "#         else:  \n",
    "#             prev=0\n",
    "#             while True:\n",
    "#                 splitted.append(css_elm[prev:prev+cut_thres])\n",
    "#                 prev+=cut_thres\n",
    "#                 if prev>=len(css_elm)-1:\n",
    "#                     break      \n",
    "            \n",
    "#     kmerized_unit_css=[seq2kmer(item, k) for item in splitted] # k-merize here\n",
    "    \n",
    "#     return splitted, kmerized_unit_css"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6685b9d",
   "metadata": {},
   "source": [
    "#### Function: `save_as_txt` \n",
    "\n",
    "* Usage: simply save the list as txt file, under the path, with the designated file name.\n",
    "* Input: list of css (Here, `comp_gene_css_all` which is generated from the fnt `extract_complex_css`)\n",
    "* Remarks: This file includes the above function `css_CUT_Kmer`\n",
    "* Output: None, just displaying that it is saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5b92032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_txt(css, path=\"../database/wo_telo/\", filename=\"complex_gene_all\", cut_thres=510, k=5):\n",
    "    \n",
    "    _, kmerized_unit_css=css_CUT_Kmer(css, cut_thres, k)\n",
    "    \n",
    "    full_path=path+filename+\"_\"+str(k)+\".txt\"\n",
    "    with open(full_path,\"w\") as save_file:\n",
    "        save_file.write(\"\\n\".join(kmerized_unit_css))\n",
    "    return print(\"{} is saved at {}\".format(filename, path))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fec478d",
   "metadata": {},
   "source": [
    "### 3-5-4. Show the composition for each case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51937b52",
   "metadata": {},
   "source": [
    "#### Function: `css_composition_piechart` \n",
    "\n",
    "* Usage: After running `css_CUT_Kmer`, show the composition of CSS in either complex or less complex genic area\n",
    "* Input: splitted_lst can be the first production of the function `css_CUT_Kmer`\n",
    "* complexity: `True`=splitted (produced from `comp_gene_css_all`, `False`=less_splitted (produced from `less_comp_gene_css_all`) \n",
    "* show_pct: threshold to show the percentage in pie chart (default=5)\n",
    "* Output: None, just displaying the pie chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f0a573e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def css_composition_piechart(splitted_lst, complexity=True, show_pct=5):\n",
    "    \"\"\"\n",
    "    Usage: css_composition_piechart(splitted_lst, complexity=True, show_pct=5)\n",
    "    Input: splitted_lst can be the first production of the function \"css_CUT_Kmer\"\n",
    "    complexity: True=splitted (produced from comp_gene_css_all, False=less_splitted (produced from less_comp_gene_css_all)\n",
    "    show_pct: threshold to show the percentage in pie chart\n",
    "    \"\"\"\n",
    "    state_count = {chr(i): 0 for i in range(ord('A'), ord('O')+1)}\n",
    "    for elm in splitted_lst:\n",
    "        for state in elm:\n",
    "            if state in state_count:\n",
    "                state_count[state] += 1  # create a dictionary, value of which is the no. of state appeared overall\n",
    "    total = sum(state_count.values())\n",
    "    sizes = [i/sum(state_count.values())*100 for i in state_count.values()] # percentage of occupation\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "    ax.pie(state_count.values(),colors=[state_col_dict[label] for label in data.keys()], autopct=lambda p: '{:.2f}%'.format(p) if p > show_pct else '')\n",
    "\n",
    "    if complexity:\n",
    "        title=\"Complex gene CS composition,\"+\" total:\"+\" \"+str(total)\n",
    "    else:\n",
    "        title=\"Less complex gene CS composition,\"+\" total:\"+\" \"+str(total)\n",
    "    \n",
    "    for t in ax.texts:\n",
    "        t.set_color(\"white\")\n",
    "        t.set_fontsize(20)\n",
    "\n",
    "    ax.set_title(title,fontsize=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2c5898",
   "metadata": {},
   "source": [
    "### 3-5-5. Prepare and save Fine-tuning for Complex gene CSS and others"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147c0ba3",
   "metadata": {},
   "source": [
    "#### Function: `prep_and_saveTF_CompNcomp` \n",
    "\n",
    "* Usage: Prerpare and save the fine-tuning data for **complex** and **less complex gene css**\n",
    "* Input files are loaded inside the function, which are pickled at `\"../database/temp_files/complexity/thres_mean/\"`\n",
    "* Output: None, just displaying the report that the file is saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e3b7949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now for compG and nonCompG (the function covers from prepration to save)\n",
    "def prep_and_saveTF_CompNcomp(condition=\"thres_mean\", cut_thres=510, k=5, save_path=\"CompG_and_lessCompG\",len_tr=20000, len_dev=1000):\n",
    "    \"\"\"\n",
    "    prepare fine tuning data for [the complex gene css / less complex gene css]\n",
    "    \"\"\"\n",
    "    print(\"* Project name: \", save_path)\n",
    "    print(\"* condition: \", condition)\n",
    "    print(\"* Cut threshold length: \", cut_thres)\n",
    "    print(\"* k-merization: \", k)\n",
    "    print(\"* train: dev = {} : {}\".format(len_tr,len_dev))\n",
    "    \n",
    "    comp_path=\"../database/temp_files/complexity/\"+condition+\"/comp\"\n",
    "    comp=pickle.load(open(comp_path, \"rb\"))\n",
    "    less_comp_path=\"../database/temp_files/complexity/\"+condition+\"/less_comp\"\n",
    "    less_comp=pickle.load(open(less_comp_path, \"rb\"))\n",
    "    \n",
    "    # kmerization\n",
    "    _, comp_kmerized=css_CUT_Kmer(comp, cut_thres, k)\n",
    "    _, less_comp_kmerized=css_CUT_Kmer(less_comp, cut_thres, k)\n",
    "    \n",
    "    # make it dataframe\n",
    "    df_comp=pd.DataFrame(comp_kmerized, columns=[\"sequence\"])\n",
    "    df_comp[\"label\"]=1\n",
    "    df_less_comp=pd.DataFrame(less_comp_kmerized, columns=[\"sequence\"])\n",
    "    df_less_comp[\"label\"]=0\n",
    "    \n",
    "    # make them have the same length\n",
    "    if len(df_comp)>len(df_less_comp):\n",
    "        df_comp=df_comp[:len(df_less_comp)] \n",
    "    elif len(df_comp)<len(df_less_comp):\n",
    "        df_less_comp=df_less_comp[:len(df_comp)]\n",
    "    assert len(df_comp)==len(df_less_comp), \"Check the data length.\"\n",
    "    \n",
    "    # shuffling ...\n",
    "    df_comp_all=pd.concat([df_comp,df_less_comp]).sample(frac=1).reset_index(drop=True)  \n",
    "\n",
    "    # cutting into train and dev\n",
    "    assert len(df_comp_all)> len_tr+len_dev, \"Not enough data length.\"\n",
    "    df_comp_train=df_comp_all[:len_tr]\n",
    "    df_comp_dev=df_comp_all[len_tr:len_tr+len_dev]    \n",
    "  \n",
    "    path=\"../database/fine_tune/\"+save_path+\"/\"+str(k)+\"mer/\"\n",
    "    train_name=path+\"train.tsv\"\n",
    "    dev_name=path+\"dev.tsv\"\n",
    "    \n",
    "    df_comp_train.to_csv(train_name, sep=\"\\t\", index=False)\n",
    "    df_comp_dev.to_csv(dev_name, sep=\"\\t\", index=False)\n",
    "\n",
    "    return print(\"Fine-tuning data for {} are {}merized and saved at {}.\".format(save_path,k,path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2565df7f",
   "metadata": {},
   "source": [
    "#### Function: `prep_and_saveTF_CompNgene` \n",
    "\n",
    "* Usage: Prerpare and save the fine-tuning data for **complex** and **None gene css**\n",
    "* Input files are loaded inside the function, which are pickled at `\"../database/temp_files/complexity/thres_mean/\"` for complex gene, and at `\"../database/temp_files/css_Ngene_unit_lst_all\"` for intergenic area (a.k.a. Ngene)\n",
    "* Output: None, just displaying the report that the file is saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72e759e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now,  for compG and non gene (the function covers from prepration to save)\n",
    "def prep_and_saveTF_CompNgene(condition=\"thres_mean\", cut_thres=510, k=5, save_path=\"CompG_and_intergenic\",len_tr=20000, len_dev=1000):\n",
    "    \"\"\"\n",
    "    prepare fine tuning data for [the complex gene css / none gene css]\n",
    "    \"\"\"\n",
    "    print(\"* Project name: \", save_path)\n",
    "    print(\"* condition: \", condition)\n",
    "    print(\"* Cut threshold length: \", cut_thres)\n",
    "    print(\"* k-merization: \", k)\n",
    "    print(\"* train: dev = {} : {}\".format(len_tr,len_dev))\n",
    "    \n",
    "    comp_path=\"../database/temp_files/complexity/\"+condition+\"/comp\"\n",
    "    comp=pickle.load(open(comp_path, \"rb\"))\n",
    "    Ngene_path=\"../database/temp_files/css_Ngene_unit_lst_all\"\n",
    "    Ngene=pickle.load(open(Ngene_path, \"rb\"))\n",
    "    #flatten\n",
    "    Ngene=flatLst(Ngene)\n",
    "    \n",
    "    # kmerization\n",
    "    _, comp_kmerized=css_CUT_Kmer(comp, cut_thres, k)\n",
    "    _, Ngene_kmerized=css_CUT_Kmer(Ngene, cut_thres, k)\n",
    "    \n",
    "    # make it dataframe\n",
    "    df_comp=pd.DataFrame(comp_kmerized, columns=[\"sequence\"])\n",
    "    df_comp[\"label\"]=1\n",
    "    df_Ngene=pd.DataFrame(Ngene_kmerized, columns=[\"sequence\"])\n",
    "    df_Ngene[\"label\"]=0\n",
    "    \n",
    "    # make them have the same length\n",
    "    if len(df_comp)>len(df_Ngene):\n",
    "        df_comp=df_comp[:len(df_Ngene)] \n",
    "    elif len(df_comp)<len(df_Ngene):\n",
    "        df_Ngene=df_Ngene[:len(df_comp)]\n",
    "    assert len(df_comp)==len(df_Ngene), \"Check the data length.\"\n",
    "    \n",
    "    # shuffling ...\n",
    "    df_compNgene=pd.concat([df_comp,df_Ngene]).sample(frac=1).reset_index(drop=True)  \n",
    "\n",
    "    # cutting into train and dev\n",
    "    assert len(df_compNgene)> len_tr+len_dev, \"Not enough data length.\"\n",
    "    df_compNgene_train=df_compNgene[:len_tr]\n",
    "    df_compNgene_dev=df_compNgene[len_tr:len_tr+len_dev]    \n",
    "  \n",
    "    path=\"../database/fine_tune/\"+save_path+\"/\"+str(k)+\"mer/\"\n",
    "    train_name=path+\"train.tsv\"\n",
    "    dev_name=path+\"dev.tsv\"\n",
    "    \n",
    "    df_compNgene_train.to_csv(train_name, sep=\"\\t\", index=False)\n",
    "    df_compNgene_dev.to_csv(dev_name, sep=\"\\t\", index=False)\n",
    "\n",
    "    return print(\"Fine-tuning data for {} are {}merized and saved at {}.\".format(save_path,k,path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f34a8a8",
   "metadata": {},
   "source": [
    "## 3-6. Gene expression classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f281fb8",
   "metadata": {},
   "source": [
    "For more difficult tasks, gene expression can be one of the criteria to prepare fine tuning data. First, using the gene expression level from RNA-seq, highly expressed "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a68f0eb",
   "metadata": {},
   "source": [
    "### 3-6-1. Gene expression file into the list of dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566e76a2",
   "metadata": {},
   "source": [
    "#### Function: `Gexp_Gene2GLChr`\n",
    "\n",
    "* This function only checks a single file.\n",
    "* Usage: After the gene expression files such as `gene_highlyexpressed.refFlat` are acquired by `/database/bed/gene_expression/classifygenes_ROADMAP_RPKM.py`, apply this function to obtain the list of dataframe per chromosome contains the transcription start and end indices.\n",
    "* Input: gene expression (high/low/not) file\n",
    "* Output: a chromosome-wise list of dataframe containing `TxStart` and `TxEnd`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3628ef37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for preprocess the whole gene data and produce chromosome-wise gene lists\n",
    "# each element is dataframe\n",
    "\n",
    "### this function is not essential, but just to check by create df from .refFlat\n",
    "def Gexp_Gene2GLChr(exp_gene_file='../database/bed/gene_expression/E050/gene_highlyexpressed.refFlat'):\n",
    "    print(\"Extracting the gene file ...\")\n",
    "    g_fn=exp_gene_file\n",
    "    g_df_raw=pd.read_csv(g_fn, sep='\\t', index_col=False, header=0)\n",
    "    g_df=g_df_raw\n",
    "    g_df=g_df.iloc[:,1:]\n",
    "    g_df.rename(columns={\"name\":\"gene_id\"}, inplace=True)\n",
    "    g_df.rename(columns={\"#geneName\":\"geneName\"}, inplace=True)\n",
    "    g_df.rename(columns={\"txStart\":\"TxStart\"}, inplace=True) # to make it coherent to my previous codes\n",
    "    g_df.rename(columns={\"txEnd\":\"TxEnd\"}, inplace=True)\n",
    "#     g_df=g_df_raw.rename(columns={0:\"geneName\",1:\"gene_id\",2:\"chrom\",3:\"strand\",4:\"txStart\",5:\"txEnd\",\n",
    "#                                       6:\"cdsStart\",7:\"cdsEnd\",8:\"exonCount\",9:\"exonStart\",10:\"exonEnds\",\n",
    "#                                       11:\"gene type\",12:\"transcript type\",13:\"reference transcript name\",\n",
    "#                                       14:\"reference transcription id\"})\n",
    "    ## string to the list of \"int\", for exon start/end ##\n",
    "    g_df_temp=g_df # copy for processing\n",
    "    exon_start_int_lst=[]\n",
    "    for i, str_lst in enumerate(g_df_temp[\"exonStarts\"]):\n",
    "        int_lst=[int(elm) for elm in str_lst.replace(\"[\",\"\").replace(\"]\",\"\").split(\",\")]\n",
    "        assert g_df_temp[\"exonCount\"][i]==len(int_lst) # make sure the no. element in exon st count\n",
    "        exon_start_int_lst.append(int_lst)    \n",
    "    g_df_temp[\"exonStarts\"]=exon_start_int_lst\n",
    "\n",
    "    exon_end_int_lst=[]\n",
    "    for i, str_lst in enumerate(g_df_temp[\"exonEnds\"]):\n",
    "        int_lst=[int(elm) for elm in str_lst.replace(\"[\",\"\").replace(\"]\",\"\").split(\",\")]\n",
    "        assert g_df_temp[\"exonCount\"][i]==len(int_lst) # make sure the no. element in exon start = count\n",
    "        exon_end_int_lst.append(int_lst)    \n",
    "    g_df_temp[\"exonEnds\"]=exon_end_int_lst    \n",
    "    g_df=g_df_temp # and make it back the original name\n",
    "        \n",
    "    g_df=g_df[[\"geneName\",\"gene_id\",\"chrom\",\"TxStart\",\"TxEnd\"]] # extract these only\n",
    "    \n",
    "    # Remove other than regular chromosomes\n",
    "    chr_lst=['chr1','chr2','chr3','chr4','chr5','chr6','chr7','chr8','chr9','chr10',\n",
    "             'chr11','chr12','chr13','chr14','chr15','chr16','chr17','chr18','chr19',\n",
    "             'chr20','chr21','chr22','chrX','chrY']\n",
    "    g_df=g_df.loc[g_df[\"chrom\"].isin(chr_lst)]\n",
    "    \n",
    "    # Create a list of chromosome-wise dataframe \n",
    "    g_df_chr_lst=[]\n",
    "    for num in range(len(chr_lst)):\n",
    "        chr_num=chr_lst[num]\n",
    "        g_chr_df='g_'+chr_num  # name it as \"g_\"\n",
    "        locals()[g_chr_df]=g_df[g_df[\"chrom\"]==chr_num]\n",
    "        g_chr_df=locals()[g_chr_df]\n",
    "        g_chr_df=g_chr_df.sort_values(\"TxStart\")\n",
    "        g_df_chr_lst.append(g_chr_df)\n",
    "        \n",
    "    # Remove the overlapped area (using removeOverlapDF function in css_utility.py)\n",
    "    g_df_chr_collapsed_lst=[]\n",
    "    for g_df_chr in g_df_chr_lst:\n",
    "        g_df_chr_collapsed=removeOverlapDF(g_df_chr)\n",
    "        assert len(g_df_chr)>=len(g_df_chr_collapsed)\n",
    "        g_df_chr_collapsed_lst.append(g_df_chr_collapsed)\n",
    "    print(\"Done!\")\n",
    "    \n",
    "    return g_df_chr_collapsed_lst  # list of dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b573fbe",
   "metadata": {},
   "source": [
    "### 3-6-2. Matching to CSS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d361ead",
   "metadata": {},
   "source": [
    "#### Function: `comp_expGene2css`\n",
    "\n",
    "* Usage: modified from `compGene2css`, Use it like  `css_gene_lst_all=comp_expGene2css(\"../database/bed/gene_expression/gene_highlyexpressed.refFlat\",df_e050)`\n",
    "* Input: \n",
    "    * (highly/low/not) expressed gene, such as `\"../database/bed/gene_expression/gene_highlyexpressed.refFlat\"`\n",
    "    * df, acquired from css created by bed2df_expanded\n",
    "* Output\n",
    "    * list of chromosome-wise list that contains the css at (highly/low/not) genic area only.\n",
    "* **caution!** Do not forget to conduct `Convert2unitCSS_main(css_gene_lst_all, unit=200)`, to convert the result into 200-bps unit length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80c7ec5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_expGene2css(exp_gene_file,df):   # df indicates css, created by bed2df_expanded\n",
    "    \"\"\"\n",
    "    modified from `compGene2css`\n",
    "    Input: Reference gene file, df (CSS)\n",
    "    Output: list of chromosome-wise list that contains the css at (expressed) genic area only.\n",
    "    \"\"\"\n",
    "    g_lst_chr=Gexp_Gene2GLChr(exp_gene_file)\n",
    "#     g_lst_chr=whGene2GLChr(whole_gene_file) # list of gene table df per chromosome\n",
    "    css_lst_chr=df2longcss(df) # list of long css per chromosome\n",
    "    total_chr=len(g_lst_chr)\n",
    "    \n",
    "    print(\"Matching to the chromatin state sequence data ...\")\n",
    "    css_gene_lst_all=[]\n",
    "    for i in tqdm_notebook(range(total_chr)):\n",
    "        css=css_lst_chr[i]   # long css of i-th chromosome\n",
    "        gene_df=g_lst_chr[i] # gene df of i-th chromosome\n",
    "        \n",
    "        css_gene_lst_chr=[]\n",
    "        for j in range(len(gene_df)):\n",
    "            g_start=gene_df[\"TxStart\"].iloc[j]-1  # python counts form 0\n",
    "            g_end=gene_df[\"TxEnd\"].iloc[j]+1      # python excludes the end\n",
    "            \n",
    "            css_gene=css[g_start:g_end]           # cut the gene area only\n",
    "            css_gene_lst_chr.append(css_gene)     # store in the list\n",
    "          \n",
    "        css_gene_lst_all.append(css_gene_lst_chr)  # list of list\n",
    "    \n",
    "    assert len(css_gene_lst_all)==total_chr\n",
    "    \n",
    "    # remove chromosome if it is empty (e.g. chrY for female)\n",
    "    css_gene_lst_all=[elm for elm in css_gene_lst_all if elm!=[]] \n",
    "            \n",
    "    print(\"Done!\")\n",
    "    return css_gene_lst_all ## this is the original length! reduce it at Convert2unitCSS_main(css_lst_all, unit=200)!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f27b03f",
   "metadata": {},
   "source": [
    "### 3-6-2-1. CSS for various gene expression cases are saved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e0abbc",
   "metadata": {},
   "source": [
    "#### Function `extExpGenic_byCell_1_ver01`\n",
    "* From the css bed file for each cell, expressed genic region and highly expressed genic region `refFlat` data are saved by running the \"classifygenes_ROADMAP_RPKM.py\". To complete, execute `extExpGenic_byCell_2`.\n",
    "* Input: output path\n",
    "* Usage example: `extExpGenic_byCell_1_ver01(output_path=\"../database/temp_files/expressed/byCellType/refFlat/\", all_file=False, high_only=True, verbose=True, exp=0, high_exp=10, file=\"E050_15_coreMarks_stateno.bed\")`\n",
    "* In `ver01`, the argument `high_only` is added to produce highly_expressed case only, as the \"expressed\" is the same (rpkm > 0)\n",
    "* This function was executed and the result is already saved. See `../database/bed/gene_expression/byCellType/refFlat/rpkm10`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d3c36ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extExpGenic_byCell_1_ver01(output_path=\"../database/temp_files/expressed/byCellType/refFlat/\", all_file=True, high_only=True, verbose=True, exp=0, high_exp=50, **kwargs):\n",
    "    \"\"\"\n",
    "    RUN THE SECOND function 'extExpGenic_byCell_2' after running this function.\n",
    "    This function extract CSS expressed genic region, mainly for \"expressed\" and \"highly-expressed\"\n",
    "    (1) To process all the  ... set 'all_file=True'.\n",
    "        If you want to process only one file at a time, set e.g.) all_file=False, file=\"E050_15_coreMarks_stateno.bed\"\n",
    "    (2) High_only = True will only produce the highly expressed cases (default) \n",
    "    (3) Outputs are e.g.) \"E112_gene_expressed.refFlat\", \"E112_gene_highlyexpressed.refFlat\" at output path\n",
    "    \"\"\"\n",
    "    \n",
    "    output_path_mod=output_path+\"rpkm\"+str(high_exp)+\"/\"\n",
    "    \n",
    "    path=\"../database/bed/gene_expression/\"\n",
    "    script=\"classifygenes_ROADMAP_RPKM.py\"\n",
    "    epi_rpkm_tsv=\"57epigenomes.RPKM.pc.tsv\"\n",
    "    gene_ref=\"chr.gene.refFlat\"\n",
    "    original_path=\"~/Work/chromatin_state/NSP/\"\n",
    "    \n",
    "    save_path=\"./byCellType/refFlat/\"+\"rpkm\"+str(high_exp)+\"/\"\n",
    "    css_bed_path=\"../database/bed/unzipped/\"\n",
    "\n",
    "    if all_file:\n",
    "        css_gene_path=\"../database/temp_files/whole_gene_unit/\"\n",
    "        # File list of CSS on genic region for all cell types\n",
    "        files_under_folder=sorted(os.listdir(css_gene_path))\n",
    "        cell_gene_css_all=[file for file in files_under_folder if file.startswith('E') and file.endswith('.pkl')]\n",
    "        \n",
    "#         all_css_bed_file=sorted(os.listdir(css_bed_path)) # all css bed file, we need to choose the target\n",
    "#         # list comprehension to choose the targets (57 epigenomes)    \n",
    "#         target_cell_gene_css=[css_bed for css_bed in all_css_bed_file for epi in cell_gene_css_all if css_bed[:4]==epi[:4]]\n",
    "        \n",
    "        if verbose: print(\"processing all files ...\")\n",
    "        for epi_css in tqdm_notebook(cell_gene_css_all):             \n",
    "            epi_num=epi_css[:4] # e.g.) E003\n",
    "            \n",
    "            if verbose: print(\"{} is now processed ...\".format(epi_num))\n",
    "            file_path=css_bed_path+epi_css\n",
    "#             df=bed2df_expanded(file_path)  # css df\n",
    "\n",
    "            ######## Running the script at working path and come back to the original path #########\n",
    "            %cd -q {path}\n",
    "            %run {script} --thre_expressed {exp} --thre_highlyexpressed {high_exp} {epi_rpkm_tsv} {epi_num} {gene_ref}\n",
    "\n",
    "            if not high_only:\n",
    "                exp_file_name=save_path+epi_num+\"_\"+\"gene_expressed.refFlat\"\n",
    "            hexp_file_name=save_path+epi_num+\"_\"+\"gene_highlyexpressed.refFlat\"\n",
    "            %mv \"gene_expressed.refFlat\" {exp_file_name}\n",
    "            %mv \"gene_highlyexpressed.refFlat\" {hexp_file_name}\n",
    "            %cd -q {original_path}\n",
    "            ########################################################################################\n",
    "                \n",
    "        \n",
    "    elif len(kwargs)>0:       \n",
    "        for file_key, file_name in kwargs.items():            \n",
    "            epi_num=file_name[:4]\n",
    "            if verbose: print(\"all_file=False, processing single case for {}.\".format(epi_num))\n",
    "\n",
    "            file_path=css_bed_path+file_name\n",
    "#             df=bed2df_expanded(file_path)  # css df for the designated file\n",
    "            \n",
    "            ######## Running the script at working path and come back to the original path #########\n",
    "            %cd -q {path}\n",
    "            %run {script} --thre_expressed {exp} --thre_highlyexpressed {high_exp} {epi_rpkm_tsv} {epi_num} {gene_ref}\n",
    "\n",
    "            if not high_only:\n",
    "                exp_file_name=save_path+epi_num+\"_\"+\"gene_expressed.refFlat\"\n",
    "            hexp_file_name=save_path+epi_num+\"_\"+\"gene_highlyexpressed.refFlat\"\n",
    "            %mv \"gene_expressed.refFlat\" {exp_file_name}\n",
    "            %mv \"gene_highlyexpressed.refFlat\" {hexp_file_name}\n",
    "            %cd -q {original_path}\n",
    "            ########################################################################################\n",
    "            \n",
    "    else:\n",
    "        raise ValueError(\"Set all_file=True, or desginate any file name to proceed!\")\n",
    "    assert os.getcwd()[-3:]==\"NSP\", \"Check the current working directory.\"\n",
    "    \n",
    "    return print(\"Results are stored at {}, and current working directory is : {}\".format(output_path_mod, os.getcwd()))\n",
    "                           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e6ed08",
   "metadata": {},
   "source": [
    "#### Function `extExpGenic_byCell_2_ver01`\n",
    "* Expressed genic region, highly expressed genic region's css data are saved.\n",
    "* Input: output path, `high_only` for selecting whether just \"expressed\" will be included. `high_exp` is for designating the RPKM\n",
    "* Output: output folder name will be like `rpkm50`\n",
    "* This function was executed and the result is already saved.\n",
    "* To check the result, visit the output path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f455c4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extExpGenic_byCell_2_ver01(output_path=\"../database/temp_files/expressed/byCellType/\",all_file=True, high_only=True, high_exp=50, verbose=True, **kwargs):\n",
    "    \"\"\"\n",
    "    Should be executed after extExpGenic_byCell_1_ver01\n",
    "    modified the previous version to make it applicalbe to highly_expressed only extraction\n",
    "    with high_only=True, highly expressed gene according to the high_exp value (RPKM) are extracted.\n",
    "    \"\"\"\n",
    "    exp_ref_path=\"../database/bed/gene_expression/byCellType/refFlat/\"\n",
    "    hexp_ref_path=exp_ref_path+\"rpkm\"+str(high_exp)+\"/\"\n",
    "    \n",
    "    ref_exp_file_all=sorted(os.listdir(exp_ref_path))\n",
    "    ref_hexp_file_all=sorted(os.listdir(hexp_ref_path))\n",
    "    \n",
    "    ref_exp_all=[elm for elm in ref_exp_file_all if '_expressed' in elm and elm.startswith('E')]\n",
    "    ref_hexp_all=[elm for elm in ref_hexp_file_all if 'high' in elm and elm.startswith('E')]\n",
    "      \n",
    "    css_gene_path=\"../database/temp_files/whole_gene_unit/\"\n",
    "    css_bed_path=\"../database/bed/unzipped/\"\n",
    "    css_bed_file_all=sorted(os.listdir(css_bed_path))    \n",
    "\n",
    "    if all_file:\n",
    "        if verbose: print(\"processing all files ...\")\n",
    "        for epi_css in tqdm_notebook(ref_hexp_all):\n",
    "            epi_num=epi_css[:4]\n",
    "            if verbose: print(\"{} is now processed ...\".format(epi_num))\n",
    "            # preparing df from bed\n",
    "            target_bed=[elm for elm in css_bed_file_all if elm[:4]==epi_num]\n",
    "            bed_path=css_bed_path+target_bed[0]\n",
    "            df=bed2df_expanded(bed_path)\n",
    "            # preparing ref from exp_refs\n",
    "            target_hexp_ref=[elm for elm in ref_hexp_all if elm[:4]==epi_num]\n",
    "            target_exp_ref=[elm for elm in ref_exp_all if elm[:4]==epi_num]\n",
    "            hexp=hexp_ref_path+target_hexp_ref[0]\n",
    "            exp=exp_ref_path+target_exp_ref[0]\n",
    "\n",
    "            if not high_only:  # extract just 'expressed' case if high_only is False (default=True)\n",
    "                css_exp_gene_lst=comp_expGene2css(exp,df)\n",
    "                css_exp_gene_unit_lst=flatLst(Convert2unitCSS_main(css_exp_gene_lst, unit=200))\n",
    "                with open(output_path+\"expressed/\"+epi_num+\"_exp_gene_css.pkl\",\"wb\") as g:\n",
    "                    pickle.dump(css_exp_gene_unit_lst,g)\n",
    "                    \n",
    "            css_hexp_gene_lst=comp_expGene2css(hexp,df)\n",
    "            css_hexp_gene_unit_lst=flatLst(Convert2unitCSS_main(css_hexp_gene_lst, unit=200))\n",
    "            with open(output_path+\"rpkm\"+str(high_exp)+\"_highly_expressed/\"+epi_num+\"_highly_exp_gene_css.pkl\",\"wb\") as f:\n",
    "                pickle.dump(css_hexp_gene_unit_lst,f)\n",
    "            \n",
    "    elif \"file\" in kwargs:\n",
    "        file_name=kwargs[\"file\"]\n",
    "#         for file_key, file_name in kwargs.items():            \n",
    "        epi_num=file_name[:4]\n",
    "        if verbose: print(\"all_file=False, processing single case for {}.\".format(epi_num))\n",
    "        # preparing df from bed\n",
    "        target_bed=[elm for elm in css_bed_file_all if elm[:4]==epi_num]\n",
    "        bed_path=css_bed_path+target_bed[0]\n",
    "        df=bed2df_expanded(bed_path)\n",
    "        # preparing ref from exp_refs\n",
    "        target_hexp_ref=[elm for elm in ref_hexp_all if elm[:4]==epi_num]\n",
    "        target_exp_ref=[elm for elm in ref_exp_all if elm[:4]==epi_num]\n",
    "        hexp=hexp_ref_path+target_hexp_ref[0]\n",
    "        exp=exp_ref_path+target_exp_ref[0]\n",
    "        \n",
    "        if not high_only:  # extract just 'expressed' case if high_only is False (default=True)\n",
    "            css_exp_gene_lst=comp_expGene2css(exp,df)\n",
    "            css_exp_gene_unit_lst=flatLst(Convert2unitCSS_main(css_exp_gene_lst, unit=200))\n",
    "            with open(output_path+\"expressed/\"+epi_num+\"_exp_gene_css.pkl\",\"wb\") as g:\n",
    "                pickle.dump(css_exp_gene_unit_lst,g)\n",
    "\n",
    "        css_hexp_gene_lst=comp_expGene2css(hexp,df)\n",
    "        css_hexp_gene_unit_lst=flatLst(Convert2unitCSS_main(css_hexp_gene_lst, unit=200))\n",
    "        with open(output_path+\"rpkm\"+str(high_exp)+\"_highly_expressed/\"+epi_num+\"_highly_exp_gene_css.pkl\",\"wb\") as f:\n",
    "            pickle.dump(css_hexp_gene_unit_lst,f)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Set all_file=True, or desginate any file name to proceed!\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d87817",
   "metadata": {},
   "source": [
    "#### Function `extNOTexp_Genic_byCell`\n",
    "* NOT expressed genic region's css data are saved.\n",
    "* Input: output path\n",
    "* This function was executed and the result is already saved.\n",
    "* To check the result, visit the output path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78fafee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extNOTexp_Genic_byCell(output_path=\"../database/temp_files/expressed/byCellType/not_expressed/\", all_file=True, verbose=True, **kwargs):\n",
    "  # This function only compares the whole genic with expressed genic and subtract them.\n",
    "  # Perhaps should be changed later?\n",
    "    css_exp_path=\"../database/temp_files/expressed/byCellType/expressed/\"\n",
    "    css_whole=\"../database/temp_files/whole_gene_unit/\"\n",
    "    whole_gene_files=sorted(glob.glob(css_whole+\"*.pkl\"))\n",
    "    exp_gene_files=sorted(glob.glob(css_exp_path+\"*.pkl\"))\n",
    "\n",
    "    if all_file: \n",
    "        if verbose: print(\"processing all files ...\")\n",
    "        for gene_file in tqdm_notebook(whole_gene_files):\n",
    "            pattern=r'E[0-9]+'\n",
    "            epi_num=re.findall(pattern, gene_file)[0] # e.g.) 'E003'\n",
    "            # take expressed gene list for the same cell type\n",
    "            exp_gene_file=[file for file in exp_gene_files if epi_num in file][0]\n",
    "            with open(gene_file,\"rb\") as f:\n",
    "                whole_gene=flatLst(pickle.load(f))\n",
    "            with open(exp_gene_file, \"rb\") as g:\n",
    "                exp_gene=pickle.load(g)\n",
    "            not_exp_gene_all=[]\n",
    "            not_exp_gene=[gene for gene in whole_gene if gene not in exp_gene]\n",
    "            not_exp_gene_all.append(not_exp_gene)\n",
    "            with open(output_path+epi_num+\"_not_exp_gene_css.pkl\",\"wb\") as h:\n",
    "                pickle.dump(not_exp_gene,h)\n",
    "    \n",
    "    elif \"file\" in kwargs:\n",
    "        exp_gene_file=kwargs[\"file\"]    \n",
    "        epi_num=exp_gene_file[:4]\n",
    "        exp_gene_file_w_path=css_exp_path+exp_gene_file\n",
    "        assert epi_num[0]==\"E\", \"File name should start with 'E'. Remove any path before the file name.\"\n",
    "        if verbose: print(\"all_file=False, processing single case for {}.\".format(epi_num))\n",
    "        \n",
    "        gene_file=[elm for elm in whole_gene_files if epi_num in elm][0]        \n",
    "        with open(gene_file,\"rb\") as f:\n",
    "            whole_gene=flatLst(pickle.load(f))\n",
    "        with open(exp_gene_file_w_path, \"rb\") as g:\n",
    "            exp_gene=pickle.load(g)\n",
    "        not_exp_gene=[gene for gene in whole_gene if gene not in exp_gene]\n",
    "        with open(output_path+epi_num+\"_not_exp_gene_css.pkl\",\"wb\") as h:\n",
    "            pickle.dump(not_exp_gene,h)\n",
    "    else:\n",
    "        pass\n",
    "    return print(\"files are saved at {}\".format(output_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf40922",
   "metadata": {},
   "source": [
    "### 3-6-3. Cut into Kmer and save"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae219eab",
   "metadata": {},
   "source": [
    "#### Function `save_kmers_ver01`\n",
    "* **Note** that this function for highly_expressed case is not useful because the pretrain is conducted for whole_cell\n",
    "* Input: output path, k for kmerization, kwargs should include \"kind\"\n",
    "* Usage: e.g.) `save_kmers(k=4,kind=\"whole_gene\")`\n",
    "* Output: none, **note** that this function is already executed and `.txt` files for the pretraining have been saved. Visit the output path indicated in the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e52dd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_kmers_ver01(output_path=\"../database/pretrain/expressed/\", high_exp=50, k=4,**kwargs):\n",
    "    \"\"\"\n",
    "    \"kind\" for kwargs can be chosen among (\"whold_gene\",\"not_expressed\",\"expressed\", \"highly_expressed\")\n",
    "    if \"kind\" is highly_expressed, RPKM value should be provided as high_exp.\n",
    "    But this is not very meaningful, because pretrain is conducted with whole_gene only...\n",
    "    \"\"\"\n",
    "    input_path=\"../database/temp_files/\"\n",
    "    epi_num_lst=pd.read_csv(\"../database/temp_files/whole_gene_unit/epigenome_lst.txt\", header=None, names=[\"num\"])\n",
    "    epi_num=epi_num_lst[\"num\"].tolist()\n",
    "    if high_exp:\n",
    "        print(\"The threshold for highly expressed is set as RPKM={}\".format(high_exp))\n",
    "    for num in tqdm_notebook(epi_num):   \n",
    "        if 'kind' in kwargs:\n",
    "            gene_type=kwargs[\"kind\"]\n",
    "            if gene_type==\"whole_gene\":\n",
    "                file_name=input_path+gene_type+\"_unit/\"+num+\"_css_gene_unit_lst_all.pkl\"\n",
    "            elif gene_type==\"not_expressed\":\n",
    "                file_name=input_path+\"expressed/byCellType/\"+gene_type+\"/\"+num+\"_not_exp_gene_css.pkl\"\n",
    "            elif gene_type==\"expressed\":\n",
    "                file_name=input_path+\"expressed/byCellType/\"+gene_type+\"/\"+num+\"_exp_gene_css.pkl\"\n",
    "            ### note that there is subfolder for highly expressed case\n",
    "            elif gene_type==\"highly_expressed\":\n",
    "                file_name=input_path+\"expressed/byCellType/\"+\"rpkm\"+str(high_exp)+\"_\"+gene_type+\"/\"+num+\"_highly_exp_gene_css.pkl\"\n",
    "            else:\n",
    "                pass\n",
    "            with open(file_name, \"rb\") as f:\n",
    "                target=pickle.load(f)\n",
    "                ####### whole_gene is not flat list #######\n",
    "                if gene_type==\"whole_gene\":\n",
    "                    target=flatLst(target)\n",
    "                ###########################################\n",
    "                _, kmerized_unit_css=css_CUT_Kmer(target, k=k)\n",
    "            \n",
    "        if gene_type==\"highly_expressed\":\n",
    "            output_path_mod=output_path+str(k)+\"mer/\"+\"rpkm\"+str(high_exp)+\"_\"+gene_type+\"/\"+num+\"_\"+gene_type+\".txt\"\n",
    "        else:\n",
    "            output_path_mod=output_path+str(k)+\"mer/\"+gene_type+\"/\"+num+\"_\"+gene_type+\".txt\"\n",
    "        with open(output_path_mod,\"w\") as g:\n",
    "            g.write(\"\\n\".join(kmerized_unit_css))           \n",
    "    return \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a455f0a2",
   "metadata": {},
   "source": [
    "### 3-6-4. Fine-tuning data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d603c3",
   "metadata": {},
   "source": [
    "#### Function: `prep_and_saveTF_ver01`\n",
    "* Save the fine-tuning data for gene expression\n",
    "* Three different binary classifications are possible: exp vs. not exp, rpkmNN_highly exp vs. exp, rpkmNN_highly exp vs. not exp\n",
    "* Can be used with following inputs, for example:\n",
    "    <blockquote>\n",
    "    input_path=\"../database/temp_files/expressed/byCellType/\" <br>\n",
    "    output_path=\"../database/fine_tune/gene_exp/4mer/Gexp_or_not\" <br>\n",
    "    cl1=\"expressed\" <br>\n",
    "    cl2=\"not_expressed\" <br>\n",
    "    epi_num_lst=[\"E003\",\"E128\"] <br>\n",
    "    </blockquote>\n",
    "* This function already executed for the above conditions. See `../database/fine_tune/gene_exp/4mer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99b276d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For saving gene expression fine-tuning data\n",
    "def prep_and_saveTF_ver01(input_path, output_path, cl1, cl2, epi_num_lst, cut_thres=510, k=4, len_tr=20000, len_dev=1000):\n",
    "    \"\"\"\n",
    "    * Generallized function for preparing fine tuning data.\n",
    "    * Input path will be in the temp_files\n",
    "    * cl1 and cl2 refer to the name of class you want to classify in binary classification.\n",
    "    * cl1 and cl2 are any of \"expressed\", \"not_expressed\", \"rpkmNN_highly_expressed\" (NN is number)\n",
    "    * epi_num_lst should contain the name of epigenomes like \"E003.\" If you need more, then add like [\"E003\", \"E004\", ...]\n",
    "    \"\"\"\n",
    "    print(\"* Input path: \", input_path)\n",
    "    print(\"* Binary classification for '{}' and '{}'\".format(cl1, cl2))\n",
    "#     ans= \"yes\" if incl_hexp else \"no\"\n",
    "#     print(\"* Including highly expressed case: {}\".format(ans))\n",
    "    print(\"* Output path: \", output_path)\n",
    "    print(\"* Cut threshold length: \", cut_thres)\n",
    "    print(\"* k-merization: \", k)\n",
    "    print(\"* train: dev = {} : {}\".format(len_tr,len_dev))\n",
    "    \n",
    "    cl1_path=input_path+cl1+\"/\"\n",
    "    cl2_path=input_path+cl2+\"/\"\n",
    "    \n",
    "    cl1_concat=[]\n",
    "    cl2_concat=[]\n",
    "    \n",
    "    suffix_dict = {}\n",
    "    for cl in [cl1, cl2]:\n",
    "        if \"highly\" in cl:\n",
    "#             rpkm_no=re.search(r'rpkm(\\d+)',cl).group(1) # no.. this is not required. already inside the name of cl1 an cl2\n",
    "            suffix_dict[cl] = \"_highly_exp_gene_css.pkl\"\n",
    "        elif \"not\" in cl:\n",
    "            suffix_dict[cl] = \"_not_exp_gene_css.pkl\"\n",
    "        else:\n",
    "            suffix_dict[cl] = \"_exp_gene_css.pkl\"\n",
    "    \n",
    "    for cl, concat_lst in [(cl1, cl1_concat), (cl2, cl2_concat)]:\n",
    "        for epi_num in epi_num_lst:\n",
    "            file_path = input_path + cl + \"/\" + epi_num + suffix_dict[cl]\n",
    "            concat_lst.extend(pickle.load(open(file_path, \"rb\")))\n",
    "    \n",
    "    # kmerization\n",
    "    _, cl1_kmerized=css_CUT_Kmer(cl1_concat, cut_thres, k)\n",
    "    _, cl2_kmerized=css_CUT_Kmer(cl2_concat, cut_thres, k)\n",
    "    \n",
    "    # make it dataframe\n",
    "    df_cl1=pd.DataFrame(cl1_kmerized, columns=[\"sequence\"])\n",
    "    df_cl1[\"label\"]=1\n",
    "    df_cl2=pd.DataFrame(cl2_kmerized, columns=[\"sequence\"])\n",
    "    df_cl2[\"label\"]=0\n",
    "    \n",
    "    # make them have the same length\n",
    "    if len(df_cl1)>len(df_cl2):\n",
    "        df_cl1=df_cl1[:len(df_cl2)] \n",
    "    elif len(df_cl1)<len(df_cl2):\n",
    "        df_cl2=df_cl2[:len(df_cl1)]\n",
    "    assert len(df_cl1)==len(df_cl2), \"Check the data length.\"\n",
    "    \n",
    "    # shuffling ...\n",
    "    df_all=pd.concat([df_cl1,df_cl2]).sample(frac=1).reset_index(drop=True)  \n",
    "\n",
    "    # cutting into train and dev\n",
    "    assert len(df_all)> len_tr+len_dev, \"Not enough data length.\"\n",
    "    df_train=df_all[:len_tr]\n",
    "    df_dev=df_all[len_tr:len_tr+len_dev]    \n",
    "  \n",
    "    #path=\"../database/fine_tune/\"+save_path+\"/\"+str(k)+\"mer/\"\n",
    "    \n",
    "    by_tr_len=str(\"{:.0f}\".format(len_tr/1000))\n",
    "    output_path_mod=output_path+\"tr_len_\"+by_tr_len+\"k/\"\n",
    "    \n",
    "    # create a destination folder if it does not exist.\n",
    "    if os.path.exists(output_path_mod):\n",
    "        raise ValueError(\"Folder already exists:{}\".format(output_path_mod))\n",
    "    else:\n",
    "        os.makedirs(output_path_mod)\n",
    "    \n",
    "    train_name=output_path_mod+\"train.tsv\"\n",
    "    dev_name=output_path_mod+\"dev.tsv\"\n",
    "    \n",
    "    df_train.to_csv(train_name, sep=\"\\t\", index=False)\n",
    "    df_dev.to_csv(dev_name, sep=\"\\t\", index=False)\n",
    "\n",
    "    return print(\"Fine-tuning data for {} and {} (epigenome no. {}) are {}merized and saved at {}.\".format(cl1, cl2, epi_num_lst, k, output_path_mod))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10956b62",
   "metadata": {},
   "source": [
    "### 3-6-5. Pie chart statistics: generalized verion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a14e5a",
   "metadata": {},
   "source": [
    "#### Funtion `css_composition_piechart_Gen`\n",
    "* Input: path for .pkl or the list of \"splitted\" acquired directly from the function `css_CUT_Kmer` \n",
    "    * Either one of the path for .pkl or splitted shold be provided. \n",
    "* Usage\n",
    "    * Create a piechar to show the composition of each state in a certain list of css.\n",
    "    * e.g.) `css_composition_piechart_Gen(load_pkl=True, pkl_path=\"../database/temp_files/expressed/byCellType/highly_expressed/\",show_pct=5, title=\"highly_expressed\")`\n",
    "* Output: Just a piechart for showing the composition of the css list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9842d119",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generalized version, for splitted (the result of css_CUT_Kmer) or from the pkl file saved \n",
    "# e.g.) css_composition_piechart_Gen(load_pkl=True, pkl_path=\"../database/temp_files/expressed/byCellType/highly_expressed/\",show_pct=5, title=\"highly_expressed\")\n",
    "def css_composition_piechart_Gen(load_pkl=True, pkl_path=None, splitted=None, show_pct=5, **kwargs):\n",
    "    \"\"\"\n",
    "    Usage: css_composition_piechart using the data from either .pkl or splitted (after running css_CUT_Kmer)\n",
    "    Input: .pkl file path or2for , splitted_lst can be the first production of the function \"css_CUT_Kmer\"\n",
    "    show_pct: threshold to show the percentage in pie chart\n",
    "    \"\"\"\n",
    "    ### case 1. when you load .pkl which is usually stored at ../database/temp_files\n",
    "    if load_pkl:\n",
    "        if pkl_path is None:\n",
    "            raise ValueError(\"Path for the folder including .pkl files is required if load_pkl is True.\")\n",
    "        else:\n",
    "            pkl_files = sorted([f for f in os.listdir(pkl_path) if f.endswith('.pkl')])\n",
    "            css_concat=[]\n",
    "            for pkl_file in pkl_files:\n",
    "                with open(pkl_path + pkl_file, \"rb\") as f:\n",
    "                    css = pickle.load(f)\n",
    "                    if isinstance(css[0], list):\n",
    "                        css_flat = flatLst(css)\n",
    "                        css_concat.extend(css_flat)\n",
    "                    else:\n",
    "                        css_concat.extend(css)\n",
    "        splitted=css_concat\n",
    "\n",
    "    ### case 2. when you use splitted, the first one of the results from the function css_CUT_kmer\n",
    "    else:\n",
    "        if splitted is None:\n",
    "            raise ValueError(\"Splitted is required. Run the css_CUT_Kmer first.\")\n",
    "    \n",
    "    splitted_lst=splitted\n",
    "    num_elm=len(splitted_lst)\n",
    "    print(\"total {} of fragments.\".format(num_elm))\n",
    "    \n",
    "    state_count = {chr(i): 0 for i in range(ord('A'), ord('O')+1)}\n",
    "    for elm in splitted_lst:\n",
    "        for state in elm:\n",
    "            if state in state_count:\n",
    "                state_count[state] += 1  # create a dictionary, value of which is the no. of state appeared overall\n",
    "    total = sum(state_count.values())\n",
    "    sizes = [i/sum(state_count.values())*100 for i in state_count.values()] # percentage of occupation\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2,figsize=(12, 6))\n",
    "\n",
    "    ax1.pie(state_count.values(),colors=[state_col_dict[label] for label in state_count.keys()], autopct=lambda p: '{:.2f}%'.format(p) if p > show_pct else '')\n",
    "\n",
    "    if \"title\" in kwargs:\n",
    "        ax1.set_title(kwargs[\"title\"], fontsize=15)\n",
    "    \n",
    "    for t in ax1.texts:\n",
    "        t.set_color(\"white\")\n",
    "        t.set_fontsize(15)\n",
    "        \n",
    "    # print the list of percentages and states\n",
    "    # uncomment this if you want to use text rather than picture-table\n",
    "#     for state, size in zip(state_count.keys(), sizes):\n",
    "#         num_states = int(round(size * total / 100))\n",
    "#         print(f\"{state}. {num_states} ({size:.2f}%)\")\n",
    "\n",
    "    # Hide axis\n",
    "    ax2.axis('off')\n",
    "\n",
    "    # Create table\n",
    "    table = ax2.table(cellText=list(zip(state_count.keys(), [f\"{size:.2f}\" for size in sizes])),\n",
    "                     colLabels=['State', 'Proportion'],\n",
    "                     cellLoc='center', loc='center')\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(12)\n",
    "    table.scale(0.5, 1)\n",
    "    \n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a0ef5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b98da3a7",
   "metadata": {},
   "source": [
    "# 4. CSS Pattern analysis\n",
    "**[back to index](#Index)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd9ff7c",
   "metadata": {},
   "source": [
    "## 4-1. For 15th-including data\n",
    "\n",
    "* Target data: CSS dataset with 15th state included\n",
    "* Starting data is acquired from `all_unit_css=df2unitcss(df)` [Jump](#Unit-length-css)\n",
    "* `all_unit_css` is a list, the element of which is chromosome-wise all-connected **unit-length** (per 200 bp) CSS\n",
    "> `len(all_unit_css)` = 24 <br>\n",
    "> `len(all_unit_css[0])` =1246253\n",
    "<!-- * Start from the process [3-2. Cut the telomere region on CSS and save the file](#3-2.-Cut-the-telomere-region-on-CSS-and-save-the-file) -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "536fc5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## but it must be a distribution where 15th states covers almost of the entire area. \n",
    "## So I stopped here, because basic statistics are known from 4-2. For 15th-less data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2002887f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5c1117",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "818f9291",
   "metadata": {},
   "source": [
    "## 4-2. For 15th-less data\n",
    "\n",
    "Now the dataframe has been transformed into a list of string all connected css, chromosome-wise.<br>\n",
    "The variable of the above list is now called chr_css_list.<br>\n",
    "Following functions will analyze the statistics of the each strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cd84237f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def css_list2count(df, chr_css_list):\n",
    "    \n",
    "    \"\"\"Input: chr_css_list acquired by df2css_chr_str(df), \n",
    "    which is a list of string all connected css, chromosome-wise.\n",
    "    Output: a dataframe (col: chromosome, row:letter)\"\"\"\n",
    "    \n",
    "    state_alphabets=list(state_dict.values())\n",
    "    chr_names=list(df[\"chromosome\"].unique())\n",
    "    count_all=pd.DataFrame(columns=chr_names, index=state_alphabets)  # create an empty dataframe \n",
    "    \n",
    "    for num, _ in enumerate(chr_css_list):   # for each chromosome..\n",
    "        chr_css=chr_css_list[num]\n",
    "        chr_name=chr_names[num]\n",
    "\n",
    "        for letter in state_alphabets:   # count the number of A, B, C, D ... in the string\n",
    "            count_all.loc[letter][chr_name]=chr_css.count(letter)\n",
    "    \n",
    "    return count_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5dbe712c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_count_barplot_incl15(count_all, chr_no):\n",
    "    \n",
    "    \"\"\" Draw a bar plot (chromatin state vs. count) per chromosome\n",
    "    input(1) table of 'count_all' which is created by the function css_list2count(df, chr_css_list) \n",
    "    input(2) chromosome name in string, e.g.) 'chr1', 'chr2', ... \n",
    "    output: bar plot of the all chromatin state count (including 15th state)\"\"\"\n",
    "\n",
    "    count_all_renamed=count_all.rename(index=css_dict)\n",
    "    color_dec=colors2color_dec(css_color_dict)\n",
    "    count_all_renamed.loc[:,chr_no].plot.bar(rot=45, color=color_dec)\n",
    "    ax0=ax0.set_ylabel(\"Counts\", fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "aecf17ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_count_barplot_wo15(count_all, chr_no):\n",
    "    \n",
    "    \"\"\" Draw a bar plot (chromatin state vs. count) per chromosome\n",
    "    input(1) table of 'count_all' which is created by the function css_list2count(df, chr_css_list) \n",
    "    input(2) chromosome name in string, e.g.) 'chr1', 'chr2', ... \n",
    "    output: bar plot of the all chromatin state count except for 15th state\"\"\"\n",
    "\n",
    "    count_all_renamed=count_all.rename(index=css_dict)\n",
    "    color_dec=colors2color_dec(css_color_dict)\n",
    "    ax0=count_all_renamed.loc[:,chr_no][:-1].plot.bar(rot=45, color=color_dec)\n",
    "    ax0.set_ylabel(\"Counts\", fontsize=14)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5bef3b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def colored_css_str(sub_str):\n",
    "    col_str=\"\"\n",
    "    for letter in sub_str:\n",
    "        for state in list(state_col_255_dict.keys()):\n",
    "            if letter==state:\n",
    "                r=state_col_255_dict[letter][0]\n",
    "                g=state_col_255_dict[letter][1]\n",
    "                b=state_col_255_dict[letter][2]\n",
    "                col_letter=\"\\033[38;2;{};{};{}m{}\\033[38;2;255;255;255m\".format(r,g,b,letter)\n",
    "                col_str+=col_letter\n",
    "    return print(\"\\033[1m\"+col_str+\"\\033[0;0m\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067f5b22",
   "metadata": {},
   "source": [
    "**Frequently used function!** <br>\n",
    "To convert any string into colored string according to the color palette for CSS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "aa9c144e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def colored_css_str_as_is(sub_str):   # convert space into space\n",
    "    col_str=\"\"\n",
    "    for letter in sub_str:\n",
    "        if letter==\" \":\n",
    "            col_str+=\" \"\n",
    "        else:                \n",
    "            for state in list(state_col_255_dict.keys()):\n",
    "                if letter==state:\n",
    "                    r=state_col_255_dict[letter][0]\n",
    "                    g=state_col_255_dict[letter][1]\n",
    "                    b=state_col_255_dict[letter][2]\n",
    "                    col_letter=\"\\033[38;2;{};{};{}m{}\\033[38;2;255;255;255m\".format(r,g,b,letter)\n",
    "                    col_str+=col_letter\n",
    "    return print(\"\\033[1m\"+col_str+\"\\033[0;0m\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fece48",
   "metadata": {},
   "source": [
    "#### css pattern analysis without 15th state (state **O**)\n",
    "\n",
    "1. create a list of a css without 15th state, the element of which is connected (df2inbetweeen_lst)\n",
    "2. create a whole list of css without 15th state, using a all-chromosome df (df2wo15list)\n",
    "3. calculate the length of each element of the generated list, and analyze the statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7b009962",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df2inbetweeen_lst(df):\n",
    "    lst=[]\n",
    "    df_wo_o=df[df[\"state\"]!=15]   #remove the 15th state from the css\n",
    "    css_df=df_wo_o[\"state_seq_full\"]\n",
    "    str_elm=css_df.iloc[0]  # the very first elm\n",
    "    for i in range(1, len(css_df)):\n",
    "        # check the index first\n",
    "        cid=css_df.index[i] #init=1\n",
    "        pid=css_df.index[i-1] # init=0\n",
    "        ssf=css_df\n",
    "        if (cid-pid)!=1: # if the index is separated (not a succeeding numbers)\n",
    "            lst.append(str_elm)\n",
    "            str_elm=ssf.iloc[i]\n",
    "        else:            # if encountered a consecutive index\n",
    "            str_elm+=ssf.iloc[i] # attach the next str to the previous str\n",
    "            if i==len(css_df)-1:   # treat the final line\n",
    "                lst.append(str_elm)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "086119b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df2wo15list(df):\n",
    "    total_lst=[]\n",
    "    df_chr_list=df2chr_df(df)   # a list, elm of which is the df of each chromosome\n",
    "    for df_chr in df_chr_list:   # for each chromosome, create a grand list by adding up the whole\n",
    "        lst_chr=df2inbetweeen_lst(df_chr)\n",
    "        total_lst+=lst_chr\n",
    "    return total_lst   # total_lst here consists of the connected-patterns betweeen 15th state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c2bd4a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def css_elm_stat(total_lst):# graph of the length distribution \n",
    "    len_lst=[]              # total_lst here consists of the connected-patterns betweeen 15th state\n",
    "    for elm in total_lst:\n",
    "        assert type(elm)==str, \"element type is not string\"\n",
    "        len_lst.append(len(elm))\n",
    "    print(\"total count: \", len(total_lst))\n",
    "    print(\"max length: \", max(len_lst))\n",
    "    print(\"min length: \", min(len_lst))\n",
    "    print(\"average length: \",np.mean(len_lst))\n",
    "    fig =plt.figure(figsize=(6,4))\n",
    "    plt.hist(len_lst, bins=20, log=True, color=\"teal\", edgecolor=\"white\")\n",
    "    plt.xlabel(\"length of chromatin state pattern\", fontsize=14)\n",
    "    plt.ylabel(\"Count\", fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e198cc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lst2let_compose(total_lst):# graph of the number of letter composed for a pattern\n",
    "    letter_cnt=[]              # total_lst here consists of the connected-patterns betweeen 15th state\n",
    "    for word in total_lst:\n",
    "        chk_let=word[0]\n",
    "        num_let=1\n",
    "        for let in word:\n",
    "            if let!=chk_let:\n",
    "                num_let+=1\n",
    "                chk_let=let\n",
    "        letter_cnt.append(num_let)\n",
    "    print(\"total count: \", len(letter_cnt))\n",
    "    print(\"max composition: \", max(letter_cnt))\n",
    "    print(\"min composition: \", min(letter_cnt))\n",
    "    print(\"average composition: \", np.mean(letter_cnt))\n",
    "    fig =plt.figure(figsize=(6,4))\n",
    "    plt.hist(letter_cnt, bins=20, log=True, color=\"orange\", edgecolor=\"white\")\n",
    "    plt.xlabel(\"number of state in a composition\", fontsize=14)\n",
    "    plt.ylabel(\"Count\", fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9269b02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_colorlist(data_dict):\n",
    "    \n",
    "    \"\"\" \n",
    "    INPUT: solo chromatin state data in dict such as \n",
    "           data_dict={'I': 114, 'A': 23, 'N': 119, 'G': 33, 'E': 131, 'H': 1}\n",
    "    OUTPUT: customized colormap according to ROADMAP (type=list)\n",
    "    \"\"\"\n",
    "    state_list=list(data_dict.keys())\n",
    "    colormap_list=[]\n",
    "    assert type(state_list[0])==str\n",
    "    for state in state_list:\n",
    "        if css_dict[state] in css_name_col_dict.keys():\n",
    "            color_rgb=css_name_col_dict[css_dict[state]]\n",
    "            colormap_list.append(color_rgb)\n",
    "    return colormap_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2327915a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lst2solo_compose(total_lst):# graph of a solo pattern frequency\n",
    "    \n",
    "    \"\"\"INPUT: the entire list of in-between pattern w.o. 15th state (total_lst)\n",
    "       OUTPUT: the most/least frequent solo pattern and the frequency graph\n",
    "    \"\"\"\n",
    "    \n",
    "    letter_cnt=[]\n",
    "    for word in total_lst:\n",
    "        chk_let=word[0]\n",
    "        num_let=1\n",
    "        for let in word:\n",
    "            if let!=chk_let:\n",
    "                num_let+=1\n",
    "                chk_let=let\n",
    "        letter_cnt.append(num_let)\n",
    "    css_lst_dict=dict(zip(total_lst, letter_cnt))\n",
    "    \n",
    "    lst_for_solo=[]                   # prepare to make a solo pattern list\n",
    "    for pattern, num in list(css_lst_dict.items()): # as a tuple element (key, val)\n",
    "        if num==1:\n",
    "            lst_for_solo.append(pattern[0])\n",
    "    solo_counter=collections.Counter(lst_for_solo)\n",
    "    solo_data_dict=dict(solo_counter) # ditionary of solo pattern and the frequency\n",
    "    solo_data_dict=dict(sorted(solo_data_dict.items(), reverse=True, key=lambda item: item[1]))\n",
    "    my_color=custom_colorlist(solo_data_dict)  # create a customized colormap using solo data\n",
    "    \n",
    "    for pattern, num in solo_data_dict.items():\n",
    "        if num is max(solo_data_dict.values()):\n",
    "            max_state=pattern\n",
    "            max_num=num\n",
    "        elif num is min(solo_data_dict.values()):\n",
    "            min_state=pattern\n",
    "            min_num=num\n",
    "\n",
    "    print(\"frequency of solo pattern: \", len(lst_for_solo))\n",
    "    print(\"the most frequent solo pattern: \", css_dict[max_state], \" for \", max_num, \" times appeared.\" )\n",
    "    print(\"the least frequent solo pattern: \", css_dict[min_state], \" for \", min_num, \" times appeared.\" )\n",
    "    \n",
    "    x=[css_dict[state] for state in solo_data_dict.keys()]\n",
    "    y=solo_data_dict.values()\n",
    "    \n",
    "    fig =plt.figure(figsize=(6,4))\n",
    "    plt.bar(x,y, color=my_color)\n",
    "    plt.xlabel(\"solo pattern\", fontsize=14)\n",
    "    plt.ylabel(\"Frequency\", fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56e48fe",
   "metadata": {},
   "source": [
    "#### make a kmer and save as a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7ff9bc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_lst2kmer(total_lst,k):\n",
    "    total_kmer_lst=[]\n",
    "    for elm in total_lst:\n",
    "        elm2kmer=seq2kmer(elm, k)\n",
    "        if len(elm2kmer) >0:   # remove the short pattern... will be fine?\n",
    "            total_kmer_lst.append(elm2kmer)\n",
    "    return total_kmer_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7100ccca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_kmer_lst=total_lst2kmer(total_lst,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "88b26d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name02=\"../database/test_data/6_tr01.txt\"\n",
    "# with open(file_name02,\"w\") as g:\n",
    "#     g.write(\"\\n\".join(total_kmer_lst))\n",
    "# g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e55f46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcba3c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11110dd0",
   "metadata": {},
   "source": [
    "# 5. Training result analysis\n",
    "**[back to index](#Index)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d7564d",
   "metadata": {},
   "source": [
    "## 5-1. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408a0e09",
   "metadata": {},
   "source": [
    "### 5-1-2. Pretrain evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "145de902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalDFconcat(df_lst, col_name, col_rename, colormap=\"Set1\"):\n",
    "    \"\"\"\n",
    "    Input\n",
    "    (1) df_lst: a list of target dataframes\n",
    "    (2) col_name: the columns of interest\n",
    "    (3) col_rename: a list of columns for the concatenated dataframes\n",
    "    \"\"\"\n",
    "    assert type(df_lst), \"Input should be a list of dataframes\"\n",
    "    assert type(col_rename), \"col_rename should be a list\"\n",
    "    assert len(df_lst)==len(col_rename), \"Check the length of input list\"\n",
    "    assert col_name in df_lst[0].columns, \"'{}' is not in the column list of dataframe\".format(col_name)\n",
    "    df_col_lst=[]\n",
    "    for num in range(len(df_lst)):       \n",
    "        df_col_lst.append(df_lst[num][col_name])\n",
    "    df_concat=pd.concat(df_col_lst, axis=1)\n",
    "    df_concat.columns=col_rename\n",
    "    \n",
    "    fig=plt.figure(figsize=(6,4))\n",
    "    p=sns.lineplot(data=df_concat, palette=colormap)\n",
    "    p.set_ylabel(col_name, fontsize=14)\n",
    "    p.set_xlabel(\"Iteration\", fontsize=14)\n",
    "#     p.set_ylim(1.0,2.8)\n",
    "    p.legend(fontsize=14)\n",
    "    \n",
    "    return df_concat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b28b0bb",
   "metadata": {},
   "source": [
    "#### Function: `evalPre_by_folder` \n",
    "\n",
    "* Usage: Create a dataframe and show the result plot of pretraining \n",
    "* Input: path of the pretraining result, basically under the folder `../database/pretrain/`\n",
    "* User input: `\"all\"` or a list of integer, such as `[0,1,2]`, as you can select from the list this function shows. \n",
    "* Output: Plot of perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1657291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalPre_by_folder(path,target='all',colormap=\"Set1\", ylim=6.5):\n",
    "    \"\"\"\n",
    "    path: the directory you have the pretrain result (eval_results.txt)\n",
    "          Multiple files can be processed.\n",
    "    target: if designated as \"all\", it considers all the files. \n",
    "            Otherwise, a list containing the numbers of the file you want to analyze should be given.\n",
    "    \"\"\"\n",
    "    file_list=[os.path.join(path, file) for file in sorted(os.listdir(path))]\n",
    "    print(\"\\n\".join(file_list))\n",
    "\n",
    "    target = input(\"Enter 'all' to process all files or a list of file numbers to process (ex. [1,2,3]): \")\n",
    "\n",
    "    if target == 'all':\n",
    "        target = 'all'\n",
    "    else:\n",
    "        try:\n",
    "            target = ast.literal_eval(target)\n",
    "            if not all(isinstance(i, int) for i in target):\n",
    "                raise ValueError(\"Invalid input, target should be 'all' or a list of integers.\")\n",
    "            for i in target:\n",
    "                if i > len(file_list):\n",
    "                    raise ValueError(\"Invalid file number\")\n",
    "        except (ValueError, SyntaxError):\n",
    "            raise ValueError(\"Invalid input, target should be 'all' or a list of integers in the format [1,2,3].\")\n",
    "\n",
    "    file_df_all=[]\n",
    "    if target=='all':        \n",
    "        for i, file in enumerate(file_list):\n",
    "            f_name=re.search(r'eval_results_(.*).txt', file).group(1)\n",
    "            file_df=pd.read_csv(file, header=None, names=[\"perplexity\"])\n",
    "            file_df.rename(columns={'perplexity': f_name}, inplace=True)\n",
    "            file_df_all.append(file_df)\n",
    "        result_df = pd.concat(file_df_all, axis=1)\n",
    "        \n",
    "    elif type(target)==list and type(target[0])==int:\n",
    "        for i in target:\n",
    "            f_name=re.search(r'eval_results_(.*).txt', file_list[i]).group(1)\n",
    "            file_df=pd.read_csv(file_list[i], header=None, names=[\"perplexity\"])\n",
    "            file_df.rename(columns={'perplexity': f_name}, inplace=True)\n",
    "            file_df_all.append(file_df)\n",
    "        result_df = pd.concat(file_df_all, axis=1)\n",
    "        \n",
    "    fig=plt.figure(figsize=(6,4))\n",
    "    p=sns.lineplot(data=result_df, palette=colormap)\n",
    "    p.set_xlabel(\"Iternation\", fontsize=13)\n",
    "    p.set_ylim([0.5, ylim])\n",
    "    \n",
    "    return result_df    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39ffef8",
   "metadata": {},
   "source": [
    "### 5-1-3. Fine tuning evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03d0ed4",
   "metadata": {},
   "source": [
    "The result of fine-tuning is provided by a `eval_result.txt` file by default, which contains acc (accuracy), auc (area under curve), mcc (Matthew's correlation coefficient), f1 score, precision, and recall. Those files can be saved with different names which contain the different experimental condition. \n",
    "\n",
    "The series of functions below are the unit functions for internal use, or simple use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95311d0",
   "metadata": {},
   "source": [
    " #### Function: `evalFT_df`\n",
    " * Create dataframe from the raw file `eval_result.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82aa8282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalFT_df(path):\n",
    "    \"\"\"\n",
    "    Unit function for eval_result.txt obtained after the fine tuning\n",
    "    \"\"\"\n",
    "    df=pd.read_csv(path, index_col=False, sep=\"\\s\", header=None, engine='python')\n",
    "    df.columns=[\"k\",\"acc\",\"auc\",\"f1\",\"mcc\",\"precision\",\"recall\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83de1135",
   "metadata": {},
   "source": [
    "#### Function `evalFT_fig`\n",
    "* Draw af figure for a single `eval_result.txt` file at the designated path. \n",
    "* Inputs\n",
    "    * `path` : path of the raw file\n",
    "    * `target` : any of `[acc\",\"auc\",\"f1\",\"mcc\",\"precision\",\"recall\"]` as a string, or a sub-list can be accepted\n",
    "    * `kwargs` : title can be added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e3856745",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalFT_fig(path, iteration=60, target=\"auc\", figsize=(4,2.5), colormap=\"Set1\", **kwargs):\n",
    "    \"\"\"\n",
    "    Unit function for drawing the figure only\n",
    "    \"target\" should be designated, either string or a list of strings\n",
    "    \"\"\"\n",
    "    df=evalFT_df(path)\n",
    "    fig=plt.figure(figsize=figsize)\n",
    "    plt.ylim([0,1])\n",
    "    plt.ylabel(\"metrics\")\n",
    "    plt.xlabel(\"iterations\")\n",
    "    color_lst=sns.color_palette(colormap)\n",
    "    line_lst=[\"-\",\"--\",\":\"]\n",
    "\n",
    "    if \"title\" in kwargs:\n",
    "        title=kwargs[\"title\"]\n",
    "        plt.title(title)\n",
    "    \n",
    "    df_target=pd.DataFrame()\n",
    "    \n",
    "    if not isinstance(target,list):\n",
    "        sns.lineplot(df[target][:iteration], label=target)\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        auc_avg_f10=np.mean(df[\"auc\"][:iteration].iloc[-10:])\n",
    "        df_target[target]=list(df[target][:iteration])\n",
    "        plt.text(2, 0.1, \"final 10 AUC avg. \"+str(round(auc_avg_f10,3)))\n",
    "    else:    \n",
    "        for i, tar in enumerate(target):\n",
    "            sns.lineplot(df[tar][:iteration], label=tar, linestyle=line_lst[i], color=color_lst[i])\n",
    "            plt.legend(loc=\"lower right\")\n",
    "            auc_avg_f10=np.mean(df[\"auc\"][:iteration].iloc[-10:])\n",
    "            plt.text(2, 0.1, \"final 10 AUC avg. \"+str(round(auc_avg_f10,3)))\n",
    "            \n",
    "            target_val_lst=list(df[tar][:iteration])\n",
    "            df_target[tar]=target_val_lst\n",
    "            \n",
    "    return  df_target "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561955a3",
   "metadata": {},
   "source": [
    "#### Function `evalFT_overview`\n",
    "* Show the result of evaluation in a figure\n",
    "* Input:\n",
    "    * `path_all` : either one or multiple paths\n",
    "    * `target`: any of `[acc\",\"auc\",\"f1\",\"mcc\",\"precision\",\"recall\"]` as a string, or a sub-list can be accepted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b1bd46f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalFT_overview(path_all,iteration, target,colormap=\"Set1\", show_depth=-2):\n",
    "    \n",
    "    if not isinstance(path_all,list):\n",
    "        df_target=evalFT_fig(path_all,iteration=iteration, target=target, figsize=(4,2.5), colormap=colormap)\n",
    "\n",
    "    else:\n",
    "        keys=[]\n",
    "        values=[]\n",
    "        for i, path in enumerate(path_all):\n",
    "            file_name_lst=os.path.splitext(path)[0].split(\"/\")[show_depth:]\n",
    "            title='   '.join(file_name_lst)\n",
    "            keys.append(file_name_lst[0])\n",
    "            df_target=evalFT_fig(path, iteration=iteration, target=target, colormap=colormap, title=title)\n",
    "            values.append(df_target)    \n",
    "        dict_df_target=dict(zip(keys,values))\n",
    "        \n",
    "    return dict_df_target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a278d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ce5bbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3564a4eb",
   "metadata": {},
   "source": [
    "#### Function: `pred_prob_overall` \n",
    "\n",
    "* Usage: Create a dataframe for prediction result and show the result plot (confusion matrix, violin plot)\n",
    "* Input: path of the prediction result file (`pred_results.npy`) and the labeled file (`dev.tsv`)\n",
    "    * `dev_path=\"../database/fine_tune/CompG_and_lessCompG/4mer/dev.tsv\"`\n",
    "    * `pred_path=\"../database/ft_result/pred/4_compless/pred_results.npy\"`\n",
    "* Output: Two dataframes (`high_pred`: label 1 and its prediction ,`low_pred`: label 0 and its prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e2c28f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pred_prob_overall(dev_path,pred_path, color1=\"Blues\",color2_lst=[\"yellowgreen\",\"skyblue\",\"teal\",\"royalblue\"]):\n",
    "#     pred=np.load(pred_path)\n",
    "#     dev=pd.read_csv(dev_path, sep=\"\\t\")\n",
    "#     dev[\"pred\"]=pred\n",
    "#     dev[\"pred_bool\"]=None\n",
    "#     df=dev\n",
    "    \n",
    "#     assert type(color2_lst) and len(color2_lst)==4, \"enter a list of 4 elements, as color names\"\n",
    "    \n",
    "#     # confusion matrix #\n",
    "#     for i in range(len(df)):\n",
    "#         if df[\"pred\"].at[i]>=0.5 :\n",
    "#             df[\"pred_bool\"].at[i]=1\n",
    "#         else:\n",
    "#             df[\"pred_bool\"].at[i]=0\n",
    "#     assert df[\"pred_bool\"].isnull().any()==False, \"Check the pred_bool\"\n",
    "#     cf_matrix=confusion_matrix(df[\"label\"],df[\"pred_bool\"].astype(bool))\n",
    "\n",
    "#     group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "#     group_counts = [\"{0:0.0f}\".format(value) for value in cf_matrix.flatten()]\n",
    "#     group_percentages = [\"({0:.2%})\".format(value) for value in cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "#     labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "#     labels = np.asarray(labels).reshape(2,2)\n",
    "    \n",
    "#     # confusion matrix visualization\n",
    "#     sns.heatmap(cf_matrix, annot=labels, annot_kws={'size': 16}, fmt='', cmap=color1)\n",
    "#     print(classification_report(df[\"label\"], df[\"pred_bool\"].astype(bool)))\n",
    "    \n",
    "#     high_prob, low_prob=[],[]\n",
    "#     label_1, label_0=[],[]\n",
    "#     high_1, high_0=[],[]\n",
    "#     low_1, low_0=[],[]\n",
    "\n",
    "#     for i in range(len(df)):\n",
    "#         # high_prob is defined as larger than 0.5       \n",
    "#         if df[\"pred\"].iloc[i]>=0.5:\n",
    "#             high_prob.append(df[\"pred\"].iloc[i])\n",
    "#             label_1.append(df[\"label\"].iloc[i])\n",
    "#             if df[\"label\"].iloc[i]==1:  # predition is higher than 0.5(=true), and label is 1 (=true): true positive\n",
    "#                 high_1.append(df[\"pred\"].iloc[i])\n",
    "#             else:\n",
    "#                 high_0.append(df[\"pred\"].iloc[i])    \n",
    "#         else:\n",
    "#             low_prob.append(df[\"pred\"].iloc[i])\n",
    "#             label_0.append(df[\"label\"].iloc[i])\n",
    "#             if df[\"label\"].iloc[i]==0: # predition is lower than 0.5(=false), and label is 0 (=false): true negative\n",
    "#                 low_0.append(df[\"pred\"].iloc[i])\n",
    "#             else:\n",
    "#                 low_1.append(df[\"pred\"].iloc[i])\n",
    "\n",
    "# #     print(\"false positive: {} |  false negative: {}\".format(false_positive,false_negative))\n",
    "#     high_pred=pd.DataFrame({'label': label_1, 'pred': high_prob})\n",
    "#     low_pred=pd.DataFrame({'label': label_0, 'pred': low_prob})\n",
    "\n",
    "#     fig=plt.figure(figsize=(8,8))\n",
    "#     plt.subplots_adjust(wspace=0.5, hspace=0.5)\n",
    "#     plt.subplot(2, 2, 1)\n",
    "#     sns.violinplot(data=high_prob, color=color2_lst[0])\n",
    "#     plt.title('High Probability', fontsize=13)\n",
    "#     plt.xticks([])\n",
    "#     plt.xlabel(\"predition >= 0.5\", fontsize=13)\n",
    "#     plt.ylabel(\"Prediction\", fontsize=13)\n",
    "\n",
    "#     plt.subplot(2, 2, 2)\n",
    "#     sns.violinplot(data=low_prob, color=color2_lst[1])\n",
    "#     plt.title('Low Probability', fontsize=13)\n",
    "#     plt.xticks([])\n",
    "#     plt.xlabel(\"predition < 0.5\", fontsize=13)\n",
    "#     plt.ylabel(\"Prediction\", fontsize=13)\n",
    "    \n",
    "#     plt.subplot(2, 2, 3)\n",
    "#     sns.violinplot(data=high_1, color=color2_lst[2])\n",
    "#     plt.title('True positive', fontsize=13)\n",
    "#     plt.xticks([])\n",
    "#     plt.xlabel(\"For label 1\", fontsize=13)\n",
    "#     plt.ylabel(\"Prediction\", fontsize=13)\n",
    "    \n",
    "#     plt.subplot(2, 2, 4)\n",
    "#     sns.violinplot(data=low_0, color=color2_lst[3])\n",
    "#     plt.title('True negative', fontsize=13)\n",
    "#     plt.xticks([])\n",
    "#     plt.xlabel(\"For label 0\", fontsize=13)\n",
    "#     plt.ylabel(\"Prediction\", fontsize=13)\n",
    "\n",
    "#     plt.show()\n",
    "\n",
    "#     return high_pred,low_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f95e9382",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_prob_overall(dev_path,pred_path, color1=\"Blues\",color2_lst=[\"yellowgreen\",\"skyblue\",\"teal\",\"royalblue\"]):\n",
    "    pred=np.load(pred_path)\n",
    "    dev=pd.read_csv(dev_path, sep=\"\\t\")\n",
    "    dev[\"pred\"]=pred\n",
    "    dev[\"pred_bool\"]=None\n",
    "    df=dev\n",
    "    \n",
    "    assert type(color2_lst) and len(color2_lst)==4, \"enter a list of 4 elements, as color names\"\n",
    "    \n",
    "    # confusion matrix #\n",
    "    for i in range(len(df)):\n",
    "        if df[\"pred\"].at[i]>=0.5 :\n",
    "            df[\"pred_bool\"].at[i]=1\n",
    "        else:\n",
    "            df[\"pred_bool\"].at[i]=0\n",
    "    assert df[\"pred_bool\"].isnull().any()==False, \"Check the pred_bool\"\n",
    "    cf_matrix=confusion_matrix(df[\"label\"],df[\"pred_bool\"].astype(bool))\n",
    "\n",
    "    group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in cf_matrix.flatten()]\n",
    "    group_percentages = [\"({0:.2%})\".format(value) for value in cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "    labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "    \n",
    "    # confusion matrix visualization\n",
    "    sns.heatmap(cf_matrix, annot=labels, annot_kws={'size': 16}, fmt='', cmap=color1)\n",
    "    print(classification_report(df[\"label\"], df[\"pred_bool\"].astype(bool)))\n",
    "    \n",
    "    high_prob, low_prob=[],[]\n",
    "    label_1, label_0=[],[]\n",
    "    high_1, high_0=[],[]\n",
    "    low_1, low_0=[],[]\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        # high_prob is defined as larger than 0.5       \n",
    "        if df[\"pred\"].iloc[i]>=0.5:\n",
    "            high_prob.append(df[\"pred\"].iloc[i])\n",
    "            label_1.append(df[\"label\"].iloc[i])\n",
    "            if df[\"label\"].iloc[i]==1:  # predition is higher than 0.5(=true), and label is 1 (=true): true positive\n",
    "                high_1.append(df[\"pred\"].iloc[i])\n",
    "            else:\n",
    "                high_0.append(df[\"pred\"].iloc[i])    \n",
    "        else:\n",
    "            low_prob.append(df[\"pred\"].iloc[i])\n",
    "            label_0.append(df[\"label\"].iloc[i])\n",
    "            if df[\"label\"].iloc[i]==0: # predition is lower than 0.5(=false), and label is 0 (=false): true negative\n",
    "                low_0.append(df[\"pred\"].iloc[i])\n",
    "            else:\n",
    "                low_1.append(df[\"pred\"].iloc[i])\n",
    "\n",
    "#     print(\"false positive: {} |  false negative: {}\".format(false_positive,false_negative))\n",
    "    high_pred=pd.DataFrame({'label': label_1, 'pred': high_prob})\n",
    "    low_pred=pd.DataFrame({'label': label_0, 'pred': low_prob})\n",
    "\n",
    "    fig=plt.figure(figsize=(8,8))\n",
    "    plt.subplots_adjust(wspace=0.5, hspace=0.5)\n",
    "    plt.subplot(2, 2, 1)\n",
    "    sns.violinplot(data=high_prob, color=color2_lst[0])\n",
    "    plt.title('High Probability', fontsize=13)\n",
    "    plt.xticks([])\n",
    "    plt.xlabel(\"predition >= 0.5\", fontsize=13)\n",
    "    plt.ylabel(\"Prediction\", fontsize=13)\n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "    sns.violinplot(data=low_prob, color=color2_lst[1])\n",
    "    plt.title('Low Probability', fontsize=13)\n",
    "    plt.xticks([])\n",
    "    plt.xlabel(\"predition < 0.5\", fontsize=13)\n",
    "    plt.ylabel(\"Prediction\", fontsize=13)\n",
    "    \n",
    "    plt.subplot(2, 2, 3)\n",
    "    sns.violinplot(data=high_1, color=color2_lst[2])\n",
    "    plt.title('True positive', fontsize=13)\n",
    "    plt.xticks([])\n",
    "    plt.xlabel(\"For label 1\", fontsize=13)\n",
    "    plt.ylabel(\"Prediction\", fontsize=13)\n",
    "    \n",
    "    plt.subplot(2, 2, 4)\n",
    "    sns.violinplot(data=low_0, color=color2_lst[3])\n",
    "    plt.title('True negative', fontsize=13)\n",
    "    plt.xticks([])\n",
    "    plt.xlabel(\"For label 0\", fontsize=13)\n",
    "    plt.ylabel(\"Prediction\", fontsize=13)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return high_pred,low_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23669ec",
   "metadata": {},
   "source": [
    "## 5-2. Motif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a59335a",
   "metadata": {},
   "source": [
    "#### Function `motif_df_initProcessing`\n",
    "\n",
    "* Usage: Initial processing for motif dataframe, created by `motif_utils.py`. Adding the columns like '\n",
    "* Input: motif dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c088599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def motif_df_initProcessing(motif_df=\"../database/motif/compNg_condw24min5ins3_df.csv\"):\n",
    "    fname=motif_df\n",
    "    hparam=r'cond(\\d+)?|w(\\d+)|min(\\d+)|ins(\\d+)'\n",
    "    matches=re.findall(hparam,fname)\n",
    "    numbers=[num for match in matches for num in match if num]\n",
    "    if not matches[0][0]: # if no number after cond (which is actually cond1 AND cond2)\n",
    "        cond='_'  # replace it with underscore\n",
    "        win=numbers[0]\n",
    "        min_len=numbers[1]\n",
    "        min_ins=numbers[2]\n",
    "    else:   \n",
    "        cond=numbers[0]\n",
    "        win=numbers[1]\n",
    "        min_len=numbers[2]\n",
    "        min_ins=numbers[3]\n",
    "    \n",
    "    print(\"condition: {}, windows: {}, min_length: {}, min_instance: {}\".format(cond,win,min_len,min_ins))\n",
    "    \n",
    "    # add columns \"pro_x\" and \"length\" to the dataframe\n",
    "    df=pd.read_csv(motif_df, engine='python')\n",
    "    df_sorted=df.sort_values(by=\"p\")   # sort by p-value, ascending order\n",
    "    df_sorted[\"pro_x\"]=df_sorted[\"x\"]/df_sorted[\"n\"] # add columns for proportional x over n\n",
    "    df_sorted[\"length\"]=[len(motif) for motif in df_sorted['motif'].tolist()] # and for length\n",
    "    \n",
    "    max_motif_len=max(df_sorted[\"length\"])\n",
    "    min_motif_len=min(df_sorted[\"length\"])\n",
    "    print(\"Total found motif number (p-val<0.05): {}\".format(len(df_sorted)))\n",
    "    print(\"max motif length: {}, min motif length: {}\".format(max_motif_len,min_motif_len))\n",
    "    \n",
    "    # list of colored motif\n",
    "    motif_lst=df_sorted[\"motif\"].tolist()\n",
    "    colored_motif=[colored_css_str_as_is(motif) for motif in motif_lst]\n",
    "    \n",
    "    return df_sorted, colored_motif   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281b3b27",
   "metadata": {},
   "source": [
    "#### Function `create_motif_wordcloud`\n",
    "\n",
    "* Usage: create a word cloud using `wordcloud` package for representing the frequency of each motif\n",
    "* Input: path of the motif (where the file name is like `motif_AAAAA_3_txt`\n",
    "* Output: word cloud of the motif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1817794f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_motif_wordcloud(path, color_map=\"viridis\"):\n",
    "    target=[word for word in path.split(\"/\")[-2:] if word !=\"\"][0]\n",
    "    print(\"target\", target)\n",
    "    file_lst=[os.path.join(path,file) for file in os.listdir(path) if \".txt\" in file]\n",
    "    motifs={}\n",
    "    for file_name in file_lst:\n",
    "        motif, num_txt=file_name.split(\"/\")[-1].split(\"_\")[1:3]\n",
    "        freq=num_txt.split(\".\")[0]\n",
    "        motifs[motif]=int(freq)\n",
    "    print(\"motifs = \", motifs)\n",
    "    wc=WordCloud(width=800, height=400, background_color=\"white\", colormap=color_map)\n",
    "    wordcloud=wc.generate_from_frequencies(motifs)\n",
    "    plt.figure(figsize=(6,2), facecolor=None)\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout(pad=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6750e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0f8152",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c24083",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307784a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f11478",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
